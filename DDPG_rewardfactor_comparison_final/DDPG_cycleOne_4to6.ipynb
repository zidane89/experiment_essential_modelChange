{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "import scipy.io as sio\n",
    "\n",
    "from vehicle_model_variant import Environment \n",
    "from cell_model import CellModel \n",
    "from driver_MDP import Driver_MDP \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "# env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "driver = Driver_MDP(0.02)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200 \n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1.0 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "#     actor_model.load_weights(\"./DDPG1_trial1/actor_model_checkpoint\")\n",
    "#     critic_model.load_weights(\"./DDPG1_trial1/critic_model_checkpoint\")\n",
    "#     target_actor.load_weights(\"./DDPG1_trial1/target_actor_checkpoint\")\n",
    "#     target_critic.load_weights(\"./DDPG1_trial1/target_critic_checkpoint\")\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    if not os.path.exists(root): \n",
    "        os.makedirs(root)\n",
    "        \n",
    "    actor_model.save_weights(\"./{}/actor_model.h5\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model.h5\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor.h5\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic.h5\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor):\n",
    "#     test_cycle = driver.get_cycle() \n",
    "    test_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "    test_cycle = sio.loadmat(test_cycle_path)\n",
    "    test_cycle = test_cycle[\"sch_cycle\"][:, 1]\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "#     print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_cycle)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env.history[\"Action\"])\n",
    "    plt.show() \n",
    "    return env.history  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 4\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.347\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -2137.9022247450516 SOC: 0.9996 Cumulative_SOC_deviation: 485.5456 Fuel Consumption: 195.7199\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.184\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2128.0913946949604 SOC: 1.0000 Cumulative_SOC_deviation: 483.9072 Fuel Consumption: 192.4626\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.720\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2045.229986222075 SOC: 0.9994 Cumulative_SOC_deviation: 464.7664 Fuel Consumption: 186.1644\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 32.766\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -2141.7047648919574 SOC: 0.9997 Cumulative_SOC_deviation: 486.7720 Fuel Consumption: 194.6169\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.900\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -2122.3212385077527 SOC: 1.0000 Cumulative_SOC_deviation: 482.2817 Fuel Consumption: 193.1944\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.748\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -2064.914874514088 SOC: 1.0000 Cumulative_SOC_deviation: 471.1101 Fuel Consumption: 180.4745\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.997\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2061.444794265419 SOC: 1.0000 Cumulative_SOC_deviation: 470.4384 Fuel Consumption: 179.6911\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.234\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -2039.3902490226849 SOC: 1.0000 Cumulative_SOC_deviation: 466.2571 Fuel Consumption: 174.3619\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.685\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2014.1306906883894 SOC: 0.9999 Cumulative_SOC_deviation: 459.7464 Fuel Consumption: 175.1453\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.111\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2018.9831708299648 SOC: 1.0000 Cumulative_SOC_deviation: 461.6372 Fuel Consumption: 172.4343\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.556\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -1838.272601163516 SOC: 1.0000 Cumulative_SOC_deviation: 418.5109 Fuel Consumption: 164.2292\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.060\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -1890.5947721175364 SOC: 0.9956 Cumulative_SOC_deviation: 431.0966 Fuel Consumption: 166.2083\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.948\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -1853.9254693742605 SOC: 0.9952 Cumulative_SOC_deviation: 421.9731 Fuel Consumption: 166.0331\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.039\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -1796.178087662706 SOC: 0.9988 Cumulative_SOC_deviation: 408.7114 Fuel Consumption: 161.3327\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.792\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -1783.248159288935 SOC: 0.9999 Cumulative_SOC_deviation: 405.1129 Fuel Consumption: 162.7964\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.256\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -1747.847281605951 SOC: 0.9973 Cumulative_SOC_deviation: 398.2341 Fuel Consumption: 154.9108\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.779\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -1602.6888287635795 SOC: 0.9988 Cumulative_SOC_deviation: 361.8981 Fuel Consumption: 155.0964\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.855\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -1643.8516538082124 SOC: 1.0000 Cumulative_SOC_deviation: 372.1450 Fuel Consumption: 155.2716\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.621\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -1473.1724935722461 SOC: 0.9977 Cumulative_SOC_deviation: 330.0422 Fuel Consumption: 153.0039\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.393\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -1454.9249113082415 SOC: 0.9979 Cumulative_SOC_deviation: 324.6531 Fuel Consumption: 156.3127\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.894\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -1315.4799061719966 SOC: 0.9864 Cumulative_SOC_deviation: 290.7401 Fuel Consumption: 152.5194\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.119\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1427.6613944797414 SOC: 0.9918 Cumulative_SOC_deviation: 318.7159 Fuel Consumption: 152.7977\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.727\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1289.4703263882247 SOC: 0.9886 Cumulative_SOC_deviation: 284.0342 Fuel Consumption: 153.3337\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.714\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1087.308194010306 SOC: 0.9644 Cumulative_SOC_deviation: 233.7384 Fuel Consumption: 152.3545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.464\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -927.2389961911537 SOC: 0.9013 Cumulative_SOC_deviation: 194.7004 Fuel Consumption: 148.4374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.764\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -764.1932049663639 SOC: 0.9200 Cumulative_SOC_deviation: 153.5910 Fuel Consumption: 149.8290\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.437\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -496.093009866075 SOC: 0.7604 Cumulative_SOC_deviation: 89.5605 Fuel Consumption: 137.8512\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.816\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -479.9163216701081 SOC: 0.7898 Cumulative_SOC_deviation: 85.1040 Fuel Consumption: 139.5005\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.089\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -521.1393039519452 SOC: 0.8215 Cumulative_SOC_deviation: 94.5773 Fuel Consumption: 142.8299\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.892\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -353.8176414565428 SOC: 0.6256 Cumulative_SOC_deviation: 56.5995 Fuel Consumption: 127.4196\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.857\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -621.7246640657397 SOC: 0.8026 Cumulative_SOC_deviation: 119.8731 Fuel Consumption: 142.2321\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.002\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -866.5475790810062 SOC: 0.4637 Cumulative_SOC_deviation: 187.6064 Fuel Consumption: 116.1221\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.746\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -791.9654196782492 SOC: 0.4635 Cumulative_SOC_deviation: 169.3371 Fuel Consumption: 114.6171\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.209\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -559.0097625971331 SOC: 0.5117 Cumulative_SOC_deviation: 110.2246 Fuel Consumption: 118.1115\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.860\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -635.3900350037057 SOC: 0.5130 Cumulative_SOC_deviation: 129.0104 Fuel Consumption: 119.3485\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.987\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1197.6486324240323 SOC: 0.3257 Cumulative_SOC_deviation: 272.8839 Fuel Consumption: 106.1131\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.618\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -890.0973982187361 SOC: 0.4245 Cumulative_SOC_deviation: 194.1587 Fuel Consumption: 113.4627\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.243\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -834.6108456666441 SOC: 0.4309 Cumulative_SOC_deviation: 180.1943 Fuel Consumption: 113.8337\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.333\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1229.8097226423022 SOC: 0.3173 Cumulative_SOC_deviation: 281.1406 Fuel Consumption: 105.2472\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.504\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1245.6471206923813 SOC: 0.2858 Cumulative_SOC_deviation: 285.6489 Fuel Consumption: 103.0517\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.531\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1392.569697328215 SOC: 0.2035 Cumulative_SOC_deviation: 323.7814 Fuel Consumption: 97.4441\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.220\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1492.6096959553663 SOC: 0.2258 Cumulative_SOC_deviation: 348.2270 Fuel Consumption: 99.7016\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.497\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -1468.0135940286996 SOC: 0.2072 Cumulative_SOC_deviation: 342.2275 Fuel Consumption: 99.1037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_modelChange\\DDPG_rewardfactor_comparison_final\\vehicle_model_variant.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.735\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -2213.478872887127 SOC: 0.0311 Cumulative_SOC_deviation: 531.3512 Fuel Consumption: 88.0742\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.131\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -1759.3641294877586 SOC: 0.0991 Cumulative_SOC_deviation: 417.0520 Fuel Consumption: 91.1563\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.459\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -1722.1019561592154 SOC: 0.0924 Cumulative_SOC_deviation: 407.8833 Fuel Consumption: 90.5688\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.698\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -2126.997224687977 SOC: 0.0109 Cumulative_SOC_deviation: 510.2281 Fuel Consumption: 86.0848\n",
      "\n",
      "battery power is 15515.997062127959(+) but condition is not avail\n",
      "elapsed_time: 75.405\n",
      "Episode: 48 Exploration P: 0.3033 Total reward: -2947.414711969484 SOC: -0.0001 Cumulative_SOC_deviation: 467.3701 Fuel Consumption: 80.3355\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.579\n",
      "Episode: 49 Exploration P: 0.2953 Total reward: -2032.1693440240294 SOC: 0.0330 Cumulative_SOC_deviation: 486.1913 Fuel Consumption: 87.4042\n",
      "\n",
      "battery power is 11234.27069825687(+) but condition is not avail\n",
      "elapsed_time: 61.982\n",
      "Episode: 50 Exploration P: 0.2893 Total reward: -2600.3822855290186 SOC: -0.0000 Cumulative_SOC_deviation: 384.8841 Fuel Consumption: 63.2469\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.417\n",
      "Episode: 51 Exploration P: 0.2817 Total reward: -2189.433500378715 SOC: 0.0212 Cumulative_SOC_deviation: 525.5099 Fuel Consumption: 87.3939\n",
      "\n",
      "battery power is 5493.065387096972(+) but condition is not avail\n",
      "elapsed_time: 66.221\n",
      "Episode: 52 Exploration P: 0.2756 Total reward: -2646.0024309159207 SOC: -0.0008 Cumulative_SOC_deviation: 395.0280 Fuel Consumption: 68.2945\n",
      "\n",
      "battery power is 10886.199985334762(+) but condition is not avail\n",
      "elapsed_time: 58.011\n",
      "Episode: 53 Exploration P: 0.2703 Total reward: -2506.117184948909 SOC: -0.0004 Cumulative_SOC_deviation: 362.8090 Fuel Consumption: 57.2836\n",
      "\n",
      "battery power is 504.22417234866225(+) but condition is not avail\n",
      "elapsed_time: 53.708\n",
      "Episode: 54 Exploration P: 0.2655 Total reward: -2301.0272534747246 SOC: -0.0001 Cumulative_SOC_deviation: 312.9696 Fuel Consumption: 51.6427\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_modelChange\\DDPG_rewardfactor_comparison_final\\vehicle_model_variant.py:252: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.506\n",
      "Episode: 55 Exploration P: 0.2586 Total reward: -872.758434156487 SOC: 0.5934 Cumulative_SOC_deviation: 186.8362 Fuel Consumption: 125.4135\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.703\n",
      "Episode: 56 Exploration P: 0.2519 Total reward: -287.3128365219051 SOC: 0.5762 Cumulative_SOC_deviation: 42.2426 Fuel Consumption: 118.3426\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.885\n",
      "Episode: 57 Exploration P: 0.2453 Total reward: -330.2741553329674 SOC: 0.5404 Cumulative_SOC_deviation: 54.1854 Fuel Consumption: 113.5325\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.754\n",
      "Episode: 58 Exploration P: 0.2390 Total reward: -739.0322257585187 SOC: 0.4084 Cumulative_SOC_deviation: 158.8671 Fuel Consumption: 103.5638\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.387\n",
      "Episode: 59 Exploration P: 0.2328 Total reward: -590.0392138243818 SOC: 0.5574 Cumulative_SOC_deviation: 117.8659 Fuel Consumption: 118.5758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.961\n",
      "Episode: 60 Exploration P: 0.2267 Total reward: -447.2731139727954 SOC: 0.5106 Cumulative_SOC_deviation: 83.9819 Fuel Consumption: 111.3456\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.073\n",
      "Episode: 61 Exploration P: 0.2209 Total reward: -642.8168601880197 SOC: 0.4571 Cumulative_SOC_deviation: 133.5845 Fuel Consumption: 108.4788\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.754\n",
      "Episode: 62 Exploration P: 0.2151 Total reward: -757.3347099089256 SOC: 0.4951 Cumulative_SOC_deviation: 160.8753 Fuel Consumption: 113.8337\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.671\n",
      "Episode: 63 Exploration P: 0.2096 Total reward: -690.4929508362396 SOC: 0.5053 Cumulative_SOC_deviation: 144.1583 Fuel Consumption: 113.8599\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.085\n",
      "Episode: 64 Exploration P: 0.2042 Total reward: -831.3176549902162 SOC: 0.3881 Cumulative_SOC_deviation: 181.8629 Fuel Consumption: 103.8661\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.340\n",
      "Episode: 65 Exploration P: 0.1989 Total reward: -763.2170982292557 SOC: 0.4660 Cumulative_SOC_deviation: 163.1204 Fuel Consumption: 110.7356\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.416\n",
      "Episode: 66 Exploration P: 0.1938 Total reward: -864.9942823792285 SOC: 0.4378 Cumulative_SOC_deviation: 189.8054 Fuel Consumption: 105.7727\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.836\n",
      "Episode: 67 Exploration P: 0.1888 Total reward: -918.3237397527766 SOC: 0.4795 Cumulative_SOC_deviation: 201.9264 Fuel Consumption: 110.6182\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.047\n",
      "Episode: 68 Exploration P: 0.1840 Total reward: -1002.7426418218441 SOC: 0.4330 Cumulative_SOC_deviation: 224.9228 Fuel Consumption: 103.0515\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.528\n",
      "Episode: 69 Exploration P: 0.1793 Total reward: -409.6331788647952 SOC: 0.5858 Cumulative_SOC_deviation: 74.2913 Fuel Consumption: 112.4680\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.334\n",
      "Episode: 70 Exploration P: 0.1747 Total reward: -499.62101098802356 SOC: 0.5560 Cumulative_SOC_deviation: 97.4427 Fuel Consumption: 109.8503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.563\n",
      "Episode: 71 Exploration P: 0.1702 Total reward: -1256.2389305426454 SOC: 0.2192 Cumulative_SOC_deviation: 291.2824 Fuel Consumption: 91.1093\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.439\n",
      "Episode: 72 Exploration P: 0.1659 Total reward: -431.8693906259446 SOC: 0.5531 Cumulative_SOC_deviation: 79.6471 Fuel Consumption: 113.2809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 120.207\n",
      "Episode: 73 Exploration P: 0.1617 Total reward: -990.7523919075442 SOC: 0.1995 Cumulative_SOC_deviation: 225.5768 Fuel Consumption: 88.4450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.597\n",
      "Episode: 74 Exploration P: 0.1576 Total reward: -427.11188810118364 SOC: 0.5717 Cumulative_SOC_deviation: 78.0297 Fuel Consumption: 114.9931\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 120.588\n",
      "Episode: 75 Exploration P: 0.1536 Total reward: -499.3965514832197 SOC: 0.5749 Cumulative_SOC_deviation: 93.8888 Fuel Consumption: 123.8414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.997\n",
      "Episode: 76 Exploration P: 0.1497 Total reward: -654.4102386151541 SOC: 0.5106 Cumulative_SOC_deviation: 134.8276 Fuel Consumption: 115.0997\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 117.761\n",
      "Episode: 77 Exploration P: 0.1459 Total reward: -587.0281180365689 SOC: 0.5336 Cumulative_SOC_deviation: 116.1924 Fuel Consumption: 122.2585\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.985\n",
      "Episode: 78 Exploration P: 0.1422 Total reward: -575.3789044925942 SOC: 0.4708 Cumulative_SOC_deviation: 115.3336 Fuel Consumption: 114.0445\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.449\n",
      "Episode: 79 Exploration P: 0.1386 Total reward: -1115.903653726549 SOC: 0.1970 Cumulative_SOC_deviation: 254.9107 Fuel Consumption: 96.2609\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.125\n",
      "Episode: 80 Exploration P: 0.1351 Total reward: -1369.840612268969 SOC: 0.4301 Cumulative_SOC_deviation: 313.0944 Fuel Consumption: 117.4632\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.681\n",
      "Episode: 81 Exploration P: 0.1318 Total reward: -1013.0674339295119 SOC: 0.4025 Cumulative_SOC_deviation: 226.8684 Fuel Consumption: 105.5938\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.031\n",
      "Episode: 82 Exploration P: 0.1285 Total reward: -1096.1930315029492 SOC: 0.4106 Cumulative_SOC_deviation: 246.5056 Fuel Consumption: 110.1706\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.906\n",
      "Episode: 83 Exploration P: 0.1252 Total reward: -1041.4053123064186 SOC: 0.4127 Cumulative_SOC_deviation: 233.9496 Fuel Consumption: 105.6071\n",
      "\n",
      "battery power is 1622.2170043185733(+) but condition is not avail\n",
      "elapsed_time: 86.011\n",
      "Episode: 84 Exploration P: 0.1227 Total reward: -2281.6248696779703 SOC: -0.0007 Cumulative_SOC_deviation: 306.1425 Fuel Consumption: 59.4890\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.487\n",
      "Episode: 85 Exploration P: 0.1197 Total reward: -1592.9962002253153 SOC: 0.4284 Cumulative_SOC_deviation: 370.7512 Fuel Consumption: 109.9916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.750\n",
      "Episode: 86 Exploration P: 0.1167 Total reward: -1149.1613536493055 SOC: 0.3804 Cumulative_SOC_deviation: 261.8484 Fuel Consumption: 101.7679\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.231\n",
      "Episode: 87 Exploration P: 0.1138 Total reward: -1195.6687942382198 SOC: 0.2402 Cumulative_SOC_deviation: 276.5504 Fuel Consumption: 89.4674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.926\n",
      "Episode: 88 Exploration P: 0.1110 Total reward: -1631.5641180393181 SOC: 0.4042 Cumulative_SOC_deviation: 381.3460 Fuel Consumption: 106.1803\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.889\n",
      "Episode: 89 Exploration P: 0.1083 Total reward: -1069.8152665379002 SOC: 0.4129 Cumulative_SOC_deviation: 241.6379 Fuel Consumption: 103.2639\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.545\n",
      "Episode: 90 Exploration P: 0.1056 Total reward: -1003.0025139339875 SOC: 0.4530 Cumulative_SOC_deviation: 224.3005 Fuel Consumption: 105.8006\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.332\n",
      "Episode: 91 Exploration P: 0.1030 Total reward: -1361.895523471794 SOC: 0.1074 Cumulative_SOC_deviation: 320.5774 Fuel Consumption: 79.5860\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.730\n",
      "Episode: 92 Exploration P: 0.1005 Total reward: -559.4498141873878 SOC: 0.3795 Cumulative_SOC_deviation: 115.5937 Fuel Consumption: 97.0750\n",
      "\n",
      "battery power is 3842.0652745216203(+) but condition is not avail\n",
      "elapsed_time: 92.654\n",
      "Episode: 93 Exploration P: 0.0984 Total reward: -2753.460072651662 SOC: -0.0005 Cumulative_SOC_deviation: 420.1198 Fuel Consumption: 75.3838\n",
      "\n",
      "battery power is 2169.47495504405(+) but condition is not avail\n",
      "elapsed_time: 51.109\n",
      "Episode: 94 Exploration P: 0.0972 Total reward: -1950.1240524387772 SOC: -0.0006 Cumulative_SOC_deviation: 232.2261 Fuel Consumption: 23.7641\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.837\n",
      "Episode: 95 Exploration P: 0.0949 Total reward: -2283.9110104219835 SOC: 0.0643 Cumulative_SOC_deviation: 551.3560 Fuel Consumption: 78.4871\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.703\n",
      "Episode: 96 Exploration P: 0.0926 Total reward: -2166.3194442864415 SOC: 0.1121 Cumulative_SOC_deviation: 521.5685 Fuel Consumption: 80.0456\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.741\n",
      "Episode: 97 Exploration P: 0.0903 Total reward: -742.2013283233824 SOC: 0.3316 Cumulative_SOC_deviation: 162.5552 Fuel Consumption: 91.9803\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.000\n",
      "Episode: 98 Exploration P: 0.0882 Total reward: -2374.9289356631425 SOC: 0.0752 Cumulative_SOC_deviation: 573.4911 Fuel Consumption: 80.9645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.315\n",
      "Episode: 99 Exploration P: 0.0860 Total reward: -675.7967992368035 SOC: 0.2957 Cumulative_SOC_deviation: 146.6546 Fuel Consumption: 89.1783\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.135\n",
      "Episode: 100 Exploration P: 0.0840 Total reward: -1631.8428197563483 SOC: 0.1294 Cumulative_SOC_deviation: 387.9740 Fuel Consumption: 79.9470\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.166\n",
      "Episode: 101 Exploration P: 0.0820 Total reward: -1734.790825319162 SOC: 0.0760 Cumulative_SOC_deviation: 414.2312 Fuel Consumption: 77.8659\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.075\n",
      "Episode: 102 Exploration P: 0.0800 Total reward: -1763.6897404500617 SOC: 0.1004 Cumulative_SOC_deviation: 421.2437 Fuel Consumption: 78.7151\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.743\n",
      "Episode: 103 Exploration P: 0.0781 Total reward: -2031.9734824451655 SOC: 0.0846 Cumulative_SOC_deviation: 487.7727 Fuel Consumption: 80.8827\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.777\n",
      "Episode: 104 Exploration P: 0.0763 Total reward: -1016.7037506973339 SOC: 0.4319 Cumulative_SOC_deviation: 228.9537 Fuel Consumption: 100.8891\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.957\n",
      "Episode: 105 Exploration P: 0.0745 Total reward: -1063.0627343503938 SOC: 0.4284 Cumulative_SOC_deviation: 240.3331 Fuel Consumption: 101.7303\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.453\n",
      "Episode: 106 Exploration P: 0.0727 Total reward: -1026.5732236936487 SOC: 0.4319 Cumulative_SOC_deviation: 231.7168 Fuel Consumption: 99.7059\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.064\n",
      "Episode: 107 Exploration P: 0.0710 Total reward: -1030.5798676438976 SOC: 0.3710 Cumulative_SOC_deviation: 233.7266 Fuel Consumption: 95.6734\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.722\n",
      "Episode: 108 Exploration P: 0.0694 Total reward: -1046.9846093332678 SOC: 0.3873 Cumulative_SOC_deviation: 237.5575 Fuel Consumption: 96.7548\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.799\n",
      "Episode: 109 Exploration P: 0.0678 Total reward: -1315.0694813465977 SOC: 0.3294 Cumulative_SOC_deviation: 305.9552 Fuel Consumption: 91.2487\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.605\n",
      "Episode: 110 Exploration P: 0.0662 Total reward: -1604.5439925563624 SOC: 0.3439 Cumulative_SOC_deviation: 377.7148 Fuel Consumption: 93.6848\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.184\n",
      "Episode: 111 Exploration P: 0.0647 Total reward: -1141.6406381550921 SOC: 0.4484 Cumulative_SOC_deviation: 260.2439 Fuel Consumption: 100.6648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.637\n",
      "Episode: 112 Exploration P: 0.0632 Total reward: -1483.842075708335 SOC: 0.3071 Cumulative_SOC_deviation: 348.3844 Fuel Consumption: 90.3046\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.523\n",
      "Episode: 113 Exploration P: 0.0618 Total reward: -1134.2408651439387 SOC: 0.3964 Cumulative_SOC_deviation: 258.8662 Fuel Consumption: 98.7761\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.089\n",
      "Episode: 114 Exploration P: 0.0604 Total reward: -355.53032701532663 SOC: 0.5602 Cumulative_SOC_deviation: 62.1954 Fuel Consumption: 106.7488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.613\n",
      "Episode: 115 Exploration P: 0.0590 Total reward: -348.62278382538636 SOC: 0.5806 Cumulative_SOC_deviation: 60.2455 Fuel Consumption: 107.6409\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.549\n",
      "Episode: 116 Exploration P: 0.0577 Total reward: -1087.4355030432075 SOC: 0.3182 Cumulative_SOC_deviation: 248.8997 Fuel Consumption: 91.8366\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.030\n",
      "Episode: 117 Exploration P: 0.0564 Total reward: -1045.5764830140831 SOC: 0.3224 Cumulative_SOC_deviation: 238.2982 Fuel Consumption: 92.3835\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.115\n",
      "Episode: 118 Exploration P: 0.0551 Total reward: -1533.7326382846725 SOC: 0.1401 Cumulative_SOC_deviation: 363.6716 Fuel Consumption: 79.0462\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.356\n",
      "Episode: 119 Exploration P: 0.0539 Total reward: -2152.428174237716 SOC: 0.1554 Cumulative_SOC_deviation: 517.6523 Fuel Consumption: 81.8188\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.146\n",
      "Episode: 120 Exploration P: 0.0527 Total reward: -511.8524386476778 SOC: 0.5142 Cumulative_SOC_deviation: 102.1107 Fuel Consumption: 103.4096\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.637\n",
      "Episode: 121 Exploration P: 0.0516 Total reward: -628.7204066051094 SOC: 0.4754 Cumulative_SOC_deviation: 132.2628 Fuel Consumption: 99.6692\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.777\n",
      "Episode: 122 Exploration P: 0.0504 Total reward: -1776.1044117125605 SOC: 0.1554 Cumulative_SOC_deviation: 424.0124 Fuel Consumption: 80.0549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.843\n",
      "Episode: 123 Exploration P: 0.0493 Total reward: -1546.578133297731 SOC: 0.2276 Cumulative_SOC_deviation: 365.6433 Fuel Consumption: 84.0048\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.873\n",
      "Episode: 124 Exploration P: 0.0483 Total reward: -1186.7155570242987 SOC: 0.4292 Cumulative_SOC_deviation: 272.1634 Fuel Consumption: 98.0621\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.516\n",
      "Episode: 125 Exploration P: 0.0472 Total reward: -565.0896243832697 SOC: 0.4267 Cumulative_SOC_deviation: 116.5689 Fuel Consumption: 98.8141\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.693\n",
      "Episode: 126 Exploration P: 0.0462 Total reward: -1041.0363438529114 SOC: 0.4002 Cumulative_SOC_deviation: 236.6854 Fuel Consumption: 94.2946\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.756\n",
      "Episode: 127 Exploration P: 0.0452 Total reward: -1035.004643555402 SOC: 0.4331 Cumulative_SOC_deviation: 234.4768 Fuel Consumption: 97.0972\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.346\n",
      "Episode: 128 Exploration P: 0.0443 Total reward: -1273.4858211428368 SOC: 0.1999 Cumulative_SOC_deviation: 297.8667 Fuel Consumption: 82.0189\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.777\n",
      "Episode: 129 Exploration P: 0.0434 Total reward: -1684.2981293683802 SOC: 0.2570 Cumulative_SOC_deviation: 399.0632 Fuel Consumption: 88.0454\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.337\n",
      "Episode: 130 Exploration P: 0.0425 Total reward: -1462.4048746814674 SOC: 0.2619 Cumulative_SOC_deviation: 344.0185 Fuel Consumption: 86.3307\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.236\n",
      "Episode: 131 Exploration P: 0.0416 Total reward: -1160.703539020755 SOC: 0.4621 Cumulative_SOC_deviation: 264.9931 Fuel Consumption: 100.7311\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.196\n",
      "Episode: 132 Exploration P: 0.0407 Total reward: -848.5273370462082 SOC: 0.3475 Cumulative_SOC_deviation: 189.2069 Fuel Consumption: 91.6998\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.268\n",
      "Episode: 133 Exploration P: 0.0399 Total reward: -1241.846288349331 SOC: 0.3122 Cumulative_SOC_deviation: 287.8767 Fuel Consumption: 90.3394\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.797\n",
      "Episode: 134 Exploration P: 0.0391 Total reward: -1381.876029318047 SOC: 0.2861 Cumulative_SOC_deviation: 323.4354 Fuel Consumption: 88.1346\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.361\n",
      "Episode: 135 Exploration P: 0.0383 Total reward: -1385.6067165816203 SOC: 0.3533 Cumulative_SOC_deviation: 323.3962 Fuel Consumption: 92.0218\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.525\n",
      "Episode: 136 Exploration P: 0.0375 Total reward: -1061.2423777711783 SOC: 0.4076 Cumulative_SOC_deviation: 241.1966 Fuel Consumption: 96.4561\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.631\n",
      "Episode: 137 Exploration P: 0.0368 Total reward: -1123.9836419639944 SOC: 0.4077 Cumulative_SOC_deviation: 256.8639 Fuel Consumption: 96.5280\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.967\n",
      "Episode: 138 Exploration P: 0.0361 Total reward: -1128.7519957408504 SOC: 0.3973 Cumulative_SOC_deviation: 258.2925 Fuel Consumption: 95.5819\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.971\n",
      "Episode: 139 Exploration P: 0.0354 Total reward: -1259.789287644548 SOC: 0.4189 Cumulative_SOC_deviation: 290.7946 Fuel Consumption: 96.6108\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.856\n",
      "Episode: 140 Exploration P: 0.0347 Total reward: -1429.1834989539982 SOC: 0.3474 Cumulative_SOC_deviation: 333.3641 Fuel Consumption: 95.7273\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.678\n",
      "Episode: 141 Exploration P: 0.0340 Total reward: -1194.477599185368 SOC: 0.4046 Cumulative_SOC_deviation: 273.8626 Fuel Consumption: 99.0270\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.698\n",
      "Episode: 142 Exploration P: 0.0333 Total reward: -1163.8839708813111 SOC: 0.3986 Cumulative_SOC_deviation: 266.5680 Fuel Consumption: 97.6120\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.308\n",
      "Episode: 143 Exploration P: 0.0327 Total reward: -1169.2672719290033 SOC: 0.4153 Cumulative_SOC_deviation: 267.4448 Fuel Consumption: 99.4880\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.922\n",
      "Episode: 144 Exploration P: 0.0321 Total reward: -1207.708155890509 SOC: 0.4059 Cumulative_SOC_deviation: 277.2147 Fuel Consumption: 98.8493\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.954\n",
      "Episode: 145 Exploration P: 0.0315 Total reward: -1866.5575716562641 SOC: 0.1837 Cumulative_SOC_deviation: 446.2512 Fuel Consumption: 81.5527\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.098\n",
      "Episode: 146 Exploration P: 0.0309 Total reward: -2067.0725684178856 SOC: 0.1064 Cumulative_SOC_deviation: 497.4447 Fuel Consumption: 77.2938\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.984\n",
      "Episode: 147 Exploration P: 0.0304 Total reward: -2180.5446367540735 SOC: 0.0546 Cumulative_SOC_deviation: 526.3732 Fuel Consumption: 75.0518\n",
      "\n",
      "battery power is 4760.427063623403(+) but condition is not avail\n",
      "elapsed_time: 78.407\n",
      "Episode: 148 Exploration P: 0.0299 Total reward: -2558.4007294547537 SOC: -0.0013 Cumulative_SOC_deviation: 361.1316 Fuel Consumption: 116.2804\n",
      "\n",
      "battery power is 4342.980858409079(+) but condition is not avail\n",
      "elapsed_time: 45.179\n",
      "Episode: 149 Exploration P: 0.0297 Total reward: -1733.6701754241076 SOC: -0.0006 Cumulative_SOC_deviation: 179.6158 Fuel Consumption: 17.6101\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.872\n",
      "Episode: 150 Exploration P: 0.0292 Total reward: -2039.9753438416774 SOC: 0.0649 Cumulative_SOC_deviation: 490.5539 Fuel Consumption: 77.7599\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.276\n",
      "Episode: 151 Exploration P: 0.0287 Total reward: -337.83764969796323 SOC: 0.4884 Cumulative_SOC_deviation: 58.7874 Fuel Consumption: 102.6882\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.060\n",
      "Episode: 152 Exploration P: 0.0282 Total reward: -1410.5835764200438 SOC: 0.2161 Cumulative_SOC_deviation: 331.3945 Fuel Consumption: 85.0055\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.568\n",
      "Episode: 153 Exploration P: 0.0277 Total reward: -1161.4679708141136 SOC: 0.3146 Cumulative_SOC_deviation: 267.9329 Fuel Consumption: 89.7363\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.566\n",
      "Episode: 154 Exploration P: 0.0272 Total reward: -1370.7228213730932 SOC: 0.3125 Cumulative_SOC_deviation: 320.1578 Fuel Consumption: 90.0918\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.852\n",
      "Episode: 155 Exploration P: 0.0267 Total reward: -1666.391199541532 SOC: 0.3108 Cumulative_SOC_deviation: 393.5176 Fuel Consumption: 92.3207\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.793\n",
      "Episode: 156 Exploration P: 0.0263 Total reward: -1001.0757735132584 SOC: 0.3066 Cumulative_SOC_deviation: 227.8547 Fuel Consumption: 89.6569\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.085\n",
      "Episode: 157 Exploration P: 0.0258 Total reward: -1157.9787258616743 SOC: 0.3332 Cumulative_SOC_deviation: 266.6274 Fuel Consumption: 91.4693\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.978\n",
      "Episode: 158 Exploration P: 0.0254 Total reward: -1138.0424480353274 SOC: 0.4587 Cumulative_SOC_deviation: 259.4645 Fuel Consumption: 100.1843\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.165\n",
      "Episode: 159 Exploration P: 0.0250 Total reward: -2206.3712390768833 SOC: 0.0610 Cumulative_SOC_deviation: 532.2093 Fuel Consumption: 77.5342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.695\n",
      "Episode: 160 Exploration P: 0.0246 Total reward: -2071.333103792415 SOC: 0.0514 Cumulative_SOC_deviation: 499.1825 Fuel Consumption: 74.6030\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.413\n",
      "Episode: 161 Exploration P: 0.0242 Total reward: -2272.7531131643823 SOC: -0.0002 Cumulative_SOC_deviation: 546.6186 Fuel Consumption: 86.2787\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.459\n",
      "Episode: 162 Exploration P: 0.0238 Total reward: -1918.0324999645654 SOC: 0.2314 Cumulative_SOC_deviation: 457.5230 Fuel Consumption: 87.9407\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.570\n",
      "Episode: 163 Exploration P: 0.0234 Total reward: -515.4955900470686 SOC: 0.5367 Cumulative_SOC_deviation: 101.6547 Fuel Consumption: 108.8768\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.847\n",
      "Episode: 164 Exploration P: 0.0231 Total reward: -573.408311954896 SOC: 0.5196 Cumulative_SOC_deviation: 117.1452 Fuel Consumption: 104.8274\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.477\n",
      "Episode: 165 Exploration P: 0.0227 Total reward: -574.9526316208537 SOC: 0.5344 Cumulative_SOC_deviation: 117.2449 Fuel Consumption: 105.9730\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.010\n",
      "Episode: 166 Exploration P: 0.0224 Total reward: -515.5699461167114 SOC: 0.5424 Cumulative_SOC_deviation: 102.1751 Fuel Consumption: 106.8697\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 122.998\n",
      "Episode: 167 Exploration P: 0.0220 Total reward: -513.5332687477955 SOC: 0.4371 Cumulative_SOC_deviation: 102.8094 Fuel Consumption: 102.2956\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.974\n",
      "Episode: 168 Exploration P: 0.0217 Total reward: -878.7015697811348 SOC: 1.0000 Cumulative_SOC_deviation: 181.9932 Fuel Consumption: 150.7288\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.641\n",
      "Episode: 169 Exploration P: 0.0214 Total reward: -347.8341415817085 SOC: 0.5998 Cumulative_SOC_deviation: 57.8048 Fuel Consumption: 116.6150\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.542\n",
      "Episode: 170 Exploration P: 0.0211 Total reward: -361.05052169633444 SOC: 0.5834 Cumulative_SOC_deviation: 61.5620 Fuel Consumption: 114.8025\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 119.080\n",
      "Episode: 171 Exploration P: 0.0208 Total reward: -1965.8372311136761 SOC: 1.0000 Cumulative_SOC_deviation: 432.9759 Fuel Consumption: 233.9338\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.663\n",
      "Episode: 172 Exploration P: 0.0205 Total reward: -2121.321752104979 SOC: 0.1726 Cumulative_SOC_deviation: 510.0483 Fuel Consumption: 81.1287\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 117.990\n",
      "Episode: 173 Exploration P: 0.0202 Total reward: -426.4412931308481 SOC: 0.5643 Cumulative_SOC_deviation: 78.6796 Fuel Consumption: 111.7230\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.596\n",
      "Episode: 174 Exploration P: 0.0199 Total reward: -428.2820896106452 SOC: 0.5735 Cumulative_SOC_deviation: 79.3590 Fuel Consumption: 110.8459\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.842\n",
      "Episode: 175 Exploration P: 0.0197 Total reward: -849.5172964468361 SOC: 0.2193 Cumulative_SOC_deviation: 191.0168 Fuel Consumption: 85.4501\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.865\n",
      "Episode: 176 Exploration P: 0.0194 Total reward: -1575.3590799845203 SOC: 0.2958 Cumulative_SOC_deviation: 372.0427 Fuel Consumption: 87.1882\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.439\n",
      "Episode: 177 Exploration P: 0.0191 Total reward: -1385.8501262000193 SOC: 0.2909 Cumulative_SOC_deviation: 324.7889 Fuel Consumption: 86.6945\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.269\n",
      "Episode: 178 Exploration P: 0.0189 Total reward: -687.4505397580614 SOC: 0.3432 Cumulative_SOC_deviation: 149.4088 Fuel Consumption: 89.8153\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.030\n",
      "Episode: 179 Exploration P: 0.0187 Total reward: -741.947462310248 SOC: 1.0000 Cumulative_SOC_deviation: 145.9468 Fuel Consumption: 158.1603\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.349\n",
      "Episode: 180 Exploration P: 0.0184 Total reward: -2406.1201084693457 SOC: 1.0000 Cumulative_SOC_deviation: 520.8584 Fuel Consumption: 322.6863\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.783\n",
      "Episode: 181 Exploration P: 0.0182 Total reward: -2418.584393666141 SOC: 1.0000 Cumulative_SOC_deviation: 523.3212 Fuel Consumption: 325.2995\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.872\n",
      "Episode: 182 Exploration P: 0.0180 Total reward: -2359.647152878085 SOC: 1.0000 Cumulative_SOC_deviation: 512.7111 Fuel Consumption: 308.8026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.646\n",
      "Episode: 183 Exploration P: 0.0178 Total reward: -2402.6576202953197 SOC: 1.0000 Cumulative_SOC_deviation: 519.8745 Fuel Consumption: 323.1596\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.621\n",
      "Episode: 184 Exploration P: 0.0175 Total reward: -2365.032950492208 SOC: 1.0000 Cumulative_SOC_deviation: 512.4828 Fuel Consumption: 315.1019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.517\n",
      "Episode: 185 Exploration P: 0.0173 Total reward: -2326.2130574723556 SOC: 1.0000 Cumulative_SOC_deviation: 507.0719 Fuel Consumption: 297.9255\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.420\n",
      "Episode: 186 Exploration P: 0.0171 Total reward: -2389.6537576742185 SOC: 1.0000 Cumulative_SOC_deviation: 516.8629 Fuel Consumption: 322.2023\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.652\n",
      "Episode: 187 Exploration P: 0.0169 Total reward: -2365.4957109375277 SOC: 1.0000 Cumulative_SOC_deviation: 512.6565 Fuel Consumption: 314.8697\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.323\n",
      "Episode: 188 Exploration P: 0.0168 Total reward: -2329.1127140580143 SOC: 1.0000 Cumulative_SOC_deviation: 503.0121 Fuel Consumption: 317.0644\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.033\n",
      "Episode: 189 Exploration P: 0.0166 Total reward: -1567.3831779011764 SOC: 1.0000 Cumulative_SOC_deviation: 326.7022 Fuel Consumption: 260.5744\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.978\n",
      "Episode: 190 Exploration P: 0.0164 Total reward: -234.04167745709702 SOC: 0.6459 Cumulative_SOC_deviation: 29.9857 Fuel Consumption: 114.0989\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.589\n",
      "Episode: 191 Exploration P: 0.0162 Total reward: -181.6283951245191 SOC: 0.6236 Cumulative_SOC_deviation: 17.5451 Fuel Consumption: 111.4479\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 117.567\n",
      "Episode: 192 Exploration P: 0.0161 Total reward: -1905.8032254517689 SOC: 1.0000 Cumulative_SOC_deviation: 405.9127 Fuel Consumption: 282.1525\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.883\n",
      "Episode: 193 Exploration P: 0.0159 Total reward: -391.31703157675605 SOC: 0.6111 Cumulative_SOC_deviation: 69.3842 Fuel Consumption: 113.7802\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.151\n",
      "Episode: 194 Exploration P: 0.0157 Total reward: -275.18151299409925 SOC: 0.5812 Cumulative_SOC_deviation: 41.6803 Fuel Consumption: 108.4603\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.082\n",
      "Episode: 195 Exploration P: 0.0156 Total reward: -621.0688437774895 SOC: 1.0000 Cumulative_SOC_deviation: 115.9870 Fuel Consumption: 157.1209\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.962\n",
      "Episode: 196 Exploration P: 0.0154 Total reward: -2312.9167180415266 SOC: 1.0000 Cumulative_SOC_deviation: 504.3577 Fuel Consumption: 295.4861\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.946\n",
      "Episode: 197 Exploration P: 0.0153 Total reward: -2386.8171796608312 SOC: 1.0000 Cumulative_SOC_deviation: 518.6777 Fuel Consumption: 312.1064\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.463\n",
      "Episode: 198 Exploration P: 0.0151 Total reward: -1959.5191037761563 SOC: 1.0000 Cumulative_SOC_deviation: 418.8984 Fuel Consumption: 283.9256\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.515\n",
      "Episode: 199 Exploration P: 0.0150 Total reward: -2438.861673996194 SOC: 1.0000 Cumulative_SOC_deviation: 524.0766 Fuel Consumption: 342.5552\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.005\n",
      "Episode: 200 Exploration P: 0.0149 Total reward: -2199.4088823991538 SOC: 1.0000 Cumulative_SOC_deviation: 469.1037 Fuel Consumption: 322.9942\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 5\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.101\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -2609.2620502188756 SOC: 1.0000 Cumulative_SOC_deviation: 484.1783 Fuel Consumption: 188.3703\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.964\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2587.059046458765 SOC: 1.0000 Cumulative_SOC_deviation: 481.2489 Fuel Consumption: 180.8146\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.503\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2625.6348977618213 SOC: 0.9994 Cumulative_SOC_deviation: 486.9210 Fuel Consumption: 191.0298\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.943\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -2598.3966623033407 SOC: 1.0000 Cumulative_SOC_deviation: 481.3043 Fuel Consumption: 191.8750\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.924\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -2604.141512435289 SOC: 0.9993 Cumulative_SOC_deviation: 483.6263 Fuel Consumption: 186.0098\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.059\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -2508.7858595644516 SOC: 1.0000 Cumulative_SOC_deviation: 465.6932 Fuel Consumption: 180.3198\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.361\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2590.820558425093 SOC: 1.0000 Cumulative_SOC_deviation: 481.3044 Fuel Consumption: 184.2987\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.224\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -2507.244215771914 SOC: 0.9984 Cumulative_SOC_deviation: 466.9496 Fuel Consumption: 172.4961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.431\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2393.0148349444075 SOC: 0.9997 Cumulative_SOC_deviation: 443.3636 Fuel Consumption: 176.1967\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.157\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2401.8234906039174 SOC: 1.0000 Cumulative_SOC_deviation: 445.6449 Fuel Consumption: 173.5991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.257\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2429.5485560935276 SOC: 1.0000 Cumulative_SOC_deviation: 452.8082 Fuel Consumption: 165.5074\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.472\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2347.2898012571636 SOC: 0.9983 Cumulative_SOC_deviation: 436.6204 Fuel Consumption: 164.1879\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.197\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -2269.82422094821 SOC: 1.0000 Cumulative_SOC_deviation: 421.1767 Fuel Consumption: 163.9406\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.138\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2266.4383484228806 SOC: 0.9969 Cumulative_SOC_deviation: 420.7119 Fuel Consumption: 162.8788\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.405\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2282.683876153427 SOC: 0.9994 Cumulative_SOC_deviation: 424.4702 Fuel Consumption: 160.3328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.269\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -2151.2603096171283 SOC: 0.9980 Cumulative_SOC_deviation: 398.1773 Fuel Consumption: 160.3740\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.790\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -1844.516327297754 SOC: 0.9999 Cumulative_SOC_deviation: 337.6778 Fuel Consumption: 156.1272\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.583\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -1842.168625995572 SOC: 0.9987 Cumulative_SOC_deviation: 338.0329 Fuel Consumption: 152.0040\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.580\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -1868.9437006909059 SOC: 0.9990 Cumulative_SOC_deviation: 342.6849 Fuel Consumption: 155.5190\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.282\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -1671.5153040406788 SOC: 0.9984 Cumulative_SOC_deviation: 303.5415 Fuel Consumption: 153.8079\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.280\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -1385.729872288067 SOC: 0.9776 Cumulative_SOC_deviation: 246.4174 Fuel Consumption: 153.6429\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.097\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1354.089458082226 SOC: 0.9782 Cumulative_SOC_deviation: 240.1408 Fuel Consumption: 153.3852\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.989\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1254.3252842887193 SOC: 0.9636 Cumulative_SOC_deviation: 220.4704 Fuel Consumption: 151.9731\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.210\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1502.5453175524888 SOC: 0.9728 Cumulative_SOC_deviation: 270.0650 Fuel Consumption: 152.2204\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.001\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1200.339890314471 SOC: 0.9679 Cumulative_SOC_deviation: 209.5600 Fuel Consumption: 152.5400\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.445\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1216.8683519158633 SOC: 0.9611 Cumulative_SOC_deviation: 212.9234 Fuel Consumption: 152.2514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.713\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -979.3155856587388 SOC: 0.9337 Cumulative_SOC_deviation: 165.7468 Fuel Consumption: 150.5815\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.288\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -578.3828389660208 SOC: 0.7870 Cumulative_SOC_deviation: 87.5476 Fuel Consumption: 140.6447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.046\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -395.2722700538398 SOC: 0.7211 Cumulative_SOC_deviation: 52.0615 Fuel Consumption: 134.9650\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.962\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -931.0643230174824 SOC: 0.8819 Cumulative_SOC_deviation: 156.7253 Fuel Consumption: 147.4376\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.726\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -368.5199755723633 SOC: 0.6403 Cumulative_SOC_deviation: 47.8902 Fuel Consumption: 129.0689\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.176\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -775.0065805577369 SOC: 0.5519 Cumulative_SOC_deviation: 130.7255 Fuel Consumption: 121.3791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.925\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -509.4805231279965 SOC: 0.6537 Cumulative_SOC_deviation: 75.7216 Fuel Consumption: 130.8727\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.562\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -925.9797395140196 SOC: 0.5246 Cumulative_SOC_deviation: 161.1881 Fuel Consumption: 120.0391\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.449\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -934.0213174080408 SOC: 0.5272 Cumulative_SOC_deviation: 162.6377 Fuel Consumption: 120.8328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.107\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -749.2056316163903 SOC: 0.5204 Cumulative_SOC_deviation: 125.5921 Fuel Consumption: 121.2451\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.045\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -925.5128286926106 SOC: 0.5021 Cumulative_SOC_deviation: 161.3339 Fuel Consumption: 118.8434\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.632\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1819.4020229416822 SOC: 0.2237 Cumulative_SOC_deviation: 344.0287 Fuel Consumption: 99.2583\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.672\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1808.9209811329838 SOC: 0.2760 Cumulative_SOC_deviation: 341.0481 Fuel Consumption: 103.6804\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.693\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1634.8365260227554 SOC: 0.2557 Cumulative_SOC_deviation: 306.8538 Fuel Consumption: 100.5674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.089\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1579.8075058462557 SOC: 0.2568 Cumulative_SOC_deviation: 295.7016 Fuel Consumption: 101.2993\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.645\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1450.5858635828795 SOC: 0.2872 Cumulative_SOC_deviation: 269.4120 Fuel Consumption: 103.5258\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.275\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -1459.8555144308361 SOC: 0.3074 Cumulative_SOC_deviation: 270.9443 Fuel Consumption: 105.1339\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.321\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -2089.7165442514224 SOC: 0.1652 Cumulative_SOC_deviation: 398.8359 Fuel Consumption: 95.5372\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.669\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -2317.776886362148 SOC: 0.0736 Cumulative_SOC_deviation: 445.7034 Fuel Consumption: 89.2597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.269\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -2455.637462121732 SOC: 0.0499 Cumulative_SOC_deviation: 473.3147 Fuel Consumption: 89.0638\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.507\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -2667.5578940239766 SOC: 0.0612 Cumulative_SOC_deviation: 515.6679 Fuel Consumption: 89.2184\n",
      "\n",
      "battery power is 4306.664468358059(+) but condition is not avail\n",
      "elapsed_time: 79.573\n",
      "Episode: 48 Exploration P: 0.3030 Total reward: -3525.3324484926543 SOC: -0.0003 Cumulative_SOC_deviation: 488.8492 Fuel Consumption: 84.0890\n",
      "\n",
      "battery power is 7412.919352546885(+) but condition is not avail\n",
      "elapsed_time: 70.165\n",
      "Episode: 49 Exploration P: 0.2960 Total reward: -3311.6494015709504 SOC: -0.0008 Cumulative_SOC_deviation: 448.2367 Fuel Consumption: 73.4710\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.558\n",
      "Episode: 50 Exploration P: 0.2882 Total reward: -2368.0159422409606 SOC: 0.0395 Cumulative_SOC_deviation: 456.0440 Fuel Consumption: 87.7959\n",
      "\n",
      "battery power is 12835.389088941321(+) but condition is not avail\n",
      "elapsed_time: 61.759\n",
      "Episode: 51 Exploration P: 0.2829 Total reward: -2798.731225266538 SOC: -0.0008 Cumulative_SOC_deviation: 349.3849 Fuel Consumption: 54.8114\n",
      "\n",
      "battery power is 19719.300095205464(+) but condition is not avail\n",
      "elapsed_time: 81.905\n",
      "Episode: 52 Exploration P: 0.2766 Total reward: -3052.363146147866 SOC: -0.0008 Cumulative_SOC_deviation: 396.8851 Fuel Consumption: 70.9428\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 122.815\n",
      "Episode: 53 Exploration P: 0.2694 Total reward: -247.3618083321838 SOC: 0.5803 Cumulative_SOC_deviation: 26.2399 Fuel Consumption: 116.1621\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 137.321\n",
      "Episode: 54 Exploration P: 0.2623 Total reward: -303.25245264281443 SOC: 0.5735 Cumulative_SOC_deviation: 37.6611 Fuel Consumption: 114.9469\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.975\n",
      "Episode: 55 Exploration P: 0.2555 Total reward: -391.0511474520102 SOC: 0.5845 Cumulative_SOC_deviation: 54.8349 Fuel Consumption: 116.8769\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.823\n",
      "Episode: 56 Exploration P: 0.2488 Total reward: -324.2043523754587 SOC: 0.5765 Cumulative_SOC_deviation: 41.9419 Fuel Consumption: 114.4949\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.649\n",
      "Episode: 57 Exploration P: 0.2424 Total reward: -670.4169178956549 SOC: 0.5576 Cumulative_SOC_deviation: 110.2784 Fuel Consumption: 119.0249\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.408\n",
      "Episode: 58 Exploration P: 0.2361 Total reward: -341.36167789383035 SOC: 0.5684 Cumulative_SOC_deviation: 45.6911 Fuel Consumption: 112.9061\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.322\n",
      "Episode: 59 Exploration P: 0.2300 Total reward: -420.142890685848 SOC: 0.5346 Cumulative_SOC_deviation: 61.9436 Fuel Consumption: 110.4249\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.003\n",
      "Episode: 60 Exploration P: 0.2240 Total reward: -530.7259033489707 SOC: 0.5509 Cumulative_SOC_deviation: 83.9518 Fuel Consumption: 110.9667\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.255\n",
      "Episode: 61 Exploration P: 0.2182 Total reward: -707.1487274988837 SOC: 0.5004 Cumulative_SOC_deviation: 119.1184 Fuel Consumption: 111.5568\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.165\n",
      "Episode: 62 Exploration P: 0.2126 Total reward: -872.103195224447 SOC: 0.4545 Cumulative_SOC_deviation: 153.0633 Fuel Consumption: 106.7866\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.020\n",
      "Episode: 63 Exploration P: 0.2071 Total reward: -609.4314887325127 SOC: 0.5265 Cumulative_SOC_deviation: 99.2337 Fuel Consumption: 113.2630\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.214\n",
      "Episode: 64 Exploration P: 0.2017 Total reward: -520.0059631270884 SOC: 0.5483 Cumulative_SOC_deviation: 80.9591 Fuel Consumption: 115.2107\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.194\n",
      "Episode: 65 Exploration P: 0.1965 Total reward: -443.63555750143183 SOC: 0.5627 Cumulative_SOC_deviation: 65.7572 Fuel Consumption: 114.8495\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.038\n",
      "Episode: 66 Exploration P: 0.1915 Total reward: -596.7449223708278 SOC: 0.5234 Cumulative_SOC_deviation: 96.7932 Fuel Consumption: 112.7791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.112\n",
      "Episode: 67 Exploration P: 0.1866 Total reward: -632.5509289069853 SOC: 0.5178 Cumulative_SOC_deviation: 104.4782 Fuel Consumption: 110.1600\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.539\n",
      "Episode: 68 Exploration P: 0.1818 Total reward: -698.7921099968786 SOC: 0.4731 Cumulative_SOC_deviation: 118.3076 Fuel Consumption: 107.2543\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.900\n",
      "Episode: 69 Exploration P: 0.1771 Total reward: -900.5439248128986 SOC: 0.5025 Cumulative_SOC_deviation: 157.5130 Fuel Consumption: 112.9791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.752\n",
      "Episode: 70 Exploration P: 0.1726 Total reward: -933.0047258953714 SOC: 0.4619 Cumulative_SOC_deviation: 164.1642 Fuel Consumption: 112.1836\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.154\n",
      "Episode: 71 Exploration P: 0.1682 Total reward: -1968.6408762672038 SOC: 0.2421 Cumulative_SOC_deviation: 374.5310 Fuel Consumption: 95.9861\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.802\n",
      "Episode: 72 Exploration P: 0.1639 Total reward: -2325.9793912577707 SOC: 0.2240 Cumulative_SOC_deviation: 446.3163 Fuel Consumption: 94.3978\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.277\n",
      "Episode: 73 Exploration P: 0.1598 Total reward: -2146.9797893949817 SOC: 0.2909 Cumulative_SOC_deviation: 410.2467 Fuel Consumption: 95.7465\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.495\n",
      "Episode: 74 Exploration P: 0.1557 Total reward: -1307.9118526388872 SOC: 0.4386 Cumulative_SOC_deviation: 240.1049 Fuel Consumption: 107.3872\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.491\n",
      "Episode: 75 Exploration P: 0.1518 Total reward: -1227.408508755519 SOC: 0.4286 Cumulative_SOC_deviation: 223.3904 Fuel Consumption: 110.4566\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.024\n",
      "Episode: 76 Exploration P: 0.1479 Total reward: -950.509048315527 SOC: 0.4610 Cumulative_SOC_deviation: 167.9200 Fuel Consumption: 110.9090\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.810\n",
      "Episode: 77 Exploration P: 0.1442 Total reward: -1085.6382026626275 SOC: 0.4861 Cumulative_SOC_deviation: 194.4412 Fuel Consumption: 113.4322\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.990\n",
      "Episode: 78 Exploration P: 0.1405 Total reward: -907.9674852782335 SOC: 0.4131 Cumulative_SOC_deviation: 159.5707 Fuel Consumption: 110.1140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.120\n",
      "Episode: 79 Exploration P: 0.1370 Total reward: -891.3455807553494 SOC: 0.4907 Cumulative_SOC_deviation: 155.3973 Fuel Consumption: 114.3591\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.128\n",
      "Episode: 80 Exploration P: 0.1336 Total reward: -1139.46129047005 SOC: 0.4443 Cumulative_SOC_deviation: 205.5801 Fuel Consumption: 111.5608\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.917\n",
      "Episode: 81 Exploration P: 0.1302 Total reward: -1262.8554197946523 SOC: 0.3882 Cumulative_SOC_deviation: 231.2584 Fuel Consumption: 106.5636\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.167\n",
      "Episode: 82 Exploration P: 0.1270 Total reward: -1497.0442256097106 SOC: 0.3649 Cumulative_SOC_deviation: 279.1287 Fuel Consumption: 101.4006\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.868\n",
      "Episode: 83 Exploration P: 0.1238 Total reward: -1300.2900650525403 SOC: 0.4340 Cumulative_SOC_deviation: 237.3519 Fuel Consumption: 113.5303\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.654\n",
      "Episode: 84 Exploration P: 0.1207 Total reward: -1173.3270550253612 SOC: 0.4432 Cumulative_SOC_deviation: 213.2421 Fuel Consumption: 107.1163\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.840\n",
      "Episode: 85 Exploration P: 0.1177 Total reward: -1085.765553706069 SOC: 0.4236 Cumulative_SOC_deviation: 195.6834 Fuel Consumption: 107.3484\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.678\n",
      "Episode: 86 Exploration P: 0.1148 Total reward: -1443.769353758394 SOC: 0.3734 Cumulative_SOC_deviation: 268.4396 Fuel Consumption: 101.5716\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.744\n",
      "Episode: 87 Exploration P: 0.1120 Total reward: -1656.9467052726454 SOC: 0.3185 Cumulative_SOC_deviation: 311.6035 Fuel Consumption: 98.9294\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.558\n",
      "Episode: 88 Exploration P: 0.1092 Total reward: -1612.8869626548096 SOC: 0.3537 Cumulative_SOC_deviation: 301.5042 Fuel Consumption: 105.3659\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.060\n",
      "Episode: 89 Exploration P: 0.1065 Total reward: -1754.3387373705577 SOC: 0.2990 Cumulative_SOC_deviation: 330.3890 Fuel Consumption: 102.3936\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.584\n",
      "Episode: 90 Exploration P: 0.1039 Total reward: -2160.5476062209596 SOC: 0.3042 Cumulative_SOC_deviation: 410.8985 Fuel Consumption: 106.0549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.333\n",
      "Episode: 91 Exploration P: 0.1014 Total reward: -1606.3954521013109 SOC: 0.3416 Cumulative_SOC_deviation: 299.7300 Fuel Consumption: 107.7455\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.759\n",
      "Episode: 92 Exploration P: 0.0989 Total reward: -1278.8279235360833 SOC: 0.4764 Cumulative_SOC_deviation: 231.9750 Fuel Consumption: 118.9528\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.543\n",
      "Episode: 93 Exploration P: 0.0965 Total reward: -933.5658538654643 SOC: 0.4342 Cumulative_SOC_deviation: 163.9044 Fuel Consumption: 114.0441\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.772\n",
      "Episode: 94 Exploration P: 0.0941 Total reward: -1288.1866812846406 SOC: 0.3934 Cumulative_SOC_deviation: 236.1424 Fuel Consumption: 107.4749\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.646\n",
      "Episode: 95 Exploration P: 0.0918 Total reward: -1353.8667589307008 SOC: 0.4262 Cumulative_SOC_deviation: 249.7456 Fuel Consumption: 105.1389\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.860\n",
      "Episode: 96 Exploration P: 0.0896 Total reward: -1243.227496209215 SOC: 0.3825 Cumulative_SOC_deviation: 227.3787 Fuel Consumption: 106.3342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.741\n",
      "Episode: 97 Exploration P: 0.0875 Total reward: -1578.6546688597443 SOC: 0.3496 Cumulative_SOC_deviation: 295.6754 Fuel Consumption: 100.2776\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.489\n",
      "Episode: 98 Exploration P: 0.0854 Total reward: -1402.7179155207766 SOC: 0.3715 Cumulative_SOC_deviation: 260.0519 Fuel Consumption: 102.4585\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.045\n",
      "Episode: 99 Exploration P: 0.0833 Total reward: -1195.1967591550201 SOC: 0.4282 Cumulative_SOC_deviation: 216.2620 Fuel Consumption: 113.8868\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.058\n",
      "Episode: 100 Exploration P: 0.0813 Total reward: -1583.7183345279657 SOC: 0.3372 Cumulative_SOC_deviation: 295.7575 Fuel Consumption: 104.9308\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.172\n",
      "Episode: 101 Exploration P: 0.0794 Total reward: -1313.7554232034513 SOC: 0.4390 Cumulative_SOC_deviation: 239.8844 Fuel Consumption: 114.3332\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.137\n",
      "Episode: 102 Exploration P: 0.0775 Total reward: -958.7399116882104 SOC: 0.3904 Cumulative_SOC_deviation: 169.4938 Fuel Consumption: 111.2708\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.382\n",
      "Episode: 103 Exploration P: 0.0757 Total reward: -1216.8267365856664 SOC: 0.4156 Cumulative_SOC_deviation: 220.6138 Fuel Consumption: 113.7577\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.401\n",
      "Episode: 104 Exploration P: 0.0739 Total reward: -1278.2719573213672 SOC: 0.4157 Cumulative_SOC_deviation: 233.2757 Fuel Consumption: 111.8936\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.553\n",
      "Episode: 105 Exploration P: 0.0722 Total reward: -1142.937025480518 SOC: 0.3974 Cumulative_SOC_deviation: 206.3140 Fuel Consumption: 111.3672\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.874\n",
      "Episode: 106 Exploration P: 0.0705 Total reward: -1244.700187854095 SOC: 0.4756 Cumulative_SOC_deviation: 225.1463 Fuel Consumption: 118.9685\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.931\n",
      "Episode: 107 Exploration P: 0.0689 Total reward: -1036.1562503256846 SOC: 0.4383 Cumulative_SOC_deviation: 184.0662 Fuel Consumption: 115.8250\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.968\n",
      "Episode: 108 Exploration P: 0.0673 Total reward: -870.0696459389974 SOC: 0.4734 Cumulative_SOC_deviation: 150.3321 Fuel Consumption: 118.4090\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.134\n",
      "Episode: 109 Exploration P: 0.0657 Total reward: -995.687641115129 SOC: 0.4179 Cumulative_SOC_deviation: 176.2779 Fuel Consumption: 114.2981\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.360\n",
      "Episode: 110 Exploration P: 0.0642 Total reward: -1107.0262830636807 SOC: 0.4488 Cumulative_SOC_deviation: 197.9437 Fuel Consumption: 117.3077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.270\n",
      "Episode: 111 Exploration P: 0.0627 Total reward: -933.8092318865101 SOC: 0.4373 Cumulative_SOC_deviation: 163.5197 Fuel Consumption: 116.2107\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.244\n",
      "Episode: 112 Exploration P: 0.0613 Total reward: -1090.9797228132238 SOC: 0.4975 Cumulative_SOC_deviation: 193.9340 Fuel Consumption: 121.3095\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.922\n",
      "Episode: 113 Exploration P: 0.0599 Total reward: -967.0004537827649 SOC: 0.4837 Cumulative_SOC_deviation: 169.4607 Fuel Consumption: 119.6970\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.220\n",
      "Episode: 114 Exploration P: 0.0586 Total reward: -888.5952307673234 SOC: 0.4854 Cumulative_SOC_deviation: 153.7837 Fuel Consumption: 119.6767\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.336\n",
      "Episode: 115 Exploration P: 0.0573 Total reward: -1258.4107790152411 SOC: 0.3902 Cumulative_SOC_deviation: 229.0956 Fuel Consumption: 112.9328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.070\n",
      "Episode: 116 Exploration P: 0.0560 Total reward: -1537.0846049422432 SOC: 0.3416 Cumulative_SOC_deviation: 285.9275 Fuel Consumption: 107.4471\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.176\n",
      "Episode: 117 Exploration P: 0.0547 Total reward: -2099.924781578702 SOC: 0.2754 Cumulative_SOC_deviation: 400.1078 Fuel Consumption: 99.3857\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.091\n",
      "Episode: 118 Exploration P: 0.0535 Total reward: -1883.922635130722 SOC: 0.3210 Cumulative_SOC_deviation: 355.9090 Fuel Consumption: 104.3776\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.108\n",
      "Episode: 119 Exploration P: 0.0523 Total reward: -1596.6707774884621 SOC: 0.3761 Cumulative_SOC_deviation: 297.5599 Fuel Consumption: 108.8712\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.018\n",
      "Episode: 120 Exploration P: 0.0512 Total reward: -1589.084297774208 SOC: 0.3831 Cumulative_SOC_deviation: 295.9006 Fuel Consumption: 109.5811\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.156\n",
      "Episode: 121 Exploration P: 0.0501 Total reward: -1419.0380538696506 SOC: 0.4228 Cumulative_SOC_deviation: 260.0737 Fuel Consumption: 118.6698\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.214\n",
      "Episode: 122 Exploration P: 0.0490 Total reward: -1105.2324170344648 SOC: 0.4110 Cumulative_SOC_deviation: 199.1598 Fuel Consumption: 109.4333\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.024\n",
      "Episode: 123 Exploration P: 0.0479 Total reward: -1468.4693068312974 SOC: 0.3936 Cumulative_SOC_deviation: 272.2767 Fuel Consumption: 107.0858\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.680\n",
      "Episode: 124 Exploration P: 0.0469 Total reward: -1108.7164922622105 SOC: 0.4591 Cumulative_SOC_deviation: 199.3383 Fuel Consumption: 112.0251\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.314\n",
      "Episode: 125 Exploration P: 0.0459 Total reward: -995.7914732496763 SOC: 0.4901 Cumulative_SOC_deviation: 175.4324 Fuel Consumption: 118.6293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.320\n",
      "Episode: 126 Exploration P: 0.0449 Total reward: -878.003995669026 SOC: 0.4804 Cumulative_SOC_deviation: 151.6546 Fuel Consumption: 119.7312\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.694\n",
      "Episode: 127 Exploration P: 0.0440 Total reward: -863.2217444474921 SOC: 0.4450 Cumulative_SOC_deviation: 149.3774 Fuel Consumption: 116.3346\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.157\n",
      "Episode: 128 Exploration P: 0.0431 Total reward: -926.7550692264302 SOC: 0.4877 Cumulative_SOC_deviation: 161.4170 Fuel Consumption: 119.6700\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.512\n",
      "Episode: 129 Exploration P: 0.0422 Total reward: -889.5543793372663 SOC: 0.4745 Cumulative_SOC_deviation: 154.2621 Fuel Consumption: 118.2437\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.703\n",
      "Episode: 130 Exploration P: 0.0413 Total reward: -1017.8193218649276 SOC: 0.4621 Cumulative_SOC_deviation: 180.3903 Fuel Consumption: 115.8679\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.433\n",
      "Episode: 131 Exploration P: 0.0405 Total reward: -1086.654764471562 SOC: 0.4513 Cumulative_SOC_deviation: 194.3778 Fuel Consumption: 114.7660\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.869\n",
      "Episode: 132 Exploration P: 0.0396 Total reward: -878.960312536427 SOC: 0.4871 Cumulative_SOC_deviation: 152.4903 Fuel Consumption: 116.5089\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.541\n",
      "Episode: 133 Exploration P: 0.0388 Total reward: -867.9224099295759 SOC: 0.4804 Cumulative_SOC_deviation: 149.6838 Fuel Consumption: 119.5034\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.580\n",
      "Episode: 134 Exploration P: 0.0380 Total reward: -1165.2965392679491 SOC: 0.4309 Cumulative_SOC_deviation: 210.0814 Fuel Consumption: 114.8894\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.287\n",
      "Episode: 135 Exploration P: 0.0373 Total reward: -1078.7175874192387 SOC: 0.4465 Cumulative_SOC_deviation: 192.3220 Fuel Consumption: 117.1073\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.359\n",
      "Episode: 136 Exploration P: 0.0365 Total reward: -969.1213196360237 SOC: 0.4555 Cumulative_SOC_deviation: 170.3712 Fuel Consumption: 117.2654\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.989\n",
      "Episode: 137 Exploration P: 0.0358 Total reward: -1140.438098276824 SOC: 0.4241 Cumulative_SOC_deviation: 205.1678 Fuel Consumption: 114.5990\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.856\n",
      "Episode: 138 Exploration P: 0.0351 Total reward: -1141.8981596605615 SOC: 0.4161 Cumulative_SOC_deviation: 205.5422 Fuel Consumption: 114.1873\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.640\n",
      "Episode: 139 Exploration P: 0.0344 Total reward: -1094.6033261680882 SOC: 0.4764 Cumulative_SOC_deviation: 195.1533 Fuel Consumption: 118.8368\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.873\n",
      "Episode: 140 Exploration P: 0.0338 Total reward: -1060.512113187988 SOC: 0.4810 Cumulative_SOC_deviation: 188.2537 Fuel Consumption: 119.2436\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.659\n",
      "Episode: 141 Exploration P: 0.0331 Total reward: -909.9263068000745 SOC: 0.4931 Cumulative_SOC_deviation: 158.1067 Fuel Consumption: 119.3928\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.964\n",
      "Episode: 142 Exploration P: 0.0325 Total reward: -1041.304290297435 SOC: 0.4463 Cumulative_SOC_deviation: 185.0323 Fuel Consumption: 116.1426\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.570\n",
      "Episode: 143 Exploration P: 0.0319 Total reward: -1014.0775597250159 SOC: 0.4197 Cumulative_SOC_deviation: 180.1248 Fuel Consumption: 113.4538\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.681\n",
      "Episode: 144 Exploration P: 0.0313 Total reward: -1102.2746957945726 SOC: 0.4530 Cumulative_SOC_deviation: 197.0663 Fuel Consumption: 116.9433\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.303\n",
      "Episode: 145 Exploration P: 0.0307 Total reward: -1239.3684999201898 SOC: 0.3974 Cumulative_SOC_deviation: 225.4080 Fuel Consumption: 112.3285\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.371\n",
      "Episode: 146 Exploration P: 0.0302 Total reward: -1153.3135135825582 SOC: 0.4246 Cumulative_SOC_deviation: 207.8520 Fuel Consumption: 114.0534\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.672\n",
      "Episode: 147 Exploration P: 0.0296 Total reward: -927.3174432203703 SOC: 0.4854 Cumulative_SOC_deviation: 161.5985 Fuel Consumption: 119.3247\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.962\n",
      "Episode: 148 Exploration P: 0.0291 Total reward: -773.622934359561 SOC: 0.4657 Cumulative_SOC_deviation: 131.4813 Fuel Consumption: 116.2163\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.884\n",
      "Episode: 149 Exploration P: 0.0286 Total reward: -925.8866182629318 SOC: 0.4579 Cumulative_SOC_deviation: 161.7539 Fuel Consumption: 117.1169\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.833\n",
      "Episode: 150 Exploration P: 0.0281 Total reward: -977.4475426986259 SOC: 0.4429 Cumulative_SOC_deviation: 172.0608 Fuel Consumption: 117.1433\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.725\n",
      "Episode: 151 Exploration P: 0.0276 Total reward: -1300.0602846895126 SOC: 0.3833 Cumulative_SOC_deviation: 237.5676 Fuel Consumption: 112.2221\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.606\n",
      "Episode: 152 Exploration P: 0.0271 Total reward: -1474.0330828449166 SOC: 0.3949 Cumulative_SOC_deviation: 272.1414 Fuel Consumption: 113.3261\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.230\n",
      "Episode: 153 Exploration P: 0.0266 Total reward: -1434.3779408277906 SOC: 0.3852 Cumulative_SOC_deviation: 264.3893 Fuel Consumption: 112.4316\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.344\n",
      "Episode: 154 Exploration P: 0.0262 Total reward: -1341.637622258225 SOC: 0.4149 Cumulative_SOC_deviation: 245.7440 Fuel Consumption: 112.9179\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.887\n",
      "Episode: 155 Exploration P: 0.0258 Total reward: -1316.11735770314 SOC: 0.4070 Cumulative_SOC_deviation: 240.6899 Fuel Consumption: 112.6677\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.670\n",
      "Episode: 156 Exploration P: 0.0253 Total reward: -1146.4979252527237 SOC: 0.4022 Cumulative_SOC_deviation: 206.9750 Fuel Consumption: 111.6232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.219\n",
      "Episode: 157 Exploration P: 0.0249 Total reward: -1330.5990550927293 SOC: 0.4288 Cumulative_SOC_deviation: 243.5895 Fuel Consumption: 112.6516\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.194\n",
      "Episode: 158 Exploration P: 0.0245 Total reward: -1231.5553385195717 SOC: 0.3499 Cumulative_SOC_deviation: 224.6470 Fuel Consumption: 108.3202\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.294\n",
      "Episode: 159 Exploration P: 0.0241 Total reward: -1661.1550919289143 SOC: 0.3380 Cumulative_SOC_deviation: 310.8610 Fuel Consumption: 106.8503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.696\n",
      "Episode: 160 Exploration P: 0.0237 Total reward: -2027.0438006408522 SOC: 0.2400 Cumulative_SOC_deviation: 386.4095 Fuel Consumption: 94.9965\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.875\n",
      "Episode: 161 Exploration P: 0.0234 Total reward: -2257.9107597929906 SOC: 0.2461 Cumulative_SOC_deviation: 432.0017 Fuel Consumption: 97.9021\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.591\n",
      "Episode: 162 Exploration P: 0.0230 Total reward: -2115.3228103521046 SOC: 0.2638 Cumulative_SOC_deviation: 403.0056 Fuel Consumption: 100.2948\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.240\n",
      "Episode: 163 Exploration P: 0.0226 Total reward: -1647.6162097146432 SOC: 0.3977 Cumulative_SOC_deviation: 306.8386 Fuel Consumption: 113.4231\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.510\n",
      "Episode: 164 Exploration P: 0.0223 Total reward: -1359.6133377346612 SOC: 0.4265 Cumulative_SOC_deviation: 248.7446 Fuel Consumption: 115.8904\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.217\n",
      "Episode: 165 Exploration P: 0.0220 Total reward: -1238.3571747514893 SOC: 0.4311 Cumulative_SOC_deviation: 224.3502 Fuel Consumption: 116.6061\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.173\n",
      "Episode: 166 Exploration P: 0.0216 Total reward: -855.1792219573223 SOC: 0.4664 Cumulative_SOC_deviation: 147.1658 Fuel Consumption: 119.3504\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.251\n",
      "Episode: 167 Exploration P: 0.0213 Total reward: -927.604783079937 SOC: 0.4932 Cumulative_SOC_deviation: 161.1700 Fuel Consumption: 121.7547\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.007\n",
      "Episode: 168 Exploration P: 0.0210 Total reward: -915.8419370149378 SOC: 0.4346 Cumulative_SOC_deviation: 159.8601 Fuel Consumption: 116.5414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.692\n",
      "Episode: 169 Exploration P: 0.0207 Total reward: -1214.77064596854 SOC: 0.3980 Cumulative_SOC_deviation: 220.6758 Fuel Consumption: 111.3919\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.540\n",
      "Episode: 170 Exploration P: 0.0204 Total reward: -1238.4577096848336 SOC: 0.4186 Cumulative_SOC_deviation: 224.8220 Fuel Consumption: 114.3478\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.103\n",
      "Episode: 171 Exploration P: 0.0202 Total reward: -1115.3437444062224 SOC: 0.4178 Cumulative_SOC_deviation: 200.0417 Fuel Consumption: 115.1354\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.466\n",
      "Episode: 172 Exploration P: 0.0199 Total reward: -1161.9577165064231 SOC: 0.4343 Cumulative_SOC_deviation: 209.0889 Fuel Consumption: 116.5134\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.271\n",
      "Episode: 173 Exploration P: 0.0196 Total reward: -796.8210422675967 SOC: 0.5241 Cumulative_SOC_deviation: 134.5855 Fuel Consumption: 123.8938\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.738\n",
      "Episode: 174 Exploration P: 0.0194 Total reward: -432.5272780411273 SOC: 0.5578 Cumulative_SOC_deviation: 61.4774 Fuel Consumption: 125.1403\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.387\n",
      "Episode: 175 Exploration P: 0.0191 Total reward: -462.4960918169144 SOC: 0.3932 Cumulative_SOC_deviation: 70.2970 Fuel Consumption: 111.0110\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.202\n",
      "Episode: 176 Exploration P: 0.0189 Total reward: -1500.668417564447 SOC: 0.4108 Cumulative_SOC_deviation: 277.2152 Fuel Consumption: 114.5926\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.282\n",
      "Episode: 177 Exploration P: 0.0186 Total reward: -982.7523946104808 SOC: 0.4535 Cumulative_SOC_deviation: 172.7871 Fuel Consumption: 118.8168\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.268\n",
      "Episode: 178 Exploration P: 0.0184 Total reward: -946.8238043304783 SOC: 0.3872 Cumulative_SOC_deviation: 166.7090 Fuel Consumption: 113.2788\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.097\n",
      "Episode: 179 Exploration P: 0.0182 Total reward: -1549.1284496253 SOC: 0.2241 Cumulative_SOC_deviation: 289.7352 Fuel Consumption: 100.4523\n",
      "\n",
      "battery power is 9871.688148716332(+) but condition is not avail\n",
      "elapsed_time: 35.557\n",
      "Episode: 180 Exploration P: 0.0181 Total reward: -2012.9412482236776 SOC: -0.0004 Cumulative_SOC_deviation: 198.7066 Fuel Consumption: 22.4107\n",
      "\n",
      "battery power is 1588.0363678403935(+) but condition is not avail\n",
      "elapsed_time: 34.654\n",
      "Episode: 181 Exploration P: 0.0180 Total reward: -2066.386778198708 SOC: -0.0004 Cumulative_SOC_deviation: 209.5947 Fuel Consumption: 21.4654\n",
      "\n",
      "battery power is 4480.123010080599(+) but condition is not avail\n",
      "elapsed_time: 35.173\n",
      "Episode: 182 Exploration P: 0.0179 Total reward: -2048.9823150004804 SOC: -0.0002 Cumulative_SOC_deviation: 206.0449 Fuel Consumption: 21.7753\n",
      "\n",
      "battery power is 7171.136232162809(+) but condition is not avail\n",
      "elapsed_time: 31.999\n",
      "Episode: 183 Exploration P: 0.0178 Total reward: -1911.7374945599925 SOC: -0.0008 Cumulative_SOC_deviation: 179.4461 Fuel Consumption: 17.5120\n",
      "\n",
      "battery power is 234.37871125683546(+) but condition is not avail\n",
      "elapsed_time: 53.204\n",
      "Episode: 184 Exploration P: 0.0176 Total reward: -2768.184150848724 SOC: -0.0000 Cumulative_SOC_deviation: 342.3636 Fuel Consumption: 59.4080\n",
      "\n",
      "battery power is 4096.36665996802(+) but condition is not avail\n",
      "elapsed_time: 53.359\n",
      "Episode: 185 Exploration P: 0.0175 Total reward: -2646.8800813750886 SOC: -0.0014 Cumulative_SOC_deviation: 318.8302 Fuel Consumption: 55.7399\n",
      "\n",
      "battery power is 8009.383584064154(+) but condition is not avail\n",
      "elapsed_time: 31.057\n",
      "Episode: 186 Exploration P: 0.0174 Total reward: -1876.4566400460517 SOC: -0.0011 Cumulative_SOC_deviation: 172.9004 Fuel Consumption: 14.9610\n",
      "\n",
      "battery power is 6053.485987488464(+) but condition is not avail\n",
      "elapsed_time: 35.215\n",
      "Episode: 187 Exploration P: 0.0174 Total reward: -2063.625481859226 SOC: -0.0008 Cumulative_SOC_deviation: 208.9282 Fuel Consumption: 21.9893\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.345\n",
      "Episode: 188 Exploration P: 0.0172 Total reward: -2691.0408119745425 SOC: 0.1306 Cumulative_SOC_deviation: 518.7386 Fuel Consumption: 97.3478\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.385\n",
      "Episode: 189 Exploration P: 0.0170 Total reward: -2636.635573480364 SOC: 0.1354 Cumulative_SOC_deviation: 507.8827 Fuel Consumption: 97.2222\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.500\n",
      "Episode: 190 Exploration P: 0.0168 Total reward: -2228.475973076658 SOC: 0.2958 Cumulative_SOC_deviation: 424.1957 Fuel Consumption: 107.4974\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.479\n",
      "Episode: 191 Exploration P: 0.0166 Total reward: -1401.5935614110601 SOC: 0.4037 Cumulative_SOC_deviation: 257.6806 Fuel Consumption: 113.1904\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.617\n",
      "Episode: 192 Exploration P: 0.0164 Total reward: -1490.3736064346172 SOC: 0.3596 Cumulative_SOC_deviation: 276.3405 Fuel Consumption: 108.6710\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.699\n",
      "Episode: 193 Exploration P: 0.0162 Total reward: -1632.7331442984923 SOC: 0.3363 Cumulative_SOC_deviation: 305.3967 Fuel Consumption: 105.7499\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.090\n",
      "Episode: 194 Exploration P: 0.0161 Total reward: -1801.8483799394157 SOC: 0.2746 Cumulative_SOC_deviation: 339.6374 Fuel Consumption: 103.6612\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.033\n",
      "Episode: 195 Exploration P: 0.0159 Total reward: -2090.46066741415 SOC: 0.2267 Cumulative_SOC_deviation: 398.0226 Fuel Consumption: 100.3478\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.234\n",
      "Episode: 196 Exploration P: 0.0157 Total reward: -1677.7558714017716 SOC: 0.4602 Cumulative_SOC_deviation: 312.2611 Fuel Consumption: 116.4506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.268\n",
      "Episode: 197 Exploration P: 0.0156 Total reward: -1203.6247557616898 SOC: 0.4292 Cumulative_SOC_deviation: 218.5345 Fuel Consumption: 110.9523\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.987\n",
      "Episode: 198 Exploration P: 0.0154 Total reward: -1372.1517858473828 SOC: 0.3679 Cumulative_SOC_deviation: 253.5126 Fuel Consumption: 104.5890\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.472\n",
      "Episode: 199 Exploration P: 0.0153 Total reward: -1680.7547604672513 SOC: 0.3694 Cumulative_SOC_deviation: 314.2978 Fuel Consumption: 109.2656\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.123\n",
      "Episode: 200 Exploration P: 0.0151 Total reward: -1760.889809765731 SOC: 0.3086 Cumulative_SOC_deviation: 331.2321 Fuel Consumption: 104.7291\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 6\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.787\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3067.679031292465 SOC: 1.0000 Cumulative_SOC_deviation: 479.7302 Fuel Consumption: 189.2981\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.762\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3124.60079733967 SOC: 1.0000 Cumulative_SOC_deviation: 488.0918 Fuel Consumption: 196.0497\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.828\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -3039.184535553951 SOC: 1.0000 Cumulative_SOC_deviation: 474.6667 Fuel Consumption: 191.1844\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer batch_normalization_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 37.359\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -3106.521288494622 SOC: 1.0000 Cumulative_SOC_deviation: 485.7675 Fuel Consumption: 191.9163\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.470\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -3083.8405175584617 SOC: 1.0000 Cumulative_SOC_deviation: 482.2691 Fuel Consumption: 190.2258\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.173\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -3048.9019156459613 SOC: 1.0000 Cumulative_SOC_deviation: 477.4133 Fuel Consumption: 184.4224\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.177\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2950.4643988267653 SOC: 1.0000 Cumulative_SOC_deviation: 462.5034 Fuel Consumption: 175.4442\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.088\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -3058.672529898695 SOC: 1.0000 Cumulative_SOC_deviation: 479.8852 Fuel Consumption: 179.3612\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.651\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2897.65479934617 SOC: 1.0000 Cumulative_SOC_deviation: 453.1898 Fuel Consumption: 178.5160\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.911\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2939.3889110340406 SOC: 0.9999 Cumulative_SOC_deviation: 461.1694 Fuel Consumption: 172.3724\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.944\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2956.405510426454 SOC: 1.0000 Cumulative_SOC_deviation: 463.9626 Fuel Consumption: 172.6301\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.276\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2824.0446333908426 SOC: 1.0000 Cumulative_SOC_deviation: 442.7408 Fuel Consumption: 167.5999\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.202\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -2859.534312970825 SOC: 0.9999 Cumulative_SOC_deviation: 449.2931 Fuel Consumption: 163.7756\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.976\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2676.1911846284684 SOC: 1.0000 Cumulative_SOC_deviation: 418.4799 Fuel Consumption: 165.3115\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.461\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2753.887775917476 SOC: 0.9987 Cumulative_SOC_deviation: 431.7781 Fuel Consumption: 163.2190\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.924\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -2599.2833375065084 SOC: 1.0000 Cumulative_SOC_deviation: 406.4626 Fuel Consumption: 160.5080\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.998\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -2479.6606207190075 SOC: 0.9958 Cumulative_SOC_deviation: 387.0168 Fuel Consumption: 157.5600\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.252\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -2120.1055665818267 SOC: 0.9994 Cumulative_SOC_deviation: 327.7043 Fuel Consumption: 153.8800\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.415\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -2016.454890430747 SOC: 0.9989 Cumulative_SOC_deviation: 310.0855 Fuel Consumption: 155.9416\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.267\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -2224.6587253129373 SOC: 0.9937 Cumulative_SOC_deviation: 345.1521 Fuel Consumption: 153.7460\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.514\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -2174.1006291839035 SOC: 0.9990 Cumulative_SOC_deviation: 336.7292 Fuel Consumption: 153.7254\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.365\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1887.211902663637 SOC: 0.9870 Cumulative_SOC_deviation: 289.3147 Fuel Consumption: 151.3237\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.261\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1661.903229917659 SOC: 0.9826 Cumulative_SOC_deviation: 251.4815 Fuel Consumption: 153.0142\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.069\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1720.0630893649145 SOC: 0.9359 Cumulative_SOC_deviation: 261.8362 Fuel Consumption: 149.0456\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.367\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1329.8173983387396 SOC: 0.9223 Cumulative_SOC_deviation: 196.8932 Fuel Consumption: 148.4581\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.329\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1099.587928573566 SOC: 0.9250 Cumulative_SOC_deviation: 158.2399 Fuel Consumption: 150.1486\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.624\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1130.7134918201252 SOC: 0.8989 Cumulative_SOC_deviation: 163.7625 Fuel Consumption: 148.1385\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.704\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -768.5298234649247 SOC: 0.7407 Cumulative_SOC_deviation: 105.3588 Fuel Consumption: 136.3772\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.372\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -917.32251015211 SOC: 0.8407 Cumulative_SOC_deviation: 128.8845 Fuel Consumption: 144.0153\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.181\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -632.9827959366651 SOC: 0.7982 Cumulative_SOC_deviation: 82.0564 Fuel Consumption: 140.6447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.894\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -687.2722456389482 SOC: 0.6776 Cumulative_SOC_deviation: 92.4841 Fuel Consumption: 132.3674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.789\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -440.7859513924977 SOC: 0.6973 Cumulative_SOC_deviation: 51.3223 Fuel Consumption: 132.8519\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.741\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1180.128079810509 SOC: 0.4861 Cumulative_SOC_deviation: 177.1728 Fuel Consumption: 117.0910\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.346\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -1059.8300388496016 SOC: 0.4866 Cumulative_SOC_deviation: 156.9067 Fuel Consumption: 118.3898\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.440\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -1258.306168099596 SOC: 0.4282 Cumulative_SOC_deviation: 190.8124 Fuel Consumption: 113.4317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.794\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -818.1601488038069 SOC: 0.5025 Cumulative_SOC_deviation: 116.5803 Fuel Consumption: 118.6785\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.100\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -1180.6680129610231 SOC: 0.4555 Cumulative_SOC_deviation: 177.5274 Fuel Consumption: 115.5036\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.943\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1681.4446804667648 SOC: 0.2954 Cumulative_SOC_deviation: 262.9796 Fuel Consumption: 103.5671\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.947\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -2429.699284925788 SOC: 0.1471 Cumulative_SOC_deviation: 389.2521 Fuel Consumption: 94.1868\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.855\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1958.2652524608266 SOC: 0.2734 Cumulative_SOC_deviation: 309.2023 Fuel Consumption: 103.0517\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.003\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1948.549282203968 SOC: 0.2245 Cumulative_SOC_deviation: 308.2478 Fuel Consumption: 99.0625\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.126\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -2208.1039156958377 SOC: 0.1722 Cumulative_SOC_deviation: 351.9776 Fuel Consumption: 96.2381\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.213\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -2270.704695842958 SOC: 0.1521 Cumulative_SOC_deviation: 362.7341 Fuel Consumption: 94.3002\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.028\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -3188.521728489748 SOC: 0.0397 Cumulative_SOC_deviation: 516.6708 Fuel Consumption: 88.4969\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.078\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -2539.14513448018 SOC: 0.0995 Cumulative_SOC_deviation: 408.0102 Fuel Consumption: 91.0842\n",
      "\n",
      "battery power is 3964.290372239211(+) but condition is not avail\n",
      "elapsed_time: 81.419\n",
      "Episode: 46 Exploration P: 0.3195 Total reward: -4018.9531202757926 SOC: -0.0008 Cumulative_SOC_deviation: 489.5853 Fuel Consumption: 85.0468\n",
      "\n",
      "battery power is 10886.199985334762(+) but condition is not avail\n",
      "elapsed_time: 60.148\n",
      "Episode: 47 Exploration P: 0.3134 Total reward: -3107.807391309142 SOC: -0.0002 Cumulative_SOC_deviation: 342.3251 Fuel Consumption: 57.4589\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.283\n",
      "Episode: 48 Exploration P: 0.3052 Total reward: -2739.802775983914 SOC: 0.0554 Cumulative_SOC_deviation: 441.9582 Fuel Consumption: 88.0536\n",
      "\n",
      "battery power is 6278.002938313482(+) but condition is not avail\n",
      "elapsed_time: 73.735\n",
      "Episode: 49 Exploration P: 0.2980 Total reward: -3793.0208132101448 SOC: -0.0005 Cumulative_SOC_deviation: 453.6633 Fuel Consumption: 74.6447\n",
      "\n",
      "battery power is 8218.624359406906(+) but condition is not avail\n",
      "elapsed_time: 64.359\n",
      "Episode: 50 Exploration P: 0.2919 Total reward: -3306.4442557078037 SOC: -0.0010 Cumulative_SOC_deviation: 374.2920 Fuel Consumption: 64.2992\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.446\n",
      "Episode: 51 Exploration P: 0.2843 Total reward: -227.02430148466908 SOC: 0.5964 Cumulative_SOC_deviation: 17.8737 Fuel Consumption: 119.7820\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.421\n",
      "Episode: 52 Exploration P: 0.2768 Total reward: -246.0208820436099 SOC: 0.5902 Cumulative_SOC_deviation: 21.0754 Fuel Consumption: 119.5682\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.569\n",
      "Episode: 53 Exploration P: 0.2696 Total reward: -297.1765475252982 SOC: 0.5877 Cumulative_SOC_deviation: 29.9791 Fuel Consumption: 117.3018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.759\n",
      "Episode: 54 Exploration P: 0.2626 Total reward: -358.5353775174272 SOC: 0.5446 Cumulative_SOC_deviation: 40.4982 Fuel Consumption: 115.5460\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.838\n",
      "Episode: 55 Exploration P: 0.2557 Total reward: -540.5103594480216 SOC: 0.5371 Cumulative_SOC_deviation: 70.5240 Fuel Consumption: 117.3663\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.963\n",
      "Episode: 56 Exploration P: 0.2491 Total reward: -888.331386031969 SOC: 0.5611 Cumulative_SOC_deviation: 128.5441 Fuel Consumption: 117.0666\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.472\n",
      "Episode: 57 Exploration P: 0.2426 Total reward: -1014.4273933333137 SOC: 0.4343 Cumulative_SOC_deviation: 150.5471 Fuel Consumption: 111.1446\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.231\n",
      "Episode: 58 Exploration P: 0.2363 Total reward: -1227.9233175210854 SOC: 0.5388 Cumulative_SOC_deviation: 184.8711 Fuel Consumption: 118.6967\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.692\n",
      "Episode: 59 Exploration P: 0.2302 Total reward: -1014.1769010071357 SOC: 0.4690 Cumulative_SOC_deviation: 150.6140 Fuel Consumption: 110.4932\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.988\n",
      "Episode: 60 Exploration P: 0.2242 Total reward: -487.25161015848033 SOC: 0.5274 Cumulative_SOC_deviation: 62.3358 Fuel Consumption: 113.2367\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.105\n",
      "Episode: 61 Exploration P: 0.2184 Total reward: -400.7023133220493 SOC: 0.5433 Cumulative_SOC_deviation: 48.1024 Fuel Consumption: 112.0880\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.897\n",
      "Episode: 62 Exploration P: 0.2128 Total reward: -565.9485637908083 SOC: 0.5138 Cumulative_SOC_deviation: 75.7902 Fuel Consumption: 111.2076\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.465\n",
      "Episode: 63 Exploration P: 0.2073 Total reward: -502.844615681289 SOC: 0.5544 Cumulative_SOC_deviation: 64.1866 Fuel Consumption: 117.7251\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.691\n",
      "Episode: 64 Exploration P: 0.2019 Total reward: -486.53764598072695 SOC: 0.5524 Cumulative_SOC_deviation: 62.6360 Fuel Consumption: 110.7214\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.951\n",
      "Episode: 65 Exploration P: 0.1967 Total reward: -422.4211288817235 SOC: 0.5730 Cumulative_SOC_deviation: 51.8673 Fuel Consumption: 111.2173\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.608\n",
      "Episode: 66 Exploration P: 0.1917 Total reward: -842.8333782038636 SOC: 0.3623 Cumulative_SOC_deviation: 123.8996 Fuel Consumption: 99.4360\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.827\n",
      "Episode: 67 Exploration P: 0.1867 Total reward: -794.9789824436266 SOC: 0.5352 Cumulative_SOC_deviation: 113.2816 Fuel Consumption: 115.2897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.239\n",
      "Episode: 68 Exploration P: 0.1820 Total reward: -519.8212865833481 SOC: 0.5183 Cumulative_SOC_deviation: 68.7823 Fuel Consumption: 107.1276\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.754\n",
      "Episode: 69 Exploration P: 0.1773 Total reward: -441.84244652774913 SOC: 0.5551 Cumulative_SOC_deviation: 54.8921 Fuel Consumption: 112.4897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.749\n",
      "Episode: 70 Exploration P: 0.1728 Total reward: -700.1358700001928 SOC: 0.5827 Cumulative_SOC_deviation: 97.6858 Fuel Consumption: 114.0211\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.952\n",
      "Episode: 71 Exploration P: 0.1684 Total reward: -369.7982498383692 SOC: 0.5163 Cumulative_SOC_deviation: 43.5236 Fuel Consumption: 108.6568\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.381\n",
      "Episode: 72 Exploration P: 0.1641 Total reward: -2836.416934022211 SOC: 0.1115 Cumulative_SOC_deviation: 457.5347 Fuel Consumption: 91.2086\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.436\n",
      "Episode: 73 Exploration P: 0.1599 Total reward: -3447.594000934181 SOC: 0.1837 Cumulative_SOC_deviation: 558.6993 Fuel Consumption: 95.3982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.407\n",
      "Episode: 74 Exploration P: 0.1558 Total reward: -2972.1469503748126 SOC: 0.2163 Cumulative_SOC_deviation: 478.9737 Fuel Consumption: 98.3050\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.845\n",
      "Episode: 75 Exploration P: 0.1519 Total reward: -651.4614299017019 SOC: 0.5777 Cumulative_SOC_deviation: 89.3479 Fuel Consumption: 115.3739\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.630\n",
      "Episode: 76 Exploration P: 0.1480 Total reward: -332.78539060050446 SOC: 0.5793 Cumulative_SOC_deviation: 36.9047 Fuel Consumption: 111.3573\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.708\n",
      "Episode: 77 Exploration P: 0.1443 Total reward: -632.1598343251085 SOC: 0.3237 Cumulative_SOC_deviation: 89.8235 Fuel Consumption: 93.2187\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.963\n",
      "Episode: 78 Exploration P: 0.1407 Total reward: -400.7847733590967 SOC: 0.5669 Cumulative_SOC_deviation: 48.7221 Fuel Consumption: 108.4524\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.061\n",
      "Episode: 79 Exploration P: 0.1371 Total reward: -270.88658925635593 SOC: 0.5923 Cumulative_SOC_deviation: 26.6793 Fuel Consumption: 110.8110\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.881\n",
      "Episode: 80 Exploration P: 0.1337 Total reward: -174.40215099907266 SOC: 0.5974 Cumulative_SOC_deviation: 10.6335 Fuel Consumption: 110.6014\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.763\n",
      "Episode: 81 Exploration P: 0.1303 Total reward: -204.16193907700654 SOC: 0.6093 Cumulative_SOC_deviation: 15.4313 Fuel Consumption: 111.5742\n",
      "\n",
      "battery power is 12285.147059318873(+) but condition is not avail\n",
      "elapsed_time: 36.726\n",
      "Episode: 82 Exploration P: 0.1289 Total reward: -2128.306098355698 SOC: -0.0017 Cumulative_SOC_deviation: 184.9281 Fuel Consumption: 22.3770\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.825\n",
      "Episode: 83 Exploration P: 0.1257 Total reward: -858.9461468341954 SOC: 0.5928 Cumulative_SOC_deviation: 124.1073 Fuel Consumption: 114.3024\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.948\n",
      "Episode: 84 Exploration P: 0.1225 Total reward: -261.30160548950363 SOC: 0.5869 Cumulative_SOC_deviation: 25.3528 Fuel Consumption: 109.1850\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.972\n",
      "Episode: 85 Exploration P: 0.1195 Total reward: -451.41173174422465 SOC: 0.5599 Cumulative_SOC_deviation: 56.8616 Fuel Consumption: 110.2421\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.847\n",
      "Episode: 86 Exploration P: 0.1165 Total reward: -218.70226911269702 SOC: 0.6099 Cumulative_SOC_deviation: 17.6981 Fuel Consumption: 112.5140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.034\n",
      "Episode: 87 Exploration P: 0.1136 Total reward: -729.5379230297566 SOC: 0.5345 Cumulative_SOC_deviation: 103.4237 Fuel Consumption: 108.9955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.053\n",
      "Episode: 88 Exploration P: 0.1108 Total reward: -265.84344701632375 SOC: 0.6040 Cumulative_SOC_deviation: 25.7114 Fuel Consumption: 111.5750\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.897\n",
      "Episode: 89 Exploration P: 0.1081 Total reward: -434.05276958304705 SOC: 0.6020 Cumulative_SOC_deviation: 53.8919 Fuel Consumption: 110.7016\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.318\n",
      "Episode: 90 Exploration P: 0.1054 Total reward: -500.7171730925603 SOC: 0.5412 Cumulative_SOC_deviation: 65.5872 Fuel Consumption: 107.1937\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.779\n",
      "Episode: 91 Exploration P: 0.1028 Total reward: -514.7088545423856 SOC: 0.5625 Cumulative_SOC_deviation: 67.7375 Fuel Consumption: 108.2837\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.757\n",
      "Episode: 92 Exploration P: 0.1003 Total reward: -367.62609290214283 SOC: 0.5582 Cumulative_SOC_deviation: 43.0887 Fuel Consumption: 109.0939\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.622\n",
      "Episode: 93 Exploration P: 0.0979 Total reward: -454.0421565624461 SOC: 0.5531 Cumulative_SOC_deviation: 57.4161 Fuel Consumption: 109.5454\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.103\n",
      "Episode: 94 Exploration P: 0.0955 Total reward: -349.8950468709536 SOC: 0.5885 Cumulative_SOC_deviation: 39.7836 Fuel Consumption: 111.1932\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.792\n",
      "Episode: 95 Exploration P: 0.0932 Total reward: -242.39513379185857 SOC: 0.5790 Cumulative_SOC_deviation: 22.1979 Fuel Consumption: 109.2077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.242\n",
      "Episode: 96 Exploration P: 0.0909 Total reward: -239.0455625429866 SOC: 0.5829 Cumulative_SOC_deviation: 21.5895 Fuel Consumption: 109.5085\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.492\n",
      "Episode: 97 Exploration P: 0.0887 Total reward: -263.76739074666324 SOC: 0.5895 Cumulative_SOC_deviation: 25.3706 Fuel Consumption: 111.5438\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.364\n",
      "Episode: 98 Exploration P: 0.0866 Total reward: -394.2863028115559 SOC: 0.5478 Cumulative_SOC_deviation: 47.9733 Fuel Consumption: 106.4463\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.116\n",
      "Episode: 99 Exploration P: 0.0845 Total reward: -527.282765624387 SOC: 0.5292 Cumulative_SOC_deviation: 70.1449 Fuel Consumption: 106.4135\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.201\n",
      "Episode: 100 Exploration P: 0.0825 Total reward: -618.8572325924255 SOC: 0.5478 Cumulative_SOC_deviation: 85.4214 Fuel Consumption: 106.3287\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.427\n",
      "Episode: 101 Exploration P: 0.0806 Total reward: -386.6722206723863 SOC: 0.5968 Cumulative_SOC_deviation: 46.0155 Fuel Consumption: 110.5793\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.238\n",
      "Episode: 102 Exploration P: 0.0786 Total reward: -395.14314319956344 SOC: 0.5454 Cumulative_SOC_deviation: 48.0307 Fuel Consumption: 106.9587\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.711\n",
      "Episode: 103 Exploration P: 0.0768 Total reward: -335.3141635579063 SOC: 0.5898 Cumulative_SOC_deviation: 37.6151 Fuel Consumption: 109.6235\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.559\n",
      "Episode: 104 Exploration P: 0.0750 Total reward: -352.21922390360066 SOC: 0.5912 Cumulative_SOC_deviation: 40.3083 Fuel Consumption: 110.3695\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.470\n",
      "Episode: 105 Exploration P: 0.0732 Total reward: -324.3898585066553 SOC: 0.5417 Cumulative_SOC_deviation: 36.3848 Fuel Consumption: 106.0808\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.467\n",
      "Episode: 106 Exploration P: 0.0715 Total reward: -391.6396161460421 SOC: 0.5664 Cumulative_SOC_deviation: 47.0871 Fuel Consumption: 109.1172\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.856\n",
      "Episode: 107 Exploration P: 0.0698 Total reward: -299.8794949791937 SOC: 0.5845 Cumulative_SOC_deviation: 31.6884 Fuel Consumption: 109.7491\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.539\n",
      "Episode: 108 Exploration P: 0.0682 Total reward: -227.9696554343583 SOC: 0.5868 Cumulative_SOC_deviation: 19.8363 Fuel Consumption: 108.9521\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.716\n",
      "Episode: 109 Exploration P: 0.0666 Total reward: -304.71843645744906 SOC: 0.4768 Cumulative_SOC_deviation: 33.8815 Fuel Consumption: 101.4292\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.403\n",
      "Episode: 110 Exploration P: 0.0651 Total reward: -388.28846494875097 SOC: 0.5959 Cumulative_SOC_deviation: 46.3140 Fuel Consumption: 110.4047\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.421\n",
      "Episode: 111 Exploration P: 0.0636 Total reward: -748.1833746692995 SOC: 0.5903 Cumulative_SOC_deviation: 106.1024 Fuel Consumption: 111.5692\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.616\n",
      "Episode: 112 Exploration P: 0.0622 Total reward: -234.6104827834863 SOC: 0.5930 Cumulative_SOC_deviation: 20.9780 Fuel Consumption: 108.7423\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.815\n",
      "Episode: 113 Exploration P: 0.0607 Total reward: -621.2158349368026 SOC: 0.5805 Cumulative_SOC_deviation: 85.2972 Fuel Consumption: 109.4325\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.712\n",
      "Episode: 114 Exploration P: 0.0594 Total reward: -252.16679078855054 SOC: 0.5676 Cumulative_SOC_deviation: 24.2068 Fuel Consumption: 106.9259\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.915\n",
      "Episode: 115 Exploration P: 0.0580 Total reward: -325.73188228612355 SOC: 0.5674 Cumulative_SOC_deviation: 36.4007 Fuel Consumption: 107.3276\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.831\n",
      "Episode: 116 Exploration P: 0.0567 Total reward: -544.1912326653828 SOC: 0.5539 Cumulative_SOC_deviation: 72.9787 Fuel Consumption: 106.3192\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.914\n",
      "Episode: 117 Exploration P: 0.0555 Total reward: -389.57305568743544 SOC: 0.5849 Cumulative_SOC_deviation: 46.8409 Fuel Consumption: 108.5279\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.931\n",
      "Episode: 118 Exploration P: 0.0542 Total reward: -283.93906555149573 SOC: 0.5486 Cumulative_SOC_deviation: 29.7690 Fuel Consumption: 105.3253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.581\n",
      "Episode: 119 Exploration P: 0.0530 Total reward: -326.09752014486185 SOC: 0.5695 Cumulative_SOC_deviation: 36.3125 Fuel Consumption: 108.2224\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.930\n",
      "Episode: 120 Exploration P: 0.0519 Total reward: -380.8122350264945 SOC: 0.5654 Cumulative_SOC_deviation: 45.7987 Fuel Consumption: 106.0199\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.959\n",
      "Episode: 121 Exploration P: 0.0507 Total reward: -335.1993194268441 SOC: 0.5886 Cumulative_SOC_deviation: 37.7864 Fuel Consumption: 108.4809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.949\n",
      "Episode: 122 Exploration P: 0.0496 Total reward: -347.4195569178012 SOC: 0.5873 Cumulative_SOC_deviation: 39.7394 Fuel Consumption: 108.9833\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.087\n",
      "Episode: 123 Exploration P: 0.0486 Total reward: -230.3998304501387 SOC: 0.5931 Cumulative_SOC_deviation: 19.9474 Fuel Consumption: 110.7153\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.961\n",
      "Episode: 124 Exploration P: 0.0475 Total reward: -452.19418213239743 SOC: 0.5961 Cumulative_SOC_deviation: 57.0428 Fuel Consumption: 109.9371\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.967\n",
      "Episode: 125 Exploration P: 0.0465 Total reward: -199.57756976193352 SOC: 0.5830 Cumulative_SOC_deviation: 15.1968 Fuel Consumption: 108.3967\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.704\n",
      "Episode: 126 Exploration P: 0.0455 Total reward: -261.84478619098195 SOC: 0.5747 Cumulative_SOC_deviation: 25.7219 Fuel Consumption: 107.5131\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.763\n",
      "Episode: 127 Exploration P: 0.0445 Total reward: -246.00731931441004 SOC: 0.5866 Cumulative_SOC_deviation: 22.9303 Fuel Consumption: 108.4258\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.956\n",
      "Episode: 128 Exploration P: 0.0436 Total reward: -303.56390131668115 SOC: 0.5785 Cumulative_SOC_deviation: 32.7505 Fuel Consumption: 107.0610\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.879\n",
      "Episode: 129 Exploration P: 0.0427 Total reward: -310.5609129999651 SOC: 0.5904 Cumulative_SOC_deviation: 33.7342 Fuel Consumption: 108.1556\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.841\n",
      "Episode: 130 Exploration P: 0.0418 Total reward: -402.39503318160564 SOC: 0.5438 Cumulative_SOC_deviation: 49.7319 Fuel Consumption: 104.0038\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.646\n",
      "Episode: 131 Exploration P: 0.0410 Total reward: -490.81191127009623 SOC: 0.5897 Cumulative_SOC_deviation: 63.7428 Fuel Consumption: 108.3549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.801\n",
      "Episode: 132 Exploration P: 0.0401 Total reward: -544.6918867811142 SOC: 0.5535 Cumulative_SOC_deviation: 73.1492 Fuel Consumption: 105.7968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.106\n",
      "Episode: 133 Exploration P: 0.0393 Total reward: -427.17272867731145 SOC: 0.5350 Cumulative_SOC_deviation: 53.8241 Fuel Consumption: 104.2280\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.676\n",
      "Episode: 134 Exploration P: 0.0385 Total reward: -733.2578777052846 SOC: 0.5761 Cumulative_SOC_deviation: 103.8556 Fuel Consumption: 110.1241\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.784\n",
      "Episode: 135 Exploration P: 0.0377 Total reward: -299.2562788077812 SOC: 0.5840 Cumulative_SOC_deviation: 31.9237 Fuel Consumption: 107.7142\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.633\n",
      "Episode: 136 Exploration P: 0.0370 Total reward: -909.3814014734628 SOC: 0.4910 Cumulative_SOC_deviation: 134.5156 Fuel Consumption: 102.2877\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.670\n",
      "Episode: 137 Exploration P: 0.0363 Total reward: -282.6417416542821 SOC: 0.5736 Cumulative_SOC_deviation: 29.1781 Fuel Consumption: 107.5733\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.057\n",
      "Episode: 138 Exploration P: 0.0355 Total reward: -312.60498749366855 SOC: 0.5694 Cumulative_SOC_deviation: 34.1912 Fuel Consumption: 107.4579\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.560\n",
      "Episode: 139 Exploration P: 0.0349 Total reward: -270.76545867542114 SOC: 0.5824 Cumulative_SOC_deviation: 27.3565 Fuel Consumption: 106.6264\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.492\n",
      "Episode: 140 Exploration P: 0.0342 Total reward: -272.89836839254514 SOC: 0.5822 Cumulative_SOC_deviation: 27.7018 Fuel Consumption: 106.6877\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.653\n",
      "Episode: 141 Exploration P: 0.0335 Total reward: -295.5212888362185 SOC: 0.5657 Cumulative_SOC_deviation: 31.5504 Fuel Consumption: 106.2188\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.696\n",
      "Episode: 142 Exploration P: 0.0329 Total reward: -283.6810442626258 SOC: 0.5741 Cumulative_SOC_deviation: 29.3770 Fuel Consumption: 107.4189\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.628\n",
      "Episode: 143 Exploration P: 0.0323 Total reward: -252.66760672341772 SOC: 0.5600 Cumulative_SOC_deviation: 24.2036 Fuel Consumption: 107.4459\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.535\n",
      "Episode: 144 Exploration P: 0.0317 Total reward: -501.3654587988086 SOC: 0.5502 Cumulative_SOC_deviation: 66.0766 Fuel Consumption: 104.9056\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.555\n",
      "Episode: 145 Exploration P: 0.0311 Total reward: -397.1994754751766 SOC: 0.5655 Cumulative_SOC_deviation: 48.4890 Fuel Consumption: 106.2655\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.730\n",
      "Episode: 146 Exploration P: 0.0305 Total reward: -437.2520823004529 SOC: 0.5382 Cumulative_SOC_deviation: 55.2198 Fuel Consumption: 105.9334\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.701\n",
      "Episode: 147 Exploration P: 0.0299 Total reward: -440.6578675688802 SOC: 0.5308 Cumulative_SOC_deviation: 55.6262 Fuel Consumption: 106.9007\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.606\n",
      "Episode: 148 Exploration P: 0.0294 Total reward: -448.285900132615 SOC: 0.5252 Cumulative_SOC_deviation: 57.1838 Fuel Consumption: 105.1828\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.453\n",
      "Episode: 149 Exploration P: 0.0289 Total reward: -1764.3185364515004 SOC: 0.4095 Cumulative_SOC_deviation: 277.9967 Fuel Consumption: 96.3384\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.369\n",
      "Episode: 150 Exploration P: 0.0284 Total reward: -660.3098071545177 SOC: 0.5666 Cumulative_SOC_deviation: 91.3425 Fuel Consumption: 112.2550\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.608\n",
      "Episode: 151 Exploration P: 0.0279 Total reward: -349.85440841992903 SOC: 0.5550 Cumulative_SOC_deviation: 40.2403 Fuel Consumption: 108.4124\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.421\n",
      "Episode: 152 Exploration P: 0.0274 Total reward: -294.3434817796204 SOC: 0.5798 Cumulative_SOC_deviation: 30.8264 Fuel Consumption: 109.3850\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.812\n",
      "Episode: 153 Exploration P: 0.0269 Total reward: -405.01625274021046 SOC: 0.5661 Cumulative_SOC_deviation: 49.4620 Fuel Consumption: 108.2440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.425\n",
      "Episode: 154 Exploration P: 0.0265 Total reward: -386.1921737356994 SOC: 0.5577 Cumulative_SOC_deviation: 46.7231 Fuel Consumption: 105.8533\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.100\n",
      "Episode: 155 Exploration P: 0.0260 Total reward: -396.5757722218154 SOC: 0.5509 Cumulative_SOC_deviation: 48.5168 Fuel Consumption: 105.4752\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.255\n",
      "Episode: 156 Exploration P: 0.0256 Total reward: -341.6834983491963 SOC: 0.5847 Cumulative_SOC_deviation: 38.7530 Fuel Consumption: 109.1654\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.814\n",
      "Episode: 157 Exploration P: 0.0252 Total reward: -400.42140582358473 SOC: 0.5653 Cumulative_SOC_deviation: 48.2901 Fuel Consumption: 110.6809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.496\n",
      "Episode: 158 Exploration P: 0.0247 Total reward: -839.8651542683363 SOC: 0.3381 Cumulative_SOC_deviation: 124.6157 Fuel Consumption: 92.1708\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.680\n",
      "Episode: 159 Exploration P: 0.0243 Total reward: -476.78587029214515 SOC: 0.5705 Cumulative_SOC_deviation: 61.5528 Fuel Consumption: 107.4688\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.787\n",
      "Episode: 160 Exploration P: 0.0240 Total reward: -447.54217421722177 SOC: 0.5425 Cumulative_SOC_deviation: 56.9604 Fuel Consumption: 105.7800\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.851\n",
      "Episode: 161 Exploration P: 0.0236 Total reward: -2333.7475359340733 SOC: 0.1314 Cumulative_SOC_deviation: 374.8223 Fuel Consumption: 84.8139\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.243\n",
      "Episode: 162 Exploration P: 0.0232 Total reward: -245.0660602167727 SOC: 0.5512 Cumulative_SOC_deviation: 22.9629 Fuel Consumption: 107.2889\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.114\n",
      "Episode: 163 Exploration P: 0.0229 Total reward: -474.9132807824601 SOC: 0.5535 Cumulative_SOC_deviation: 61.4217 Fuel Consumption: 106.3831\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.557\n",
      "Episode: 164 Exploration P: 0.0225 Total reward: -287.32706643362815 SOC: 0.5688 Cumulative_SOC_deviation: 29.8098 Fuel Consumption: 108.4681\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.456\n",
      "Episode: 165 Exploration P: 0.0222 Total reward: -292.61111400753686 SOC: 0.5919 Cumulative_SOC_deviation: 30.6373 Fuel Consumption: 108.7873\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.364\n",
      "Episode: 166 Exploration P: 0.0218 Total reward: -222.62709989151134 SOC: 0.5913 Cumulative_SOC_deviation: 18.9654 Fuel Consumption: 108.8349\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.139\n",
      "Episode: 167 Exploration P: 0.0215 Total reward: -269.8504573166247 SOC: 0.5924 Cumulative_SOC_deviation: 26.6390 Fuel Consumption: 110.0167\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.373\n",
      "Episode: 168 Exploration P: 0.0212 Total reward: -269.07076535218124 SOC: 0.5662 Cumulative_SOC_deviation: 26.6132 Fuel Consumption: 109.3916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.492\n",
      "Episode: 169 Exploration P: 0.0209 Total reward: -288.33732298993067 SOC: 0.5840 Cumulative_SOC_deviation: 30.0114 Fuel Consumption: 108.2687\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.479\n",
      "Episode: 170 Exploration P: 0.0206 Total reward: -230.65384252532124 SOC: 0.5865 Cumulative_SOC_deviation: 20.5744 Fuel Consumption: 107.2072\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.978\n",
      "Episode: 171 Exploration P: 0.0203 Total reward: -315.0389393579629 SOC: 0.5728 Cumulative_SOC_deviation: 33.8201 Fuel Consumption: 112.1182\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.088\n",
      "Episode: 172 Exploration P: 0.0200 Total reward: -364.98296802297244 SOC: 0.5177 Cumulative_SOC_deviation: 42.7520 Fuel Consumption: 108.4711\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.140\n",
      "Episode: 173 Exploration P: 0.0198 Total reward: -509.57387107021464 SOC: 0.5616 Cumulative_SOC_deviation: 66.0288 Fuel Consumption: 113.4012\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.047\n",
      "Episode: 174 Exploration P: 0.0195 Total reward: -838.0506840989328 SOC: 0.5345 Cumulative_SOC_deviation: 121.6262 Fuel Consumption: 108.2932\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.930\n",
      "Episode: 175 Exploration P: 0.0192 Total reward: -275.39345129975237 SOC: 0.5815 Cumulative_SOC_deviation: 28.0495 Fuel Consumption: 107.0964\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.001\n",
      "Episode: 176 Exploration P: 0.0190 Total reward: -189.12454615673602 SOC: 0.5818 Cumulative_SOC_deviation: 13.8059 Fuel Consumption: 106.2893\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.785\n",
      "Episode: 177 Exploration P: 0.0188 Total reward: -224.53362263020588 SOC: 0.6069 Cumulative_SOC_deviation: 19.3553 Fuel Consumption: 108.4020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.783\n",
      "Episode: 178 Exploration P: 0.0185 Total reward: -200.01337516877692 SOC: 0.6050 Cumulative_SOC_deviation: 15.3989 Fuel Consumption: 107.6199\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.781\n",
      "Episode: 179 Exploration P: 0.0183 Total reward: -175.14104986632367 SOC: 0.5885 Cumulative_SOC_deviation: 11.4378 Fuel Consumption: 106.5141\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.964\n",
      "Episode: 180 Exploration P: 0.0181 Total reward: -194.96886769322674 SOC: 0.5955 Cumulative_SOC_deviation: 14.6277 Fuel Consumption: 107.2028\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.082\n",
      "Episode: 181 Exploration P: 0.0178 Total reward: -414.353985391139 SOC: 0.5937 Cumulative_SOC_deviation: 50.8912 Fuel Consumption: 109.0068\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.089\n",
      "Episode: 182 Exploration P: 0.0176 Total reward: -243.6660042028066 SOC: 0.5933 Cumulative_SOC_deviation: 22.7549 Fuel Consumption: 107.1364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.728\n",
      "Episode: 183 Exploration P: 0.0174 Total reward: -233.31937075570656 SOC: 0.5970 Cumulative_SOC_deviation: 21.0054 Fuel Consumption: 107.2868\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.066\n",
      "Episode: 184 Exploration P: 0.0172 Total reward: -201.65570174181016 SOC: 0.5867 Cumulative_SOC_deviation: 15.8460 Fuel Consumption: 106.5799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.417\n",
      "Episode: 185 Exploration P: 0.0170 Total reward: -365.51066562665113 SOC: 0.5796 Cumulative_SOC_deviation: 43.1225 Fuel Consumption: 106.7754\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.988\n",
      "Episode: 186 Exploration P: 0.0168 Total reward: -434.3637754666682 SOC: 0.5858 Cumulative_SOC_deviation: 53.5032 Fuel Consumption: 113.3447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.746\n",
      "Episode: 187 Exploration P: 0.0167 Total reward: -1357.0760651605297 SOC: 0.2426 Cumulative_SOC_deviation: 211.5138 Fuel Consumption: 87.9930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.128\n",
      "Episode: 188 Exploration P: 0.0165 Total reward: -3043.7086467746994 SOC: 0.0754 Cumulative_SOC_deviation: 493.1727 Fuel Consumption: 84.6722\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.077\n",
      "Episode: 189 Exploration P: 0.0163 Total reward: -655.8902873307396 SOC: 0.5569 Cumulative_SOC_deviation: 90.0202 Fuel Consumption: 115.7692\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.014\n",
      "Episode: 190 Exploration P: 0.0161 Total reward: -1009.1210618346196 SOC: 0.5839 Cumulative_SOC_deviation: 150.2515 Fuel Consumption: 107.6118\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.058\n",
      "Episode: 191 Exploration P: 0.0160 Total reward: -211.80634827138385 SOC: 0.5917 Cumulative_SOC_deviation: 17.4645 Fuel Consumption: 107.0193\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.206\n",
      "Episode: 192 Exploration P: 0.0158 Total reward: -243.33202638251075 SOC: 0.5602 Cumulative_SOC_deviation: 22.8873 Fuel Consumption: 106.0080\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.606\n",
      "Episode: 193 Exploration P: 0.0156 Total reward: -375.07989829622164 SOC: 0.5170 Cumulative_SOC_deviation: 45.4387 Fuel Consumption: 102.4480\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.318\n",
      "Episode: 194 Exploration P: 0.0155 Total reward: -708.1528048587747 SOC: 0.5522 Cumulative_SOC_deviation: 99.7005 Fuel Consumption: 109.9495\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.157\n",
      "Episode: 195 Exploration P: 0.0153 Total reward: -901.9262145825905 SOC: 0.5844 Cumulative_SOC_deviation: 132.4082 Fuel Consumption: 107.4769\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.234\n",
      "Episode: 196 Exploration P: 0.0152 Total reward: -357.13142588190595 SOC: 0.5837 Cumulative_SOC_deviation: 41.1437 Fuel Consumption: 110.2692\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.992\n",
      "Episode: 197 Exploration P: 0.0151 Total reward: -246.2368696555034 SOC: 0.5814 Cumulative_SOC_deviation: 22.4184 Fuel Consumption: 111.7265\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.075\n",
      "Episode: 198 Exploration P: 0.0149 Total reward: -251.69998076707736 SOC: 0.5905 Cumulative_SOC_deviation: 23.8851 Fuel Consumption: 108.3897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.050\n",
      "Episode: 199 Exploration P: 0.0148 Total reward: -310.9226802977732 SOC: 0.5328 Cumulative_SOC_deviation: 34.3291 Fuel Consumption: 104.9480\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.898\n",
      "Episode: 200 Exploration P: 0.0147 Total reward: -507.32121686137003 SOC: 0.5692 Cumulative_SOC_deviation: 66.7676 Fuel Consumption: 106.7155\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "# print(env.version)\n",
    "\n",
    "# num_trials = 1\n",
    "reward_factors = [4, 5, 6]\n",
    "results_dict = {} \n",
    "driving_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "driving_cycle = sio.loadmat(driving_cycle_path)\n",
    "driving_cycle = driving_cycle[\"sch_cycle\"][:, 1]\n",
    "\n",
    "for reward_factor in reward_factors: \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(reward_factor))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "#         driving_cycle = driver.get_cycle() \n",
    "        env = initialization_env(driving_cycle, reward_factor)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "#             history = test_agent(actor_model, reward_factor)\n",
    "            history = env.history \n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "            \n",
    "#         if (ep + 1) % 200 == 0:             \n",
    "    root = \"DDPG_cycleOne_reward_factor{}\".format(reward_factor)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "            \n",
    "    \n",
    "    results_dict[reward_factor] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG_cycleOne_4to6.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
