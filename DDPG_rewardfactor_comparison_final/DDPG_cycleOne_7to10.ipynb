{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "import scipy.io as sio\n",
    "\n",
    "from vehicle_model_variant import Environment \n",
    "from cell_model import CellModel \n",
    "from driver_MDP import Driver_MDP \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "# env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "driver = Driver_MDP(0.02)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200 \n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1.0 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "#     actor_model.load_weights(\"./DDPG1_trial1/actor_model_checkpoint\")\n",
    "#     critic_model.load_weights(\"./DDPG1_trial1/critic_model_checkpoint\")\n",
    "#     target_actor.load_weights(\"./DDPG1_trial1/target_actor_checkpoint\")\n",
    "#     target_critic.load_weights(\"./DDPG1_trial1/target_critic_checkpoint\")\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    if not os.path.exists(root): \n",
    "        os.makedirs(root)\n",
    "        \n",
    "    actor_model.save_weights(\"./{}/actor_model.h5\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model.h5\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor.h5\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic.h5\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor):\n",
    "#     test_cycle = driver.get_cycle() \n",
    "    test_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "    test_cycle = sio.loadmat(test_cycle_path)\n",
    "    test_cycle = test_cycle[\"sch_cycle\"][:, 1]\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "#     print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_cycle)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env.history[\"Action\"])\n",
    "    plt.show() \n",
    "    return env.history  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 7\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.446\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3537.6415759272327 SOC: 1.0000 Cumulative_SOC_deviation: 478.6676 Fuel Consumption: 186.9685\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.534\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3583.7075839103486 SOC: 0.9999 Cumulative_SOC_deviation: 484.9024 Fuel Consumption: 189.3908\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.174\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -3632.6107087301025 SOC: 1.0000 Cumulative_SOC_deviation: 491.8252 Fuel Consumption: 189.8341\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 34.084\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -3489.5542104969204 SOC: 1.0000 Cumulative_SOC_deviation: 471.5005 Fuel Consumption: 189.0507\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.679\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -3576.687593350631 SOC: 1.0000 Cumulative_SOC_deviation: 483.5285 Fuel Consumption: 191.9884\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.327\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -3606.717838526111 SOC: 0.9997 Cumulative_SOC_deviation: 488.6063 Fuel Consumption: 186.4737\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.429\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -3487.0031534416844 SOC: 1.0000 Cumulative_SOC_deviation: 471.9195 Fuel Consumption: 183.5668\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.823\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -3455.5056388396292 SOC: 1.0000 Cumulative_SOC_deviation: 468.6200 Fuel Consumption: 175.1659\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.936\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -3388.219434850454 SOC: 0.9991 Cumulative_SOC_deviation: 459.1858 Fuel Consumption: 173.9186\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.345\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -3390.735026134302 SOC: 1.0000 Cumulative_SOC_deviation: 459.6615 Fuel Consumption: 173.1043\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.306\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -3349.307646249946 SOC: 1.0000 Cumulative_SOC_deviation: 454.1277 Fuel Consumption: 170.4139\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.196\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -3391.656740419343 SOC: 1.0000 Cumulative_SOC_deviation: 460.3911 Fuel Consumption: 168.9193\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.683\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -3193.5283647712245 SOC: 0.9995 Cumulative_SOC_deviation: 432.8999 Fuel Consumption: 163.2293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.707\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -3038.0068935782906 SOC: 0.9988 Cumulative_SOC_deviation: 410.8195 Fuel Consumption: 162.2707\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.351\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2952.267704008119 SOC: 0.9988 Cumulative_SOC_deviation: 398.9789 Fuel Consumption: 159.4154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.715\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -2934.862710979996 SOC: 0.9980 Cumulative_SOC_deviation: 396.8326 Fuel Consumption: 157.0342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.287\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -2774.2172445060255 SOC: 0.9976 Cumulative_SOC_deviation: 374.1763 Fuel Consumption: 154.9830\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.921\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -2297.1007701782637 SOC: 0.9994 Cumulative_SOC_deviation: 306.2038 Fuel Consumption: 153.6739\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.245\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -2780.3988941049415 SOC: 0.9985 Cumulative_SOC_deviation: 374.7561 Fuel Consumption: 157.1064\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.045\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -2563.680727280213 SOC: 0.9961 Cumulative_SOC_deviation: 344.1527 Fuel Consumption: 154.6119\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.324\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -2551.5327770134786 SOC: 1.0000 Cumulative_SOC_deviation: 342.3333 Fuel Consumption: 155.1994\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.483\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2369.7535927731483 SOC: 0.9792 Cumulative_SOC_deviation: 316.8155 Fuel Consumption: 152.0452\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.420\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1639.4705392504998 SOC: 0.9428 Cumulative_SOC_deviation: 212.6837 Fuel Consumption: 150.6846\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.416\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1400.2872478586917 SOC: 0.9368 Cumulative_SOC_deviation: 178.5765 Fuel Consumption: 150.2516\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.572\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1281.448183248717 SOC: 0.9348 Cumulative_SOC_deviation: 161.5082 Fuel Consumption: 150.8907\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.338\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1358.515954542133 SOC: 0.9130 Cumulative_SOC_deviation: 172.8301 Fuel Consumption: 148.7054\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.080\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1099.868447252078 SOC: 0.9018 Cumulative_SOC_deviation: 135.8996 Fuel Consumption: 148.5714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.614\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -610.447839379491 SOC: 0.7546 Cumulative_SOC_deviation: 67.4387 Fuel Consumption: 138.3769\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.892\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -1073.9038336371468 SOC: 0.8278 Cumulative_SOC_deviation: 132.9929 Fuel Consumption: 142.9536\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.308\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -713.8030257373596 SOC: 0.7691 Cumulative_SOC_deviation: 82.1286 Fuel Consumption: 138.9026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.204\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -467.14698729854325 SOC: 0.6317 Cumulative_SOC_deviation: 48.5163 Fuel Consumption: 127.5330\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.243\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -844.2427003307353 SOC: 0.6021 Cumulative_SOC_deviation: 102.6095 Fuel Consumption: 125.9765\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.959\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -645.6081459213738 SOC: 0.6362 Cumulative_SOC_deviation: 73.8546 Fuel Consumption: 128.6256\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.636\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -520.5315316535615 SOC: 0.6949 Cumulative_SOC_deviation: 55.3254 Fuel Consumption: 133.2539\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.001\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -893.7899633639571 SOC: 0.5318 Cumulative_SOC_deviation: 110.4681 Fuel Consumption: 120.5133\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.316\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -668.3075193072452 SOC: 0.5977 Cumulative_SOC_deviation: 77.4523 Fuel Consumption: 126.1414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.244\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -2053.641068363157 SOC: 0.2986 Cumulative_SOC_deviation: 278.5040 Fuel Consumption: 104.1134\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.235\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -2047.873348027324 SOC: 0.3153 Cumulative_SOC_deviation: 277.4886 Fuel Consumption: 105.4534\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.154\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1881.7845979832016 SOC: 0.3332 Cumulative_SOC_deviation: 253.5761 Fuel Consumption: 106.7522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.338\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -2848.7259050049133 SOC: 0.1757 Cumulative_SOC_deviation: 393.1301 Fuel Consumption: 96.8154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.663\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -2659.6458844479753 SOC: 0.2105 Cumulative_SOC_deviation: 365.8447 Fuel Consumption: 98.7326\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.216\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -3124.9057690032014 SOC: 0.0854 Cumulative_SOC_deviation: 433.4649 Fuel Consumption: 90.6512\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.998\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -2835.5461276370124 SOC: 0.1481 Cumulative_SOC_deviation: 391.6257 Fuel Consumption: 94.1662\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.298\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -2744.9140661776883 SOC: 0.1470 Cumulative_SOC_deviation: 378.6311 Fuel Consumption: 94.4961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.275\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -2907.3211209263854 SOC: 0.0934 Cumulative_SOC_deviation: 402.4064 Fuel Consumption: 90.4760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment_essential_modelChange\\DDPG_rewardfactor_comparison_final\\vehicle_model_variant.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.219\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -3419.069927615135 SOC: 0.4894 Cumulative_SOC_deviation: 470.8948 Fuel Consumption: 122.8067\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.052\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -180.07960002899995 SOC: 0.6153 Cumulative_SOC_deviation: 8.3698 Fuel Consumption: 121.4908\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.108\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -179.4393571430983 SOC: 0.6090 Cumulative_SOC_deviation: 8.3253 Fuel Consumption: 121.1621\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.052\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -173.86732768549598 SOC: 0.5982 Cumulative_SOC_deviation: 7.6981 Fuel Consumption: 119.9803\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.966\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -193.77791245426988 SOC: 0.6149 Cumulative_SOC_deviation: 10.2881 Fuel Consumption: 121.7609\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.964\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -188.31761657837654 SOC: 0.5928 Cumulative_SOC_deviation: 10.1632 Fuel Consumption: 117.1750\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.875\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -213.7135664900156 SOC: 0.5934 Cumulative_SOC_deviation: 13.6814 Fuel Consumption: 117.9440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.920\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -185.52958165421143 SOC: 0.6152 Cumulative_SOC_deviation: 9.6326 Fuel Consumption: 118.1014\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.010\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -173.37556909575937 SOC: 0.5944 Cumulative_SOC_deviation: 8.1399 Fuel Consumption: 116.3962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.048\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -193.69359415648475 SOC: 0.5954 Cumulative_SOC_deviation: 11.0615 Fuel Consumption: 116.2633\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.247\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -229.70132232600713 SOC: 0.5872 Cumulative_SOC_deviation: 16.3925 Fuel Consumption: 114.9537\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.178\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -222.6481175927565 SOC: 0.5845 Cumulative_SOC_deviation: 15.2904 Fuel Consumption: 115.6151\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.956\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -232.11419611497053 SOC: 0.5927 Cumulative_SOC_deviation: 16.4781 Fuel Consumption: 116.7677\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.336\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -220.5466942447799 SOC: 0.5897 Cumulative_SOC_deviation: 15.0253 Fuel Consumption: 115.3694\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.318\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -230.11860765635916 SOC: 0.5919 Cumulative_SOC_deviation: 16.4533 Fuel Consumption: 114.9458\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.219\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -261.174155812894 SOC: 0.5883 Cumulative_SOC_deviation: 20.9690 Fuel Consumption: 114.3908\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.260\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -249.552468849396 SOC: 0.5833 Cumulative_SOC_deviation: 19.5290 Fuel Consumption: 112.8494\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.946\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -268.52052796241315 SOC: 0.5901 Cumulative_SOC_deviation: 21.9832 Fuel Consumption: 114.6379\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.304\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -259.8916039788282 SOC: 0.5812 Cumulative_SOC_deviation: 21.0356 Fuel Consumption: 112.6426\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.073\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -246.40926034180453 SOC: 0.5769 Cumulative_SOC_deviation: 19.0085 Fuel Consumption: 113.3494\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.153\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -281.99209946158584 SOC: 0.5879 Cumulative_SOC_deviation: 23.9083 Fuel Consumption: 114.6338\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.763\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -272.3572517156434 SOC: 0.5852 Cumulative_SOC_deviation: 22.9036 Fuel Consumption: 112.0317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.029\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -313.2849380647646 SOC: 0.5809 Cumulative_SOC_deviation: 28.7059 Fuel Consumption: 112.3436\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.929\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -284.8727751057258 SOC: 0.5899 Cumulative_SOC_deviation: 24.2446 Fuel Consumption: 115.1607\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.016\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -272.7773836120605 SOC: 0.5851 Cumulative_SOC_deviation: 22.7187 Fuel Consumption: 113.7468\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.579\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -318.0435227443141 SOC: 0.5648 Cumulative_SOC_deviation: 29.6512 Fuel Consumption: 110.4854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 117.695\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -371.7728695359042 SOC: 0.5809 Cumulative_SOC_deviation: 37.0544 Fuel Consumption: 112.3920\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 121.211\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -334.86799677445777 SOC: 0.5789 Cumulative_SOC_deviation: 31.7406 Fuel Consumption: 112.6839\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 116.426\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -372.27523864345403 SOC: 0.5875 Cumulative_SOC_deviation: 37.0940 Fuel Consumption: 112.6173\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.560\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -299.56262588898255 SOC: 0.5841 Cumulative_SOC_deviation: 26.6435 Fuel Consumption: 113.0583\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 118.829\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -314.25325549211976 SOC: 0.5939 Cumulative_SOC_deviation: 28.6501 Fuel Consumption: 113.7024\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.436\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -331.7297082728548 SOC: 0.5735 Cumulative_SOC_deviation: 31.4112 Fuel Consumption: 111.8516\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.965\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -313.1082702302933 SOC: 0.5789 Cumulative_SOC_deviation: 28.7117 Fuel Consumption: 112.1265\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.623\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -393.1329702028273 SOC: 0.5780 Cumulative_SOC_deviation: 40.1851 Fuel Consumption: 111.8374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.710\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -398.4032452456264 SOC: 0.5919 Cumulative_SOC_deviation: 40.8174 Fuel Consumption: 112.6818\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.643\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -254.93708584378803 SOC: 0.5774 Cumulative_SOC_deviation: 20.3620 Fuel Consumption: 112.4033\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.910\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -370.0119019111665 SOC: 0.5938 Cumulative_SOC_deviation: 36.6430 Fuel Consumption: 113.5109\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.069\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -227.6740982587865 SOC: 0.5652 Cumulative_SOC_deviation: 16.8312 Fuel Consumption: 109.8555\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.988\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -402.69083363859676 SOC: 0.5673 Cumulative_SOC_deviation: 41.6956 Fuel Consumption: 110.8216\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.115\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -242.22173782208685 SOC: 0.5887 Cumulative_SOC_deviation: 18.7100 Fuel Consumption: 111.2516\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.768\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -258.1647935963899 SOC: 0.5891 Cumulative_SOC_deviation: 20.7794 Fuel Consumption: 112.7088\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.690\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -282.5834149059805 SOC: 0.5842 Cumulative_SOC_deviation: 23.9886 Fuel Consumption: 114.6631\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.418\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -260.8614083727572 SOC: 0.5903 Cumulative_SOC_deviation: 20.9927 Fuel Consumption: 113.9123\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.644\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -374.1221542501641 SOC: 0.5518 Cumulative_SOC_deviation: 37.7654 Fuel Consumption: 109.7647\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.144\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -279.07862081970893 SOC: 0.5595 Cumulative_SOC_deviation: 24.0632 Fuel Consumption: 110.6365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.273\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -283.07190820822274 SOC: 0.5883 Cumulative_SOC_deviation: 24.4728 Fuel Consumption: 111.7623\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.927\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -238.08422517998727 SOC: 0.5789 Cumulative_SOC_deviation: 18.1390 Fuel Consumption: 111.1111\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.139\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -323.22994235935425 SOC: 0.5968 Cumulative_SOC_deviation: 30.1053 Fuel Consumption: 112.4926\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.586\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -296.3062862369304 SOC: 0.5934 Cumulative_SOC_deviation: 26.2728 Fuel Consumption: 112.3968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.584\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -213.65170366961453 SOC: 0.5908 Cumulative_SOC_deviation: 14.5618 Fuel Consumption: 111.7192\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.842\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -248.90180527145256 SOC: 0.5805 Cumulative_SOC_deviation: 19.6603 Fuel Consumption: 111.2794\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.507\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -250.5930427944373 SOC: 0.5848 Cumulative_SOC_deviation: 19.8159 Fuel Consumption: 111.8818\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.534\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -272.00990834588634 SOC: 0.5928 Cumulative_SOC_deviation: 22.6073 Fuel Consumption: 113.7586\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.414\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -245.84365792812505 SOC: 0.5886 Cumulative_SOC_deviation: 19.1665 Fuel Consumption: 111.6783\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.271\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -244.91941229731302 SOC: 0.5850 Cumulative_SOC_deviation: 18.8487 Fuel Consumption: 112.9787\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.539\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -276.2644357173463 SOC: 0.5842 Cumulative_SOC_deviation: 23.3293 Fuel Consumption: 112.9592\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.568\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -212.94865112586714 SOC: 0.5925 Cumulative_SOC_deviation: 14.4387 Fuel Consumption: 111.8778\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.504\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -253.14580790847754 SOC: 0.5820 Cumulative_SOC_deviation: 20.4088 Fuel Consumption: 110.2844\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.473\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -264.9837822584296 SOC: 0.5831 Cumulative_SOC_deviation: 21.9905 Fuel Consumption: 111.0504\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.952\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -362.1197875031284 SOC: 0.5825 Cumulative_SOC_deviation: 35.6355 Fuel Consumption: 112.6710\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.302\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -258.1182571670534 SOC: 0.5971 Cumulative_SOC_deviation: 20.7677 Fuel Consumption: 112.7445\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.405\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -283.78293796694027 SOC: 0.5771 Cumulative_SOC_deviation: 24.6245 Fuel Consumption: 111.4114\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.425\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -364.73493348806244 SOC: 0.5747 Cumulative_SOC_deviation: 35.7691 Fuel Consumption: 114.3514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.136\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -286.9287327523561 SOC: 0.5927 Cumulative_SOC_deviation: 24.7147 Fuel Consumption: 113.9255\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.370\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -249.7470909830033 SOC: 0.5789 Cumulative_SOC_deviation: 19.5818 Fuel Consumption: 112.6743\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.354\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -295.675902891413 SOC: 0.5794 Cumulative_SOC_deviation: 26.1988 Fuel Consumption: 112.2845\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.600\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -354.8643789593624 SOC: 0.5796 Cumulative_SOC_deviation: 34.2605 Fuel Consumption: 115.0412\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.383\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -278.8383749216359 SOC: 0.5698 Cumulative_SOC_deviation: 24.1078 Fuel Consumption: 110.0836\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.352\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -375.09218057749285 SOC: 0.5708 Cumulative_SOC_deviation: 37.6765 Fuel Consumption: 111.3564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.772\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -370.1912668068287 SOC: 0.5728 Cumulative_SOC_deviation: 37.0114 Fuel Consumption: 111.1113\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.145\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -354.32700666071054 SOC: 0.5731 Cumulative_SOC_deviation: 34.6790 Fuel Consumption: 111.5738\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.068\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -308.59365453432264 SOC: 0.5847 Cumulative_SOC_deviation: 28.1111 Fuel Consumption: 111.8160\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.463\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -279.93930727166327 SOC: 0.5966 Cumulative_SOC_deviation: 23.8249 Fuel Consumption: 113.1648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.438\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -174.05926923821357 SOC: 0.5886 Cumulative_SOC_deviation: 8.8594 Fuel Consumption: 112.0436\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.800\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -292.9551589260063 SOC: 0.5783 Cumulative_SOC_deviation: 25.9101 Fuel Consumption: 111.5846\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.557\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -268.9812440337582 SOC: 0.5794 Cumulative_SOC_deviation: 22.5214 Fuel Consumption: 111.3316\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.370\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -198.59149121658464 SOC: 0.5931 Cumulative_SOC_deviation: 12.4908 Fuel Consumption: 111.1559\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.881\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -357.67841544241685 SOC: 0.5864 Cumulative_SOC_deviation: 35.0717 Fuel Consumption: 112.1766\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.618\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -266.84504612335684 SOC: 0.5901 Cumulative_SOC_deviation: 22.2925 Fuel Consumption: 110.7974\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.349\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -243.1622838407886 SOC: 0.5759 Cumulative_SOC_deviation: 19.0799 Fuel Consumption: 109.6027\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.394\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -387.5216353444421 SOC: 0.5895 Cumulative_SOC_deviation: 39.0906 Fuel Consumption: 113.8874\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.263\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -210.67281636407708 SOC: 0.5907 Cumulative_SOC_deviation: 14.5344 Fuel Consumption: 108.9323\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.821\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -313.915422463254 SOC: 0.5808 Cumulative_SOC_deviation: 29.0192 Fuel Consumption: 110.7813\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.528\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -314.2068156518165 SOC: 0.5962 Cumulative_SOC_deviation: 28.8575 Fuel Consumption: 112.2040\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.810\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -284.5858338660207 SOC: 0.5894 Cumulative_SOC_deviation: 24.7518 Fuel Consumption: 111.3229\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.552\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -383.0345443741018 SOC: 0.5570 Cumulative_SOC_deviation: 38.9806 Fuel Consumption: 110.1704\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.341\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -459.0033897919349 SOC: 0.5733 Cumulative_SOC_deviation: 49.7582 Fuel Consumption: 110.6962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.232\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -244.78284161634448 SOC: 0.5909 Cumulative_SOC_deviation: 19.0913 Fuel Consumption: 111.1439\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.779\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -213.81594962361189 SOC: 0.5953 Cumulative_SOC_deviation: 14.7734 Fuel Consumption: 110.4020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.606\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -276.14776136250043 SOC: 0.5801 Cumulative_SOC_deviation: 23.9736 Fuel Consumption: 108.3326\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.644\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -206.22820372373593 SOC: 0.5812 Cumulative_SOC_deviation: 14.0682 Fuel Consumption: 107.7508\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.438\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -279.0997414357864 SOC: 0.5837 Cumulative_SOC_deviation: 24.3567 Fuel Consumption: 108.6029\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.232\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -330.9501688329082 SOC: 0.5617 Cumulative_SOC_deviation: 31.7539 Fuel Consumption: 108.6727\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.480\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -301.940342927651 SOC: 0.5760 Cumulative_SOC_deviation: 27.5547 Fuel Consumption: 109.0574\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.796\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -267.71785166477565 SOC: 0.5930 Cumulative_SOC_deviation: 22.3773 Fuel Consumption: 111.0769\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.960\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -229.21507432462738 SOC: 0.5930 Cumulative_SOC_deviation: 17.2826 Fuel Consumption: 108.2372\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.938\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -224.09211687548535 SOC: 0.5889 Cumulative_SOC_deviation: 16.6480 Fuel Consumption: 107.5562\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.677\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -292.69557769389667 SOC: 0.5705 Cumulative_SOC_deviation: 26.3488 Fuel Consumption: 108.2541\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.451\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -404.9393972227188 SOC: 0.5530 Cumulative_SOC_deviation: 42.3692 Fuel Consumption: 108.3547\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.466\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -233.51489344694906 SOC: 0.5901 Cumulative_SOC_deviation: 18.0088 Fuel Consumption: 107.4533\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.773\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -213.67036603753348 SOC: 0.5894 Cumulative_SOC_deviation: 15.2006 Fuel Consumption: 107.2660\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.997\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -228.7379261000641 SOC: 0.5892 Cumulative_SOC_deviation: 17.2993 Fuel Consumption: 107.6428\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.915\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -262.9134999434547 SOC: 0.5849 Cumulative_SOC_deviation: 22.2571 Fuel Consumption: 107.1138\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.424\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -268.2123165110561 SOC: 0.5801 Cumulative_SOC_deviation: 23.0532 Fuel Consumption: 106.8398\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.297\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -223.32103384525547 SOC: 0.5857 Cumulative_SOC_deviation: 16.5521 Fuel Consumption: 107.4560\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.803\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -276.6347860370051 SOC: 0.5898 Cumulative_SOC_deviation: 24.2074 Fuel Consumption: 107.1828\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.750\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -228.39157896311198 SOC: 0.5924 Cumulative_SOC_deviation: 17.2935 Fuel Consumption: 107.3370\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.790\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -226.89374949783115 SOC: 0.5839 Cumulative_SOC_deviation: 17.1272 Fuel Consumption: 107.0033\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.730\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -241.40372133877457 SOC: 0.5836 Cumulative_SOC_deviation: 19.2370 Fuel Consumption: 106.7450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.889\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -238.96937260654633 SOC: 0.5849 Cumulative_SOC_deviation: 18.9288 Fuel Consumption: 106.4678\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.000\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -261.11416498803686 SOC: 0.5739 Cumulative_SOC_deviation: 22.1390 Fuel Consumption: 106.1413\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.327\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -429.5969687250346 SOC: 0.5945 Cumulative_SOC_deviation: 45.9150 Fuel Consumption: 108.1916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.532\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -255.7399990383319 SOC: 0.5863 Cumulative_SOC_deviation: 21.2413 Fuel Consumption: 107.0507\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.702\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -255.59409013420424 SOC: 0.5858 Cumulative_SOC_deviation: 21.2291 Fuel Consumption: 106.9905\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.634\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -258.6155537938144 SOC: 0.5874 Cumulative_SOC_deviation: 21.6760 Fuel Consumption: 106.8833\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.561\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -269.662218893819 SOC: 0.5856 Cumulative_SOC_deviation: 23.2372 Fuel Consumption: 107.0019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.308\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -259.9222343568228 SOC: 0.5852 Cumulative_SOC_deviation: 21.7487 Fuel Consumption: 107.6811\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 119.402\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -278.71169953601975 SOC: 0.5861 Cumulative_SOC_deviation: 24.3788 Fuel Consumption: 108.0603\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 118.063\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -236.80005721193987 SOC: 0.5909 Cumulative_SOC_deviation: 18.3180 Fuel Consumption: 108.5738\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.956\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -259.32470569122376 SOC: 0.5893 Cumulative_SOC_deviation: 21.5065 Fuel Consumption: 108.7789\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 118.177\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -262.2716262015177 SOC: 0.5818 Cumulative_SOC_deviation: 22.1730 Fuel Consumption: 107.0608\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 118.155\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -237.30917683431454 SOC: 0.5878 Cumulative_SOC_deviation: 18.5784 Fuel Consumption: 107.2605\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.912\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -240.92881845355458 SOC: 0.5908 Cumulative_SOC_deviation: 18.9310 Fuel Consumption: 108.4117\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 118.456\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -246.22952713767089 SOC: 0.5707 Cumulative_SOC_deviation: 20.0057 Fuel Consumption: 106.1896\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.323\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -318.86266862398526 SOC: 0.5852 Cumulative_SOC_deviation: 30.3670 Fuel Consumption: 106.2937\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.468\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -295.10558456681116 SOC: 0.5856 Cumulative_SOC_deviation: 26.8500 Fuel Consumption: 107.1559\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.485\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -245.65122546876486 SOC: 0.5878 Cumulative_SOC_deviation: 19.7809 Fuel Consumption: 107.1848\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.792\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -273.6532548534311 SOC: 0.5760 Cumulative_SOC_deviation: 23.9251 Fuel Consumption: 106.1775\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.989\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -330.5012588624691 SOC: 0.5745 Cumulative_SOC_deviation: 32.0835 Fuel Consumption: 105.9169\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.730\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -302.19283125520957 SOC: 0.5852 Cumulative_SOC_deviation: 27.9311 Fuel Consumption: 106.6754\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.780\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -288.9614384070211 SOC: 0.5838 Cumulative_SOC_deviation: 26.0560 Fuel Consumption: 106.5695\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.499\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -331.1044249961983 SOC: 0.5754 Cumulative_SOC_deviation: 32.1772 Fuel Consumption: 105.8639\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.561\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -283.33717590354985 SOC: 0.5798 Cumulative_SOC_deviation: 25.3127 Fuel Consumption: 106.1482\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.027\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -313.41909560493536 SOC: 0.5768 Cumulative_SOC_deviation: 29.5942 Fuel Consumption: 106.2600\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.142\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -301.3314366823428 SOC: 0.5855 Cumulative_SOC_deviation: 27.8175 Fuel Consumption: 106.6087\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.764\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -297.52806445350797 SOC: 0.5815 Cumulative_SOC_deviation: 27.3515 Fuel Consumption: 106.0674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.886\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -281.65936703362905 SOC: 0.5778 Cumulative_SOC_deviation: 25.0986 Fuel Consumption: 105.9689\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.368\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -300.40959764093805 SOC: 0.5836 Cumulative_SOC_deviation: 27.7214 Fuel Consumption: 106.3598\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.254\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -327.0105116374183 SOC: 0.5818 Cumulative_SOC_deviation: 31.5485 Fuel Consumption: 106.1713\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.215\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -269.93062183329954 SOC: 0.5791 Cumulative_SOC_deviation: 23.4068 Fuel Consumption: 106.0830\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.702\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -298.21490652355965 SOC: 0.5838 Cumulative_SOC_deviation: 27.4224 Fuel Consumption: 106.2582\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 116.635\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -303.297915642986 SOC: 0.5804 Cumulative_SOC_deviation: 28.2104 Fuel Consumption: 105.8249\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 117.251\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -295.4925766829968 SOC: 0.5786 Cumulative_SOC_deviation: 26.9910 Fuel Consumption: 106.5554\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.382\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -324.51042052090264 SOC: 0.5832 Cumulative_SOC_deviation: 31.1436 Fuel Consumption: 106.5050\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.168\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -279.09209801294105 SOC: 0.5799 Cumulative_SOC_deviation: 24.7031 Fuel Consumption: 106.1702\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.874\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -319.2465256722159 SOC: 0.5792 Cumulative_SOC_deviation: 30.5095 Fuel Consumption: 105.6799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.571\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -346.87116461989626 SOC: 0.5781 Cumulative_SOC_deviation: 34.4266 Fuel Consumption: 105.8849\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.905\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -331.8122258979068 SOC: 0.5797 Cumulative_SOC_deviation: 32.2418 Fuel Consumption: 106.1193\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.629\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -394.9619821067832 SOC: 0.5769 Cumulative_SOC_deviation: 41.3077 Fuel Consumption: 105.8079\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.328\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -377.3764864593883 SOC: 0.5775 Cumulative_SOC_deviation: 38.8168 Fuel Consumption: 105.6587\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.834\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -337.41979619527694 SOC: 0.5760 Cumulative_SOC_deviation: 33.0880 Fuel Consumption: 105.8040\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.802\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -366.3687628350313 SOC: 0.5692 Cumulative_SOC_deviation: 37.3252 Fuel Consumption: 105.0927\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.372\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -343.9193178555736 SOC: 0.5752 Cumulative_SOC_deviation: 34.0292 Fuel Consumption: 105.7151\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.792\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -354.29070088766076 SOC: 0.5760 Cumulative_SOC_deviation: 35.5158 Fuel Consumption: 105.6799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 116.270\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -344.3594493990407 SOC: 0.5771 Cumulative_SOC_deviation: 34.1279 Fuel Consumption: 105.4639\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 8\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.611\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3929.005365126103 SOC: 1.0000 Cumulative_SOC_deviation: 467.8036 Fuel Consumption: 186.5768\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.905\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -4077.3569978488204 SOC: 1.0000 Cumulative_SOC_deviation: 485.1260 Fuel Consumption: 196.3487\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.380\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -4041.8368486022364 SOC: 1.0000 Cumulative_SOC_deviation: 481.3805 Fuel Consumption: 190.7927\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer batch_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.398\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -4071.138180144975 SOC: 1.0000 Cumulative_SOC_deviation: 485.6655 Fuel Consumption: 185.8140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.589\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -4056.071676603807 SOC: 1.0000 Cumulative_SOC_deviation: 483.7912 Fuel Consumption: 185.7418\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.789\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -4034.899301152034 SOC: 1.0000 Cumulative_SOC_deviation: 481.5390 Fuel Consumption: 182.5876\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.663\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -4044.5681448210294 SOC: 0.9994 Cumulative_SOC_deviation: 483.1135 Fuel Consumption: 179.6601\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.173\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -3812.025541710309 SOC: 1.0000 Cumulative_SOC_deviation: 454.2067 Fuel Consumption: 178.3717\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.803\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -3864.5463852443672 SOC: 0.9999 Cumulative_SOC_deviation: 461.0991 Fuel Consumption: 175.7534\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.762\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -3723.2448203384206 SOC: 0.9994 Cumulative_SOC_deviation: 443.6864 Fuel Consumption: 173.7537\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.872\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -3722.061961992216 SOC: 0.9994 Cumulative_SOC_deviation: 444.3464 Fuel Consumption: 167.2906\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.070\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -3557.8063907331125 SOC: 0.9997 Cumulative_SOC_deviation: 424.0992 Fuel Consumption: 165.0126\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.288\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -3593.742721118746 SOC: 0.9989 Cumulative_SOC_deviation: 428.0527 Fuel Consumption: 169.3213\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.351\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -3544.62802704076 SOC: 1.0000 Cumulative_SOC_deviation: 422.3334 Fuel Consumption: 165.9609\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.595\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -3369.822179716635 SOC: 1.0000 Cumulative_SOC_deviation: 401.0947 Fuel Consumption: 161.0646\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.351\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -3460.8363623172013 SOC: 0.9991 Cumulative_SOC_deviation: 412.4341 Fuel Consumption: 161.3636\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.871\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -2963.585977180901 SOC: 1.0000 Cumulative_SOC_deviation: 351.2016 Fuel Consumption: 153.9728\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.549\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -3172.9073569945776 SOC: 0.9940 Cumulative_SOC_deviation: 377.2534 Fuel Consumption: 154.8799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.517\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -3000.8249910842906 SOC: 0.9998 Cumulative_SOC_deviation: 355.4790 Fuel Consumption: 156.9930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.089\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -2726.6244663810103 SOC: 0.9998 Cumulative_SOC_deviation: 321.2954 Fuel Consumption: 156.2612\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.532\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -2616.2695579245765 SOC: 0.9994 Cumulative_SOC_deviation: 307.6724 Fuel Consumption: 154.8902\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.805\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2573.4672517051854 SOC: 0.9844 Cumulative_SOC_deviation: 302.5695 Fuel Consumption: 152.9111\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.096\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -2051.601862128461 SOC: 0.9644 Cumulative_SOC_deviation: 237.4858 Fuel Consumption: 151.7154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.140\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1658.3521738237894 SOC: 0.9603 Cumulative_SOC_deviation: 188.2188 Fuel Consumption: 152.6018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.673\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1431.306025056881 SOC: 0.9299 Cumulative_SOC_deviation: 160.0931 Fuel Consumption: 150.5609\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.227\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -773.4882369840217 SOC: 0.7726 Cumulative_SOC_deviation: 79.4031 Fuel Consumption: 138.2635\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.852\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1323.0461795914657 SOC: 0.9040 Cumulative_SOC_deviation: 146.8184 Fuel Consumption: 148.4993\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.331\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -931.0899919355398 SOC: 0.8470 Cumulative_SOC_deviation: 98.1756 Fuel Consumption: 145.6852\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.944\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -906.243948660209 SOC: 0.7760 Cumulative_SOC_deviation: 95.8455 Fuel Consumption: 139.4799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.808\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -642.4244445933591 SOC: 0.7143 Cumulative_SOC_deviation: 63.5497 Fuel Consumption: 134.0270\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.210\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -579.3210670208224 SOC: 0.7274 Cumulative_SOC_deviation: 55.3963 Fuel Consumption: 136.1504\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.600\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -1088.4959230806205 SOC: 0.5574 Cumulative_SOC_deviation: 120.7427 Fuel Consumption: 122.5542\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.110\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1064.1679204927682 SOC: 0.4925 Cumulative_SOC_deviation: 118.3073 Fuel Consumption: 117.7095\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.708\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -1278.1380225984335 SOC: 0.5156 Cumulative_SOC_deviation: 144.8435 Fuel Consumption: 119.3897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.809\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -1014.4076978095128 SOC: 0.5270 Cumulative_SOC_deviation: 111.6659 Fuel Consumption: 121.0802\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.882\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1602.011662011499 SOC: 0.6051 Cumulative_SOC_deviation: 184.7658 Fuel Consumption: 123.8849\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.464\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -262.25317657105796 SOC: 0.6532 Cumulative_SOC_deviation: 17.0808 Fuel Consumption: 125.6071\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.220\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -275.04281384001376 SOC: 0.6288 Cumulative_SOC_deviation: 18.6557 Fuel Consumption: 125.7974\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.607\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -224.34723788593342 SOC: 0.6015 Cumulative_SOC_deviation: 12.6705 Fuel Consumption: 122.9832\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.715\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -291.1943933367133 SOC: 0.6357 Cumulative_SOC_deviation: 20.8370 Fuel Consumption: 124.4982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.730\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -209.32789361915323 SOC: 0.6094 Cumulative_SOC_deviation: 11.0383 Fuel Consumption: 121.0218\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.151\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -196.81769615861847 SOC: 0.5959 Cumulative_SOC_deviation: 9.7567 Fuel Consumption: 118.7640\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.111\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -185.3097621092071 SOC: 0.6053 Cumulative_SOC_deviation: 8.1221 Fuel Consumption: 120.3332\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.464\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -243.81266489857254 SOC: 0.5969 Cumulative_SOC_deviation: 15.5609 Fuel Consumption: 119.3253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.188\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -196.2798213771952 SOC: 0.6110 Cumulative_SOC_deviation: 9.6143 Fuel Consumption: 119.3657\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.705\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -186.88060553644522 SOC: 0.5915 Cumulative_SOC_deviation: 8.6186 Fuel Consumption: 117.9318\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.899\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -212.40162706742123 SOC: 0.5974 Cumulative_SOC_deviation: 11.7781 Fuel Consumption: 118.1770\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 125.590\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -162.00216035154222 SOC: 0.5999 Cumulative_SOC_deviation: 5.6999 Fuel Consumption: 116.4031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 139.834\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -181.21159071206867 SOC: 0.6004 Cumulative_SOC_deviation: 7.9782 Fuel Consumption: 117.3860\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.330\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -196.76386207818538 SOC: 0.5943 Cumulative_SOC_deviation: 10.0721 Fuel Consumption: 116.1867\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.291\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -178.44767064283695 SOC: 0.5895 Cumulative_SOC_deviation: 7.8692 Fuel Consumption: 115.4940\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.439\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -187.8340089070635 SOC: 0.6029 Cumulative_SOC_deviation: 8.7650 Fuel Consumption: 117.7138\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.399\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -180.7521458914977 SOC: 0.5939 Cumulative_SOC_deviation: 8.0448 Fuel Consumption: 116.3935\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.045\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -193.29647813412285 SOC: 0.5966 Cumulative_SOC_deviation: 9.6596 Fuel Consumption: 116.0193\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.038\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -198.3411464579732 SOC: 0.6036 Cumulative_SOC_deviation: 10.2977 Fuel Consumption: 115.9597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.354\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -171.79451442869987 SOC: 0.5941 Cumulative_SOC_deviation: 7.1605 Fuel Consumption: 114.5104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.955\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -190.34893169189726 SOC: 0.6037 Cumulative_SOC_deviation: 9.3167 Fuel Consumption: 115.8151\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.832\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -181.1565082956968 SOC: 0.5932 Cumulative_SOC_deviation: 8.3050 Fuel Consumption: 114.7167\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.104\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -192.50457340230935 SOC: 0.5960 Cumulative_SOC_deviation: 9.8078 Fuel Consumption: 114.0419\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.479\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -206.29674570733374 SOC: 0.5938 Cumulative_SOC_deviation: 11.4792 Fuel Consumption: 114.4634\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.002\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -223.04044943164848 SOC: 0.5924 Cumulative_SOC_deviation: 13.7034 Fuel Consumption: 113.4130\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.942\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -214.15742841834066 SOC: 0.5934 Cumulative_SOC_deviation: 12.5334 Fuel Consumption: 113.8904\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.959\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -195.19394355243952 SOC: 0.5923 Cumulative_SOC_deviation: 10.2058 Fuel Consumption: 113.5473\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.549\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -193.4837275013655 SOC: 0.5906 Cumulative_SOC_deviation: 10.0277 Fuel Consumption: 113.2620\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.002\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -217.23659937075473 SOC: 0.5889 Cumulative_SOC_deviation: 13.1011 Fuel Consumption: 112.4276\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.839\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -213.73916202870114 SOC: 0.5951 Cumulative_SOC_deviation: 12.5161 Fuel Consumption: 113.6106\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.172\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -208.9148267958394 SOC: 0.5897 Cumulative_SOC_deviation: 12.0474 Fuel Consumption: 112.5355\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.208\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -219.2247196513517 SOC: 0.5922 Cumulative_SOC_deviation: 13.4029 Fuel Consumption: 112.0012\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.771\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -231.2892811056696 SOC: 0.5908 Cumulative_SOC_deviation: 14.9144 Fuel Consumption: 111.9743\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.810\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -218.48287115680986 SOC: 0.5973 Cumulative_SOC_deviation: 13.2384 Fuel Consumption: 112.5759\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.189\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -233.70169850397542 SOC: 0.5834 Cumulative_SOC_deviation: 15.2716 Fuel Consumption: 111.5288\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.713\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -223.88703539091597 SOC: 0.5883 Cumulative_SOC_deviation: 13.9798 Fuel Consumption: 112.0486\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.378\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -218.30021431438223 SOC: 0.5901 Cumulative_SOC_deviation: 13.2461 Fuel Consumption: 112.3313\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.331\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -264.5997759008046 SOC: 0.5933 Cumulative_SOC_deviation: 19.1869 Fuel Consumption: 111.1050\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.619\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -228.3680574467941 SOC: 0.5886 Cumulative_SOC_deviation: 14.6135 Fuel Consumption: 111.4599\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.688\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -258.38702299062186 SOC: 0.5844 Cumulative_SOC_deviation: 18.4382 Fuel Consumption: 110.8814\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.646\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -273.16184764102405 SOC: 0.5858 Cumulative_SOC_deviation: 20.3664 Fuel Consumption: 110.2310\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.165\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -227.16138467002082 SOC: 0.5883 Cumulative_SOC_deviation: 14.4816 Fuel Consumption: 111.3085\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.171\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -271.34208295447684 SOC: 0.5866 Cumulative_SOC_deviation: 20.1581 Fuel Consumption: 110.0775\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.809\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -205.74792679374372 SOC: 0.5871 Cumulative_SOC_deviation: 11.9305 Fuel Consumption: 110.3041\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.416\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -256.17169817656844 SOC: 0.5909 Cumulative_SOC_deviation: 18.1823 Fuel Consumption: 110.7136\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.124\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -244.3787999801278 SOC: 0.5904 Cumulative_SOC_deviation: 16.7941 Fuel Consumption: 110.0258\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.976\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -221.25924349096852 SOC: 0.5916 Cumulative_SOC_deviation: 13.8633 Fuel Consumption: 110.3527\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.915\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -226.67705325356022 SOC: 0.5863 Cumulative_SOC_deviation: 14.5776 Fuel Consumption: 110.0561\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.042\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -221.11370984440478 SOC: 0.5923 Cumulative_SOC_deviation: 13.8279 Fuel Consumption: 110.4901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.571\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -225.98247408058424 SOC: 0.5888 Cumulative_SOC_deviation: 14.4013 Fuel Consumption: 110.7717\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.354\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -237.05971586814596 SOC: 0.5824 Cumulative_SOC_deviation: 16.0021 Fuel Consumption: 109.0429\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.114\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -236.38737826242934 SOC: 0.5940 Cumulative_SOC_deviation: 15.7944 Fuel Consumption: 110.0318\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.715\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -235.44071741362058 SOC: 0.5879 Cumulative_SOC_deviation: 15.7279 Fuel Consumption: 109.6174\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.671\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -206.94097376070405 SOC: 0.5878 Cumulative_SOC_deviation: 12.1684 Fuel Consumption: 109.5935\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.900\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -249.53918792824155 SOC: 0.5880 Cumulative_SOC_deviation: 17.5341 Fuel Consumption: 109.2667\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.533\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -249.72167293425673 SOC: 0.5882 Cumulative_SOC_deviation: 17.4856 Fuel Consumption: 109.8372\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.024\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -246.40839477181473 SOC: 0.5871 Cumulative_SOC_deviation: 17.0647 Fuel Consumption: 109.8905\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.059\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -243.76616770090595 SOC: 0.5843 Cumulative_SOC_deviation: 16.8221 Fuel Consumption: 109.1895\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.942\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -260.4876954926888 SOC: 0.5817 Cumulative_SOC_deviation: 18.9336 Fuel Consumption: 109.0190\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.162\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -193.66879949879288 SOC: 0.5889 Cumulative_SOC_deviation: 10.4375 Fuel Consumption: 110.1686\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.375\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -210.81201530732196 SOC: 0.5926 Cumulative_SOC_deviation: 12.6486 Fuel Consumption: 109.6230\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.466\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -255.45768779806087 SOC: 0.5890 Cumulative_SOC_deviation: 18.3382 Fuel Consumption: 108.7523\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.377\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -239.55627865946872 SOC: 0.5919 Cumulative_SOC_deviation: 16.2254 Fuel Consumption: 109.7532\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.644\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -191.44132211759876 SOC: 0.5851 Cumulative_SOC_deviation: 10.3505 Fuel Consumption: 108.6370\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.595\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -295.7090949999921 SOC: 0.5828 Cumulative_SOC_deviation: 23.3175 Fuel Consumption: 109.1695\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.804\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -285.7676853567741 SOC: 0.5744 Cumulative_SOC_deviation: 22.1561 Fuel Consumption: 108.5188\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.134\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -316.0580939315857 SOC: 0.5753 Cumulative_SOC_deviation: 25.9207 Fuel Consumption: 108.6923\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.967\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -344.97233555708493 SOC: 0.5790 Cumulative_SOC_deviation: 29.4574 Fuel Consumption: 109.3134\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.766\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -231.0849385556806 SOC: 0.5932 Cumulative_SOC_deviation: 15.1010 Fuel Consumption: 110.2768\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.040\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -205.20021826098224 SOC: 0.5919 Cumulative_SOC_deviation: 11.8465 Fuel Consumption: 110.4280\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.178\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -229.0373730442296 SOC: 0.5954 Cumulative_SOC_deviation: 14.7294 Fuel Consumption: 111.2018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.079\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -200.574507007563 SOC: 0.5906 Cumulative_SOC_deviation: 11.2336 Fuel Consumption: 110.7055\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.129\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -214.70725540746986 SOC: 0.5941 Cumulative_SOC_deviation: 12.9588 Fuel Consumption: 111.0365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.890\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -238.42059437754034 SOC: 0.5899 Cumulative_SOC_deviation: 15.8958 Fuel Consumption: 111.2542\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.234\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -253.21866946069582 SOC: 0.5910 Cumulative_SOC_deviation: 17.7844 Fuel Consumption: 110.9434\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.977\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -183.74905013602495 SOC: 0.5906 Cumulative_SOC_deviation: 9.3105 Fuel Consumption: 109.2651\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.734\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -219.45595591490985 SOC: 0.5933 Cumulative_SOC_deviation: 13.6014 Fuel Consumption: 110.6451\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.646\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -213.46222217861927 SOC: 0.5912 Cumulative_SOC_deviation: 12.8525 Fuel Consumption: 110.6421\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.853\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -206.22472352190744 SOC: 0.5898 Cumulative_SOC_deviation: 11.8719 Fuel Consumption: 111.2499\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.892\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -182.2698969223805 SOC: 0.5927 Cumulative_SOC_deviation: 8.8909 Fuel Consumption: 111.1428\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.907\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -188.03670464006083 SOC: 0.5908 Cumulative_SOC_deviation: 9.6953 Fuel Consumption: 110.4740\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.889\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -228.91839862044083 SOC: 0.5897 Cumulative_SOC_deviation: 14.7465 Fuel Consumption: 110.9468\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.101\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -199.55927563041078 SOC: 0.5960 Cumulative_SOC_deviation: 11.1745 Fuel Consumption: 110.1632\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.054\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -194.87962608180428 SOC: 0.5899 Cumulative_SOC_deviation: 10.6741 Fuel Consumption: 109.4865\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.080\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -189.34535668819763 SOC: 0.5898 Cumulative_SOC_deviation: 9.9942 Fuel Consumption: 109.3916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.459\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -204.53314500065378 SOC: 0.5934 Cumulative_SOC_deviation: 11.8948 Fuel Consumption: 109.3746\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.266\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -163.58127726661343 SOC: 0.5944 Cumulative_SOC_deviation: 6.8684 Fuel Consumption: 108.6343\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.594\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -173.7721754007397 SOC: 0.5909 Cumulative_SOC_deviation: 8.1888 Fuel Consumption: 108.2616\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.524\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -179.53291651285588 SOC: 0.5901 Cumulative_SOC_deviation: 8.9099 Fuel Consumption: 108.2538\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.043\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -231.148204298971 SOC: 0.5928 Cumulative_SOC_deviation: 15.2482 Fuel Consumption: 109.1624\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.763\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -186.74254580975912 SOC: 0.5928 Cumulative_SOC_deviation: 9.6776 Fuel Consumption: 109.3214\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.166\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -197.93026530503894 SOC: 0.5950 Cumulative_SOC_deviation: 11.1285 Fuel Consumption: 108.9019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.377\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -204.31860875306754 SOC: 0.5932 Cumulative_SOC_deviation: 11.8614 Fuel Consumption: 109.4278\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.271\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -205.07425619382664 SOC: 0.5927 Cumulative_SOC_deviation: 11.8998 Fuel Consumption: 109.8762\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.462\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -218.68934575373203 SOC: 0.5927 Cumulative_SOC_deviation: 13.6849 Fuel Consumption: 109.2102\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.389\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -221.5460301966742 SOC: 0.5879 Cumulative_SOC_deviation: 13.8978 Fuel Consumption: 110.3636\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.960\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -247.59605324713763 SOC: 0.5906 Cumulative_SOC_deviation: 17.2245 Fuel Consumption: 109.8002\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.140\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -239.1490524517475 SOC: 0.5912 Cumulative_SOC_deviation: 16.0755 Fuel Consumption: 110.5451\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.652\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -225.81800754296904 SOC: 0.5888 Cumulative_SOC_deviation: 14.6294 Fuel Consumption: 108.7827\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.049\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -251.05763592410304 SOC: 0.5876 Cumulative_SOC_deviation: 17.8075 Fuel Consumption: 108.5979\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.660\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -258.82425421789867 SOC: 0.5860 Cumulative_SOC_deviation: 18.7899 Fuel Consumption: 108.5052\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.426\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -321.35211347487024 SOC: 0.5836 Cumulative_SOC_deviation: 26.3515 Fuel Consumption: 110.5402\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.133\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -285.0231594678407 SOC: 0.5886 Cumulative_SOC_deviation: 21.9936 Fuel Consumption: 109.0740\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.223\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -263.8988645959403 SOC: 0.5870 Cumulative_SOC_deviation: 19.3546 Fuel Consumption: 109.0622\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.422\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -263.2206100232357 SOC: 0.5874 Cumulative_SOC_deviation: 19.3863 Fuel Consumption: 108.1301\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.268\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -287.6050954613024 SOC: 0.5871 Cumulative_SOC_deviation: 22.3070 Fuel Consumption: 109.1493\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.904\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -267.7861818082149 SOC: 0.5870 Cumulative_SOC_deviation: 20.0218 Fuel Consumption: 107.6116\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.840\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -216.4159287657253 SOC: 0.5912 Cumulative_SOC_deviation: 13.5183 Fuel Consumption: 108.2693\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.594\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -270.63493526662216 SOC: 0.5856 Cumulative_SOC_deviation: 20.3837 Fuel Consumption: 107.5652\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.263\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -270.04445386790775 SOC: 0.5872 Cumulative_SOC_deviation: 20.2614 Fuel Consumption: 107.9529\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.207\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -296.275501228327 SOC: 0.5860 Cumulative_SOC_deviation: 23.5447 Fuel Consumption: 107.9179\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.038\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -243.60953992772318 SOC: 0.5883 Cumulative_SOC_deviation: 17.0410 Fuel Consumption: 107.2814\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.459\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -261.3464689284925 SOC: 0.5861 Cumulative_SOC_deviation: 19.1262 Fuel Consumption: 108.3368\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.449\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -318.70142884388105 SOC: 0.5842 Cumulative_SOC_deviation: 26.3494 Fuel Consumption: 107.9064\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.042\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -256.9506318330589 SOC: 0.5912 Cumulative_SOC_deviation: 18.6138 Fuel Consumption: 108.0404\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.114\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -229.5735688347678 SOC: 0.5933 Cumulative_SOC_deviation: 15.0600 Fuel Consumption: 109.0934\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.016\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -258.7526596679525 SOC: 0.5868 Cumulative_SOC_deviation: 18.7908 Fuel Consumption: 108.4260\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.628\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -245.16572401639937 SOC: 0.5888 Cumulative_SOC_deviation: 17.2015 Fuel Consumption: 107.5535\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.712\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -281.4510484283414 SOC: 0.5891 Cumulative_SOC_deviation: 21.7696 Fuel Consumption: 107.2944\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.362\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -205.55194642828417 SOC: 0.5892 Cumulative_SOC_deviation: 12.2975 Fuel Consumption: 107.1716\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.128\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -207.84527055067264 SOC: 0.5956 Cumulative_SOC_deviation: 12.4764 Fuel Consumption: 108.0338\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.134\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -199.55246440303054 SOC: 0.5953 Cumulative_SOC_deviation: 11.4600 Fuel Consumption: 107.8721\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.955\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -266.6616427578165 SOC: 0.5917 Cumulative_SOC_deviation: 19.8906 Fuel Consumption: 107.5369\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.173\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -274.28910953918245 SOC: 0.5839 Cumulative_SOC_deviation: 20.9235 Fuel Consumption: 106.9014\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.955\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -225.58315335262523 SOC: 0.5944 Cumulative_SOC_deviation: 14.7115 Fuel Consumption: 107.8915\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.394\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -260.80820409620594 SOC: 0.5878 Cumulative_SOC_deviation: 19.2276 Fuel Consumption: 106.9871\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.621\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -256.362675223693 SOC: 0.5961 Cumulative_SOC_deviation: 18.5284 Fuel Consumption: 108.1357\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.276\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -223.57436348475125 SOC: 0.5960 Cumulative_SOC_deviation: 14.3840 Fuel Consumption: 108.5020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.995\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -234.563974504457 SOC: 0.5969 Cumulative_SOC_deviation: 15.7990 Fuel Consumption: 108.1720\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.358\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -227.6996794526677 SOC: 0.5975 Cumulative_SOC_deviation: 14.9230 Fuel Consumption: 108.3159\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.174\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -246.63705794501234 SOC: 0.5974 Cumulative_SOC_deviation: 17.2276 Fuel Consumption: 108.8166\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.539\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -286.3577857595663 SOC: 0.5935 Cumulative_SOC_deviation: 22.2301 Fuel Consumption: 108.5170\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.022\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -308.8749999427123 SOC: 0.5960 Cumulative_SOC_deviation: 25.0749 Fuel Consumption: 108.2758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.018\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -302.83649082944316 SOC: 0.5974 Cumulative_SOC_deviation: 24.2804 Fuel Consumption: 108.5929\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.915\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -268.85227087297574 SOC: 0.5983 Cumulative_SOC_deviation: 20.0170 Fuel Consumption: 108.7167\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.819\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -187.60902806808392 SOC: 0.5951 Cumulative_SOC_deviation: 9.9259 Fuel Consumption: 108.2020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.093\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -283.9257189338987 SOC: 0.5962 Cumulative_SOC_deviation: 21.9469 Fuel Consumption: 108.3505\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.969\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -195.48994622832896 SOC: 0.5955 Cumulative_SOC_deviation: 10.8886 Fuel Consumption: 108.3810\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.987\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -220.1107492051697 SOC: 0.5956 Cumulative_SOC_deviation: 13.9749 Fuel Consumption: 108.3118\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.430\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -193.33476268698402 SOC: 0.5943 Cumulative_SOC_deviation: 10.6580 Fuel Consumption: 108.0707\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.198\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -208.02395240720142 SOC: 0.5960 Cumulative_SOC_deviation: 12.5128 Fuel Consumption: 107.9219\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.189\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -228.77084936825943 SOC: 0.5899 Cumulative_SOC_deviation: 15.1342 Fuel Consumption: 107.6975\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.378\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -233.03860256780368 SOC: 0.5923 Cumulative_SOC_deviation: 15.6735 Fuel Consumption: 107.6508\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.156\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -223.64314089935525 SOC: 0.5970 Cumulative_SOC_deviation: 14.4921 Fuel Consumption: 107.7060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.310\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -208.92518349305976 SOC: 0.5968 Cumulative_SOC_deviation: 12.5774 Fuel Consumption: 108.3060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.701\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -222.29718434683653 SOC: 0.5956 Cumulative_SOC_deviation: 14.3526 Fuel Consumption: 107.4765\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.831\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -226.46430617948783 SOC: 0.5955 Cumulative_SOC_deviation: 14.8412 Fuel Consumption: 107.7344\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.167\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -227.67340220418805 SOC: 0.5933 Cumulative_SOC_deviation: 14.9956 Fuel Consumption: 107.7089\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.143\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -235.95673554338742 SOC: 0.5935 Cumulative_SOC_deviation: 16.0853 Fuel Consumption: 107.2746\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.319\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -245.38837382328504 SOC: 0.5939 Cumulative_SOC_deviation: 17.2144 Fuel Consumption: 107.6732\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.087\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -236.88077369052667 SOC: 0.5976 Cumulative_SOC_deviation: 16.0878 Fuel Consumption: 108.1787\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.714\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -258.3619863409054 SOC: 0.5960 Cumulative_SOC_deviation: 18.8338 Fuel Consumption: 107.6912\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.741\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -284.7128270657883 SOC: 0.5961 Cumulative_SOC_deviation: 22.1093 Fuel Consumption: 107.8386\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.417\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -310.5581494006684 SOC: 0.5932 Cumulative_SOC_deviation: 25.3837 Fuel Consumption: 107.4886\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.351\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -241.89381715530678 SOC: 0.5925 Cumulative_SOC_deviation: 16.7825 Fuel Consumption: 107.6341\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.460\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -262.2318090858833 SOC: 0.5901 Cumulative_SOC_deviation: 19.3709 Fuel Consumption: 107.2648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.476\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -242.48491965931655 SOC: 0.5956 Cumulative_SOC_deviation: 16.8410 Fuel Consumption: 107.7568\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.862\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -235.1802541374386 SOC: 0.5969 Cumulative_SOC_deviation: 15.9093 Fuel Consumption: 107.9059\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.161\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -228.51973972231573 SOC: 0.5924 Cumulative_SOC_deviation: 15.0886 Fuel Consumption: 107.8111\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.682\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -249.9752169087612 SOC: 0.5976 Cumulative_SOC_deviation: 17.7338 Fuel Consumption: 108.1047\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.279\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -249.4018399351425 SOC: 0.5916 Cumulative_SOC_deviation: 17.7200 Fuel Consumption: 107.6419\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.497\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -249.77115408636254 SOC: 0.5954 Cumulative_SOC_deviation: 17.7295 Fuel Consumption: 107.9348\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.519\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -239.4422892792391 SOC: 0.5955 Cumulative_SOC_deviation: 16.4610 Fuel Consumption: 107.7541\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.171\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -243.46001538142988 SOC: 0.5938 Cumulative_SOC_deviation: 16.9628 Fuel Consumption: 107.7579\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 9\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.026\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -4521.530527660901 SOC: 0.9999 Cumulative_SOC_deviation: 480.7178 Fuel Consumption: 195.0705\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.841\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -4548.6682670290575 SOC: 1.0000 Cumulative_SOC_deviation: 484.5749 Fuel Consumption: 187.4942\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.880\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -4570.861553350118 SOC: 1.0000 Cumulative_SOC_deviation: 486.2849 Fuel Consumption: 194.2974\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 37.085\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -4571.978328951393 SOC: 1.0000 Cumulative_SOC_deviation: 487.0240 Fuel Consumption: 188.7620\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.637\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -4614.626584106686 SOC: 1.0000 Cumulative_SOC_deviation: 491.6826 Fuel Consumption: 189.4836\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.647\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -4472.2529602503055 SOC: 0.9994 Cumulative_SOC_deviation: 476.7543 Fuel Consumption: 181.4640\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.024\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -4480.045867516244 SOC: 1.0000 Cumulative_SOC_deviation: 477.8848 Fuel Consumption: 179.0829\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.238\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -4326.750525382274 SOC: 1.0000 Cumulative_SOC_deviation: 460.6435 Fuel Consumption: 180.9589\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.438\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -4371.3260497675565 SOC: 0.9984 Cumulative_SOC_deviation: 466.4519 Fuel Consumption: 173.2589\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.652\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -4233.188946111234 SOC: 0.9999 Cumulative_SOC_deviation: 451.7298 Fuel Consumption: 167.6205\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.416\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -4163.587756733857 SOC: 1.0000 Cumulative_SOC_deviation: 443.5405 Fuel Consumption: 171.7230\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.409\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -4211.331351954748 SOC: 0.9981 Cumulative_SOC_deviation: 449.1306 Fuel Consumption: 169.1564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.263\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -3882.8759201794005 SOC: 1.0000 Cumulative_SOC_deviation: 413.2574 Fuel Consumption: 163.5592\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.637\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -3724.926649108294 SOC: 0.9994 Cumulative_SOC_deviation: 396.0751 Fuel Consumption: 160.2503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.435\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -4043.59460040914 SOC: 1.0000 Cumulative_SOC_deviation: 431.4483 Fuel Consumption: 160.5596\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.780\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -3732.830114597634 SOC: 0.9939 Cumulative_SOC_deviation: 397.2339 Fuel Consumption: 157.7249\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.767\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -3677.690250759967 SOC: 0.9989 Cumulative_SOC_deviation: 391.0615 Fuel Consumption: 158.1372\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.419\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -3420.7712008071767 SOC: 0.9993 Cumulative_SOC_deviation: 362.5229 Fuel Consumption: 158.0650\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.620\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -3133.0216704107297 SOC: 0.9967 Cumulative_SOC_deviation: 331.1211 Fuel Consumption: 152.9317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.845\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -3367.9882647326103 SOC: 0.9995 Cumulative_SOC_deviation: 356.8173 Fuel Consumption: 156.6322\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.230\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -2855.2272485866542 SOC: 1.0000 Cumulative_SOC_deviation: 300.0638 Fuel Consumption: 154.6531\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.812\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2861.614378138694 SOC: 0.9987 Cumulative_SOC_deviation: 300.8216 Fuel Consumption: 154.2202\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.486\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -2835.1665437267325 SOC: 1.0000 Cumulative_SOC_deviation: 297.9242 Fuel Consumption: 153.8491\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.651\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -2062.2990940235436 SOC: 0.9607 Cumulative_SOC_deviation: 212.2287 Fuel Consumption: 152.2411\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.930\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1907.9430456961854 SOC: 0.9190 Cumulative_SOC_deviation: 195.5556 Fuel Consumption: 147.9427\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.511\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1748.4456992320495 SOC: 0.9154 Cumulative_SOC_deviation: 177.6527 Fuel Consumption: 149.5713\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.156\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -925.0080106709853 SOC: 0.8011 Cumulative_SOC_deviation: 87.1217 Fuel Consumption: 140.9127\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.139\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -709.906898931726 SOC: 0.7970 Cumulative_SOC_deviation: 63.2136 Fuel Consumption: 140.9848\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.080\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -1181.946805427751 SOC: 0.8437 Cumulative_SOC_deviation: 115.2375 Fuel Consumption: 144.8091\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.248\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -856.4449102759505 SOC: 0.7663 Cumulative_SOC_deviation: 79.8323 Fuel Consumption: 137.9543\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.131\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -791.9392872735402 SOC: 0.7140 Cumulative_SOC_deviation: 73.0223 Fuel Consumption: 134.7382\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.564\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -1214.303944648258 SOC: 0.5603 Cumulative_SOC_deviation: 121.2838 Fuel Consumption: 122.7501\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.228\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1192.5671451815438 SOC: 0.5967 Cumulative_SOC_deviation: 118.4769 Fuel Consumption: 126.2754\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.511\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -1460.3559494197575 SOC: 0.5008 Cumulative_SOC_deviation: 149.0673 Fuel Consumption: 118.7506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.069\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -1685.0485087505233 SOC: 0.4367 Cumulative_SOC_deviation: 174.5680 Fuel Consumption: 113.9368\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.572\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1835.9256974053035 SOC: 0.4390 Cumulative_SOC_deviation: 191.2783 Fuel Consumption: 114.4213\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.632\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -2470.070592788625 SOC: 0.3777 Cumulative_SOC_deviation: 262.1248 Fuel Consumption: 110.9475\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.627\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -2071.2946282894827 SOC: 0.3418 Cumulative_SOC_deviation: 218.3077 Fuel Consumption: 106.5254\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.678\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -3342.3075583977557 SOC: 0.2198 Cumulative_SOC_deviation: 360.3548 Fuel Consumption: 99.1140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.968\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -2156.713165893747 SOC: 0.3712 Cumulative_SOC_deviation: 227.3943 Fuel Consumption: 110.1641\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.640\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -3343.200812295274 SOC: 0.2192 Cumulative_SOC_deviation: 360.4736 Fuel Consumption: 98.9388\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.050\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -3396.4047419955737 SOC: 0.1601 Cumulative_SOC_deviation: 366.8409 Fuel Consumption: 94.8362\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.975\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -3285.1652098130908 SOC: 0.2341 Cumulative_SOC_deviation: 353.9599 Fuel Consumption: 99.5263\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.193\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -2809.3136324026295 SOC: 0.6129 Cumulative_SOC_deviation: 297.5517 Fuel Consumption: 131.3479\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.274\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -232.7303440240603 SOC: 0.6058 Cumulative_SOC_deviation: 12.5823 Fuel Consumption: 119.4897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.241\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -233.9660379455755 SOC: 0.6165 Cumulative_SOC_deviation: 12.4901 Fuel Consumption: 121.5549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.357\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -198.66684307588423 SOC: 0.6041 Cumulative_SOC_deviation: 8.8684 Fuel Consumption: 118.8517\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.956\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -217.31516961519552 SOC: 0.5999 Cumulative_SOC_deviation: 10.9359 Fuel Consumption: 118.8917\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.144\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -195.1586331821666 SOC: 0.6213 Cumulative_SOC_deviation: 8.1799 Fuel Consumption: 121.5395\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.157\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -191.2899000262205 SOC: 0.5924 Cumulative_SOC_deviation: 8.3039 Fuel Consumption: 116.5551\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.183\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -196.14386420139493 SOC: 0.5931 Cumulative_SOC_deviation: 8.9812 Fuel Consumption: 115.3129\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.043\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -180.66492606689008 SOC: 0.6009 Cumulative_SOC_deviation: 7.0659 Fuel Consumption: 117.0721\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.031\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -191.29764049117398 SOC: 0.5939 Cumulative_SOC_deviation: 8.4308 Fuel Consumption: 115.4206\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.527\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -198.3173982789723 SOC: 0.5941 Cumulative_SOC_deviation: 9.2938 Fuel Consumption: 114.6729\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.757\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -187.7050227906151 SOC: 0.5947 Cumulative_SOC_deviation: 7.8903 Fuel Consumption: 116.6920\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.251\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -203.8058615894913 SOC: 0.5992 Cumulative_SOC_deviation: 9.8566 Fuel Consumption: 115.0965\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.622\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -221.33111619652863 SOC: 0.5848 Cumulative_SOC_deviation: 11.8758 Fuel Consumption: 114.4494\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.329\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -213.53945858241977 SOC: 0.5936 Cumulative_SOC_deviation: 11.0591 Fuel Consumption: 114.0078\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.354\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -220.58833345644837 SOC: 0.6016 Cumulative_SOC_deviation: 11.6978 Fuel Consumption: 115.3083\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.536\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -215.38865945114694 SOC: 0.5895 Cumulative_SOC_deviation: 11.3126 Fuel Consumption: 113.5754\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.738\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -235.7450715648454 SOC: 0.5881 Cumulative_SOC_deviation: 13.5946 Fuel Consumption: 113.3939\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.852\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -196.09650896577656 SOC: 0.5957 Cumulative_SOC_deviation: 9.2124 Fuel Consumption: 113.1851\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.024\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -246.76127622312865 SOC: 0.5878 Cumulative_SOC_deviation: 14.8828 Fuel Consumption: 112.8162\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.411\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -278.60787675631747 SOC: 0.5968 Cumulative_SOC_deviation: 18.3681 Fuel Consumption: 113.2948\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.161\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -259.0088645584035 SOC: 0.5914 Cumulative_SOC_deviation: 16.2641 Fuel Consumption: 112.6317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.289\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -191.58432668626654 SOC: 0.6044 Cumulative_SOC_deviation: 8.5860 Fuel Consumption: 114.3104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.421\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -257.51247889173345 SOC: 0.5934 Cumulative_SOC_deviation: 16.2694 Fuel Consumption: 111.0879\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.594\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -283.7947471577147 SOC: 0.5949 Cumulative_SOC_deviation: 19.1058 Fuel Consumption: 111.8424\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.461\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -276.6045439818237 SOC: 0.5975 Cumulative_SOC_deviation: 18.2607 Fuel Consumption: 112.2579\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.512\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -249.2579401899497 SOC: 0.5965 Cumulative_SOC_deviation: 15.3192 Fuel Consumption: 111.3854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.466\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -285.69174490180575 SOC: 0.5972 Cumulative_SOC_deviation: 19.2534 Fuel Consumption: 112.4110\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.491\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -204.63681056395893 SOC: 0.5956 Cumulative_SOC_deviation: 10.2325 Fuel Consumption: 112.5440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.367\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -207.73243537000914 SOC: 0.5967 Cumulative_SOC_deviation: 10.6868 Fuel Consumption: 111.5508\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.564\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -196.96843368724012 SOC: 0.5957 Cumulative_SOC_deviation: 9.4575 Fuel Consumption: 111.8506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.484\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -165.24124737458402 SOC: 0.5941 Cumulative_SOC_deviation: 6.0039 Fuel Consumption: 111.2057\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.597\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -146.56013163420118 SOC: 0.5974 Cumulative_SOC_deviation: 3.8663 Fuel Consumption: 111.7635\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.618\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -166.86019953295383 SOC: 0.6034 Cumulative_SOC_deviation: 6.2142 Fuel Consumption: 110.9321\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.779\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -193.23767475604026 SOC: 0.5979 Cumulative_SOC_deviation: 9.1152 Fuel Consumption: 111.2006\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.678\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -178.25894719564624 SOC: 0.5986 Cumulative_SOC_deviation: 7.4397 Fuel Consumption: 111.3018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.281\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -196.23012621383663 SOC: 0.6006 Cumulative_SOC_deviation: 9.3488 Fuel Consumption: 112.0910\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.562\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -155.99031435953984 SOC: 0.5987 Cumulative_SOC_deviation: 4.9271 Fuel Consumption: 111.6463\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.644\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -145.35629576668825 SOC: 0.5919 Cumulative_SOC_deviation: 3.8437 Fuel Consumption: 110.7630\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.453\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -150.52098529677332 SOC: 0.5924 Cumulative_SOC_deviation: 4.3753 Fuel Consumption: 111.1436\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.015\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -168.90276596679342 SOC: 0.5982 Cumulative_SOC_deviation: 6.4694 Fuel Consumption: 110.6785\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.134\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -218.7170157696251 SOC: 0.5929 Cumulative_SOC_deviation: 12.1123 Fuel Consumption: 109.7060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.848\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -142.6887245570539 SOC: 0.5975 Cumulative_SOC_deviation: 3.5095 Fuel Consumption: 111.1031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.016\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -147.5927662401408 SOC: 0.5989 Cumulative_SOC_deviation: 4.1388 Fuel Consumption: 110.3433\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.164\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -167.91920394032257 SOC: 0.5935 Cumulative_SOC_deviation: 6.4112 Fuel Consumption: 110.2187\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.976\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -156.26251193680292 SOC: 0.5939 Cumulative_SOC_deviation: 5.0940 Fuel Consumption: 110.4169\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.919\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -158.1856687437046 SOC: 0.5928 Cumulative_SOC_deviation: 5.3281 Fuel Consumption: 110.2328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.075\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -158.2883944648779 SOC: 0.5969 Cumulative_SOC_deviation: 5.2012 Fuel Consumption: 111.4779\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.130\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -164.74915981550689 SOC: 0.5998 Cumulative_SOC_deviation: 6.1005 Fuel Consumption: 109.8450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.224\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -178.79165900759202 SOC: 0.6015 Cumulative_SOC_deviation: 7.5855 Fuel Consumption: 110.5221\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.138\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -159.0004295597388 SOC: 0.5935 Cumulative_SOC_deviation: 5.5686 Fuel Consumption: 108.8827\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.362\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -179.32421397819857 SOC: 0.5957 Cumulative_SOC_deviation: 7.8018 Fuel Consumption: 109.1081\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.994\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -175.57334219370188 SOC: 0.5949 Cumulative_SOC_deviation: 7.3163 Fuel Consumption: 109.7270\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.195\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -185.5074899564858 SOC: 0.5949 Cumulative_SOC_deviation: 8.5230 Fuel Consumption: 108.8003\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.297\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -174.5994007601478 SOC: 0.5917 Cumulative_SOC_deviation: 7.3116 Fuel Consumption: 108.7953\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.946\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -184.68152492608564 SOC: 0.5966 Cumulative_SOC_deviation: 8.4200 Fuel Consumption: 108.9012\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.186\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -186.2973169793072 SOC: 0.5915 Cumulative_SOC_deviation: 8.6651 Fuel Consumption: 108.3118\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.790\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -183.23893355918858 SOC: 0.5921 Cumulative_SOC_deviation: 8.2494 Fuel Consumption: 108.9940\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.680\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -182.29800973726665 SOC: 0.5941 Cumulative_SOC_deviation: 8.1468 Fuel Consumption: 108.9765\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.506\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -173.1070509971088 SOC: 0.5947 Cumulative_SOC_deviation: 7.1534 Fuel Consumption: 108.7268\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.623\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -182.9789520120605 SOC: 0.5922 Cumulative_SOC_deviation: 8.2809 Fuel Consumption: 108.4512\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.616\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -188.1132764476885 SOC: 0.5953 Cumulative_SOC_deviation: 8.8868 Fuel Consumption: 108.1320\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.333\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -174.07376134792887 SOC: 0.5927 Cumulative_SOC_deviation: 7.2284 Fuel Consumption: 109.0179\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.288\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -192.22868917114369 SOC: 0.5948 Cumulative_SOC_deviation: 9.3357 Fuel Consumption: 108.2078\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.402\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -189.0271354581035 SOC: 0.5927 Cumulative_SOC_deviation: 9.0007 Fuel Consumption: 108.0204\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.582\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -184.00775572640643 SOC: 0.5915 Cumulative_SOC_deviation: 8.4567 Fuel Consumption: 107.8972\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.562\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -191.28474176285266 SOC: 0.5933 Cumulative_SOC_deviation: 9.2598 Fuel Consumption: 107.9468\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.541\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -191.37114481208326 SOC: 0.5945 Cumulative_SOC_deviation: 9.1885 Fuel Consumption: 108.6749\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.727\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -187.2773165491409 SOC: 0.5914 Cumulative_SOC_deviation: 8.7169 Fuel Consumption: 108.8253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.677\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -191.94938558418883 SOC: 0.5931 Cumulative_SOC_deviation: 9.2661 Fuel Consumption: 108.5541\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.614\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -206.731208239282 SOC: 0.5912 Cumulative_SOC_deviation: 10.9541 Fuel Consumption: 108.1443\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.568\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -216.0980681118973 SOC: 0.5894 Cumulative_SOC_deviation: 11.9986 Fuel Consumption: 108.1107\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.449\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -205.53817963979947 SOC: 0.5895 Cumulative_SOC_deviation: 10.8462 Fuel Consumption: 107.9226\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.867\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -234.91741437153698 SOC: 0.5893 Cumulative_SOC_deviation: 14.1199 Fuel Consumption: 107.8381\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.698\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -243.6544450099459 SOC: 0.5896 Cumulative_SOC_deviation: 15.0519 Fuel Consumption: 108.1874\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.398\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -195.71686065134418 SOC: 0.5937 Cumulative_SOC_deviation: 9.6973 Fuel Consumption: 108.4414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.599\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -226.00721761468589 SOC: 0.5882 Cumulative_SOC_deviation: 13.1024 Fuel Consumption: 108.0854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.779\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -202.88987576966736 SOC: 0.5918 Cumulative_SOC_deviation: 10.5050 Fuel Consumption: 108.3449\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.389\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -227.77341256201052 SOC: 0.5915 Cumulative_SOC_deviation: 13.2297 Fuel Consumption: 108.7065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.424\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -227.6009501995143 SOC: 0.5928 Cumulative_SOC_deviation: 13.2056 Fuel Consumption: 108.7507\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.476\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -209.46029431923182 SOC: 0.5897 Cumulative_SOC_deviation: 11.3013 Fuel Consumption: 107.7483\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.209\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -218.60086617169657 SOC: 0.5862 Cumulative_SOC_deviation: 12.2685 Fuel Consumption: 108.1844\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.923\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -247.4839622298996 SOC: 0.5875 Cumulative_SOC_deviation: 15.4781 Fuel Consumption: 108.1815\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.197\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -233.63842069634612 SOC: 0.5918 Cumulative_SOC_deviation: 13.9753 Fuel Consumption: 107.8611\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.530\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -216.60392665467256 SOC: 0.5911 Cumulative_SOC_deviation: 12.0948 Fuel Consumption: 107.7504\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.225\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -291.0659402362609 SOC: 0.5802 Cumulative_SOC_deviation: 20.4719 Fuel Consumption: 106.8186\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.353\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -316.15610335239853 SOC: 0.5830 Cumulative_SOC_deviation: 23.2313 Fuel Consumption: 107.0741\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.573\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -240.5113520699885 SOC: 0.5903 Cumulative_SOC_deviation: 14.7521 Fuel Consumption: 107.7426\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.473\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -277.63691032720203 SOC: 0.5820 Cumulative_SOC_deviation: 18.9114 Fuel Consumption: 107.4341\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.452\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -270.1566009613583 SOC: 0.5897 Cumulative_SOC_deviation: 18.0602 Fuel Consumption: 107.6149\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.383\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -213.83043143083506 SOC: 0.5881 Cumulative_SOC_deviation: 11.7955 Fuel Consumption: 107.6707\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.413\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -244.08504577240856 SOC: 0.5967 Cumulative_SOC_deviation: 15.1084 Fuel Consumption: 108.1091\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.333\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -218.69228996638523 SOC: 0.5943 Cumulative_SOC_deviation: 12.3545 Fuel Consumption: 107.5017\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.289\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -225.4803216532225 SOC: 0.5860 Cumulative_SOC_deviation: 13.1172 Fuel Consumption: 107.4253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.366\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -250.16137545647805 SOC: 0.5854 Cumulative_SOC_deviation: 15.8850 Fuel Consumption: 107.1960\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.246\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -299.2091553041629 SOC: 0.5906 Cumulative_SOC_deviation: 21.3125 Fuel Consumption: 107.3962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.303\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -202.5669605433074 SOC: 0.5919 Cumulative_SOC_deviation: 10.4997 Fuel Consumption: 108.0700\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.100\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -231.76569729515626 SOC: 0.5917 Cumulative_SOC_deviation: 13.8050 Fuel Consumption: 107.5209\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.616\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -216.6019671767406 SOC: 0.5891 Cumulative_SOC_deviation: 12.1310 Fuel Consumption: 107.4230\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.471\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -266.6706022215863 SOC: 0.5822 Cumulative_SOC_deviation: 17.8075 Fuel Consumption: 106.4035\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.116\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -270.93088112315934 SOC: 0.5862 Cumulative_SOC_deviation: 18.2617 Fuel Consumption: 106.5755\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.103\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -277.0185948127323 SOC: 0.5945 Cumulative_SOC_deviation: 18.8615 Fuel Consumption: 107.2648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.392\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -218.07912538286428 SOC: 0.5948 Cumulative_SOC_deviation: 12.2984 Fuel Consumption: 107.3937\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.229\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -255.15282038769342 SOC: 0.5894 Cumulative_SOC_deviation: 16.4443 Fuel Consumption: 107.1540\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.638\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -280.333362840365 SOC: 0.5924 Cumulative_SOC_deviation: 19.2833 Fuel Consumption: 106.7834\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.370\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -217.77047580995153 SOC: 0.5937 Cumulative_SOC_deviation: 12.2970 Fuel Consumption: 107.0974\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.328\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -186.97783011043157 SOC: 0.5975 Cumulative_SOC_deviation: 8.8374 Fuel Consumption: 107.4412\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.325\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -192.06997880140207 SOC: 0.5847 Cumulative_SOC_deviation: 9.5081 Fuel Consumption: 106.4967\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.041\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -193.0538271184264 SOC: 0.5981 Cumulative_SOC_deviation: 9.4661 Fuel Consumption: 107.8585\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.405\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -175.8957525822267 SOC: 0.5943 Cumulative_SOC_deviation: 7.6068 Fuel Consumption: 107.4349\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.214\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -181.99307306120343 SOC: 0.5952 Cumulative_SOC_deviation: 8.2775 Fuel Consumption: 107.4954\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.062\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -178.10282618238386 SOC: 0.5957 Cumulative_SOC_deviation: 7.8823 Fuel Consumption: 107.1620\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.031\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -178.12311048611056 SOC: 0.5973 Cumulative_SOC_deviation: 7.8638 Fuel Consumption: 107.3490\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.209\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -213.7097148366376 SOC: 0.5931 Cumulative_SOC_deviation: 11.8551 Fuel Consumption: 107.0138\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.288\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -169.30365394322408 SOC: 0.5962 Cumulative_SOC_deviation: 6.8904 Fuel Consumption: 107.2904\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.303\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -161.84929924804456 SOC: 0.5948 Cumulative_SOC_deviation: 6.0879 Fuel Consumption: 107.0581\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.898\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -186.4584315975168 SOC: 0.5968 Cumulative_SOC_deviation: 8.7384 Fuel Consumption: 107.8126\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.814\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -184.85755004268836 SOC: 0.5900 Cumulative_SOC_deviation: 8.6752 Fuel Consumption: 106.7804\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.856\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -187.7932786485267 SOC: 0.5953 Cumulative_SOC_deviation: 8.9400 Fuel Consumption: 107.3337\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.767\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -172.5647493245244 SOC: 0.5962 Cumulative_SOC_deviation: 7.2025 Fuel Consumption: 107.7419\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.873\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -178.21951622559544 SOC: 0.5950 Cumulative_SOC_deviation: 7.9064 Fuel Consumption: 107.0616\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.822\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -170.46008614724636 SOC: 0.5979 Cumulative_SOC_deviation: 7.0147 Fuel Consumption: 107.3282\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.614\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -179.36156165640395 SOC: 0.5957 Cumulative_SOC_deviation: 7.9897 Fuel Consumption: 107.4546\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.703\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -193.24190639508498 SOC: 0.5943 Cumulative_SOC_deviation: 9.5536 Fuel Consumption: 107.2597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.599\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -180.4139586358688 SOC: 0.5965 Cumulative_SOC_deviation: 8.0926 Fuel Consumption: 107.5809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.656\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -173.40355950540857 SOC: 0.5960 Cumulative_SOC_deviation: 7.3572 Fuel Consumption: 107.1891\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.750\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -186.2559114076024 SOC: 0.5949 Cumulative_SOC_deviation: 8.7794 Fuel Consumption: 107.2411\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.673\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -171.2176635594336 SOC: 0.5958 Cumulative_SOC_deviation: 7.1199 Fuel Consumption: 107.1386\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.440\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -179.56261850147934 SOC: 0.5974 Cumulative_SOC_deviation: 8.0295 Fuel Consumption: 107.2972\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.753\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -184.25018500449403 SOC: 0.5949 Cumulative_SOC_deviation: 8.5594 Fuel Consumption: 107.2159\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.234\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -180.10431465199264 SOC: 0.5896 Cumulative_SOC_deviation: 8.1474 Fuel Consumption: 106.7776\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.888\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -200.95568650503364 SOC: 0.5945 Cumulative_SOC_deviation: 10.4084 Fuel Consumption: 107.2799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.473\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -188.35887843606608 SOC: 0.5930 Cumulative_SOC_deviation: 9.0542 Fuel Consumption: 106.8709\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.821\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -182.9019392678549 SOC: 0.5960 Cumulative_SOC_deviation: 8.3704 Fuel Consumption: 107.5679\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.739\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -174.66136080237558 SOC: 0.5953 Cumulative_SOC_deviation: 7.5077 Fuel Consumption: 107.0916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.998\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -198.7590949622675 SOC: 0.5943 Cumulative_SOC_deviation: 10.2001 Fuel Consumption: 106.9581\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.270\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -183.088938566245 SOC: 0.5956 Cumulative_SOC_deviation: 8.4576 Fuel Consumption: 106.9703\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.311\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -173.42952778932914 SOC: 0.5942 Cumulative_SOC_deviation: 7.3435 Fuel Consumption: 107.3376\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.252\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -172.86403310606633 SOC: 0.5951 Cumulative_SOC_deviation: 7.3262 Fuel Consumption: 106.9282\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.836\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -193.58454684614472 SOC: 0.5939 Cumulative_SOC_deviation: 9.6484 Fuel Consumption: 106.7488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.827\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -198.06392829215093 SOC: 0.5934 Cumulative_SOC_deviation: 10.1388 Fuel Consumption: 106.8147\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.938\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -190.24247146030828 SOC: 0.5945 Cumulative_SOC_deviation: 9.2394 Fuel Consumption: 107.0878\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.639\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -194.39869135309118 SOC: 0.5963 Cumulative_SOC_deviation: 9.6704 Fuel Consumption: 107.3651\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.859\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -210.51315817252672 SOC: 0.5940 Cumulative_SOC_deviation: 11.5035 Fuel Consumption: 106.9818\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.842\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -200.44416756719122 SOC: 0.5943 Cumulative_SOC_deviation: 10.3990 Fuel Consumption: 106.8528\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.328\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -205.6282476774922 SOC: 0.5921 Cumulative_SOC_deviation: 10.9474 Fuel Consumption: 107.1019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.070\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -215.737185067131 SOC: 0.5896 Cumulative_SOC_deviation: 12.1556 Fuel Consumption: 106.3365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.993\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -211.62590936921788 SOC: 0.5927 Cumulative_SOC_deviation: 11.6126 Fuel Consumption: 107.1125\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.097\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -197.65068304071295 SOC: 0.5936 Cumulative_SOC_deviation: 10.0721 Fuel Consumption: 107.0015\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.142\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -187.60076076882964 SOC: 0.5960 Cumulative_SOC_deviation: 8.9311 Fuel Consumption: 107.2213\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.157\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -199.46692005935049 SOC: 0.5935 Cumulative_SOC_deviation: 10.2735 Fuel Consumption: 107.0050\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.197\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -213.9128303970997 SOC: 0.5913 Cumulative_SOC_deviation: 11.9165 Fuel Consumption: 106.6643\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.995\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -211.04989557712466 SOC: 0.5949 Cumulative_SOC_deviation: 11.4571 Fuel Consumption: 107.9362\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.030\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -202.29224319186955 SOC: 0.5952 Cumulative_SOC_deviation: 10.5145 Fuel Consumption: 107.6619\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.271\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -194.69001798349026 SOC: 0.5939 Cumulative_SOC_deviation: 9.6808 Fuel Consumption: 107.5624\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.981\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -214.3462690841382 SOC: 0.5956 Cumulative_SOC_deviation: 11.8715 Fuel Consumption: 107.5031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.005\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -378.2519548658867 SOC: 0.5850 Cumulative_SOC_deviation: 30.2330 Fuel Consumption: 106.1549\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 10\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.781\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -5006.982801744691 SOC: 1.0000 Cumulative_SOC_deviation: 481.8901 Fuel Consumption: 188.0817\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.553\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -4981.92306276824 SOC: 1.0000 Cumulative_SOC_deviation: 479.0945 Fuel Consumption: 190.9782\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.620\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -4965.451210870186 SOC: 1.0000 Cumulative_SOC_deviation: 477.6967 Fuel Consumption: 188.4837\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 30.838\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -5025.923159999486 SOC: 1.0000 Cumulative_SOC_deviation: 483.0379 Fuel Consumption: 195.5447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.222\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -5031.800987927745 SOC: 0.9993 Cumulative_SOC_deviation: 484.4925 Fuel Consumption: 186.8757\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.916\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -4743.09276115398 SOC: 1.0000 Cumulative_SOC_deviation: 456.0577 Fuel Consumption: 182.5154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.063\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -4855.367003448879 SOC: 1.0000 Cumulative_SOC_deviation: 467.5418 Fuel Consumption: 179.9488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.167\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -4838.295512954077 SOC: 1.0000 Cumulative_SOC_deviation: 466.1367 Fuel Consumption: 176.9285\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.020\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -4850.676560672947 SOC: 0.9993 Cumulative_SOC_deviation: 467.7995 Fuel Consumption: 172.6817\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.435\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -4611.014392616018 SOC: 0.9993 Cumulative_SOC_deviation: 444.5218 Fuel Consumption: 165.7960\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.319\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -4591.4973870817785 SOC: 1.0000 Cumulative_SOC_deviation: 442.4609 Fuel Consumption: 166.8886\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.314\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -4499.788082782353 SOC: 0.9994 Cumulative_SOC_deviation: 433.5229 Fuel Consumption: 164.5590\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.181\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -4510.3572192037 SOC: 1.0000 Cumulative_SOC_deviation: 434.7798 Fuel Consumption: 162.5593\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.184\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -4429.308635818848 SOC: 0.9994 Cumulative_SOC_deviation: 426.3399 Fuel Consumption: 165.9094\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.040\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -4217.770659482896 SOC: 0.9994 Cumulative_SOC_deviation: 405.7582 Fuel Consumption: 160.1885\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.968\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -4009.333085400455 SOC: 0.9988 Cumulative_SOC_deviation: 385.2639 Fuel Consumption: 156.6941\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.989\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -4249.9040813376705 SOC: 0.9952 Cumulative_SOC_deviation: 409.2581 Fuel Consumption: 157.3229\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.066\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -4085.8901315469784 SOC: 1.0000 Cumulative_SOC_deviation: 392.9062 Fuel Consumption: 156.8281\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.283\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -3076.773876303501 SOC: 1.0000 Cumulative_SOC_deviation: 292.2327 Fuel Consumption: 154.4470\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.236\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -3229.758010082754 SOC: 0.9997 Cumulative_SOC_deviation: 307.6826 Fuel Consumption: 152.9317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.167\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -3419.5866021161814 SOC: 0.9982 Cumulative_SOC_deviation: 326.4964 Fuel Consumption: 154.6222\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.209\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2628.270594205328 SOC: 0.9994 Cumulative_SOC_deviation: 247.3999 Fuel Consumption: 154.2717\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.276\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -2431.2763613764027 SOC: 0.9418 Cumulative_SOC_deviation: 228.1200 Fuel Consumption: 150.0764\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.337\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -2726.394010576031 SOC: 0.9633 Cumulative_SOC_deviation: 257.4112 Fuel Consumption: 152.2823\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.403\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -2255.1701970958684 SOC: 0.9383 Cumulative_SOC_deviation: 210.5836 Fuel Consumption: 149.3342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.577\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1783.4218725985668 SOC: 0.9118 Cumulative_SOC_deviation: 163.3995 Fuel Consumption: 149.4270\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.769\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1208.69624280695 SOC: 0.8793 Cumulative_SOC_deviation: 106.2228 Fuel Consumption: 146.4686\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.500\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -1083.86617743117 SOC: 0.8304 Cumulative_SOC_deviation: 94.0026 Fuel Consumption: 143.8401\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.916\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -873.2018137732591 SOC: 0.7216 Cumulative_SOC_deviation: 73.7515 Fuel Consumption: 135.6865\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.688\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -953.9125842698588 SOC: 0.7528 Cumulative_SOC_deviation: 81.5484 Fuel Consumption: 138.4284\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.028\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -1105.6705847091916 SOC: 0.6156 Cumulative_SOC_deviation: 97.8973 Fuel Consumption: 126.6980\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.840\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -792.5826448323859 SOC: 0.6298 Cumulative_SOC_deviation: 66.4359 Fuel Consumption: 128.2236\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.124\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -917.4900749043804 SOC: 0.5774 Cumulative_SOC_deviation: 79.3503 Fuel Consumption: 123.9870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.057\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -937.37722206281 SOC: 0.5977 Cumulative_SOC_deviation: 81.1143 Fuel Consumption: 126.2342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.696\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -2832.642785881187 SOC: 0.3050 Cumulative_SOC_deviation: 272.8890 Fuel Consumption: 103.7526\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.790\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -2473.4209082658435 SOC: 0.4069 Cumulative_SOC_deviation: 236.1927 Fuel Consumption: 111.4938\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.725\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -967.0720644693183 SOC: 0.6535 Cumulative_SOC_deviation: 83.7167 Fuel Consumption: 129.9049\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.987\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -400.3267268902095 SOC: 0.6572 Cumulative_SOC_deviation: 27.2812 Fuel Consumption: 127.5143\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.360\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -315.229682489837 SOC: 0.6566 Cumulative_SOC_deviation: 18.8093 Fuel Consumption: 127.1365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.299\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -316.78990971256565 SOC: 0.6330 Cumulative_SOC_deviation: 19.1179 Fuel Consumption: 125.6106\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.248\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -272.2743141667713 SOC: 0.6264 Cumulative_SOC_deviation: 14.8832 Fuel Consumption: 123.4424\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.494\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -271.7557305210473 SOC: 0.6023 Cumulative_SOC_deviation: 14.9453 Fuel Consumption: 122.3030\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.894\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -210.80636182899318 SOC: 0.6119 Cumulative_SOC_deviation: 9.0526 Fuel Consumption: 120.2808\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.584\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -198.67647214652516 SOC: 0.6201 Cumulative_SOC_deviation: 7.7355 Fuel Consumption: 121.3215\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.175\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -214.37844469304304 SOC: 0.6142 Cumulative_SOC_deviation: 9.3837 Fuel Consumption: 120.5411\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.250\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -198.51609093122963 SOC: 0.6112 Cumulative_SOC_deviation: 7.9242 Fuel Consumption: 119.2739\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.032\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -205.55615838037068 SOC: 0.6143 Cumulative_SOC_deviation: 8.5325 Fuel Consumption: 120.2316\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.274\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -201.31747425033114 SOC: 0.5936 Cumulative_SOC_deviation: 8.3358 Fuel Consumption: 117.9591\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.871\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -189.28905602553198 SOC: 0.5969 Cumulative_SOC_deviation: 7.1272 Fuel Consumption: 118.0173\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.510\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -186.18555127972485 SOC: 0.6014 Cumulative_SOC_deviation: 7.0068 Fuel Consumption: 116.1175\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.606\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -200.43823115685507 SOC: 0.6047 Cumulative_SOC_deviation: 8.3492 Fuel Consumption: 116.9463\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.553\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -188.8828782433333 SOC: 0.5985 Cumulative_SOC_deviation: 7.1440 Fuel Consumption: 117.4433\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.549\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -197.3467707012677 SOC: 0.5996 Cumulative_SOC_deviation: 8.0597 Fuel Consumption: 116.7497\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.421\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -201.27348945573453 SOC: 0.6036 Cumulative_SOC_deviation: 8.3547 Fuel Consumption: 117.7265\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.480\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -205.67177567811638 SOC: 0.6076 Cumulative_SOC_deviation: 8.8973 Fuel Consumption: 116.6987\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.620\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -225.35557547958155 SOC: 0.5914 Cumulative_SOC_deviation: 11.0340 Fuel Consumption: 115.0154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.345\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -221.64783999211957 SOC: 0.5925 Cumulative_SOC_deviation: 10.6898 Fuel Consumption: 114.7499\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.513\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -219.05191036517158 SOC: 0.5907 Cumulative_SOC_deviation: 10.3769 Fuel Consumption: 115.2834\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.578\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -225.0601815722556 SOC: 0.5956 Cumulative_SOC_deviation: 10.8721 Fuel Consumption: 116.3393\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.764\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -226.98137516058785 SOC: 0.5931 Cumulative_SOC_deviation: 11.1784 Fuel Consumption: 115.1976\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.758\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -210.50542727789102 SOC: 0.5906 Cumulative_SOC_deviation: 9.4875 Fuel Consumption: 115.6303\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.018\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -213.03667796449307 SOC: 0.5865 Cumulative_SOC_deviation: 9.9041 Fuel Consumption: 113.9954\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.764\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -213.75681884621648 SOC: 0.5995 Cumulative_SOC_deviation: 9.8135 Fuel Consumption: 115.6217\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.517\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -229.31185745228532 SOC: 0.5913 Cumulative_SOC_deviation: 11.6269 Fuel Consumption: 113.0430\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.776\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -234.97044774485383 SOC: 0.5845 Cumulative_SOC_deviation: 12.2057 Fuel Consumption: 112.9130\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.525\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -240.04651706491958 SOC: 0.5920 Cumulative_SOC_deviation: 12.7702 Fuel Consumption: 112.3446\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.549\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -261.71948489317634 SOC: 0.5864 Cumulative_SOC_deviation: 15.0571 Fuel Consumption: 111.1488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.648\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -231.8658033345203 SOC: 0.5898 Cumulative_SOC_deviation: 11.9402 Fuel Consumption: 112.4639\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.733\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -266.95435860969974 SOC: 0.5840 Cumulative_SOC_deviation: 15.5237 Fuel Consumption: 111.7174\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.849\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -293.72613907933646 SOC: 0.5857 Cumulative_SOC_deviation: 18.1667 Fuel Consumption: 112.0595\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.898\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -281.423784630715 SOC: 0.5854 Cumulative_SOC_deviation: 16.9256 Fuel Consumption: 112.1675\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.084\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -290.4586533500519 SOC: 0.5883 Cumulative_SOC_deviation: 17.9041 Fuel Consumption: 111.4174\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.036\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -300.71093123504494 SOC: 0.5845 Cumulative_SOC_deviation: 19.0442 Fuel Consumption: 110.2691\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.837\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -279.4202800856019 SOC: 0.5918 Cumulative_SOC_deviation: 16.6751 Fuel Consumption: 112.6693\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.726\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -334.3570152916348 SOC: 0.5830 Cumulative_SOC_deviation: 22.2831 Fuel Consumption: 111.5263\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.516\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -293.4058202446936 SOC: 0.5815 Cumulative_SOC_deviation: 18.2052 Fuel Consumption: 111.3536\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.864\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -245.01327756387198 SOC: 0.5861 Cumulative_SOC_deviation: 13.3561 Fuel Consumption: 111.4525\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.669\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -264.4468859187601 SOC: 0.5846 Cumulative_SOC_deviation: 15.2743 Fuel Consumption: 111.7040\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.843\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -232.90654636902147 SOC: 0.5954 Cumulative_SOC_deviation: 12.1475 Fuel Consumption: 111.4318\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.290\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -183.15333873337687 SOC: 0.5957 Cumulative_SOC_deviation: 7.2296 Fuel Consumption: 110.8572\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.597\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -214.1133554587882 SOC: 0.5896 Cumulative_SOC_deviation: 10.3020 Fuel Consumption: 111.0930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.672\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -162.893643194548 SOC: 0.5957 Cumulative_SOC_deviation: 5.1945 Fuel Consumption: 110.9484\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.784\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -151.15595153595345 SOC: 0.5971 Cumulative_SOC_deviation: 3.9979 Fuel Consumption: 111.1773\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.945\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -164.04317394966267 SOC: 0.5993 Cumulative_SOC_deviation: 5.3358 Fuel Consumption: 110.6849\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.835\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -158.61109301485956 SOC: 0.6017 Cumulative_SOC_deviation: 4.7770 Fuel Consumption: 110.8413\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.697\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -162.8960091357099 SOC: 0.5969 Cumulative_SOC_deviation: 5.2894 Fuel Consumption: 110.0020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.158\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -165.54154208496345 SOC: 0.5961 Cumulative_SOC_deviation: 5.5798 Fuel Consumption: 109.7433\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.037\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -155.72090255310232 SOC: 0.5976 Cumulative_SOC_deviation: 4.6054 Fuel Consumption: 109.6668\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.016\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -164.03195667540965 SOC: 0.5977 Cumulative_SOC_deviation: 5.4616 Fuel Consumption: 109.4157\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.804\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -157.9570184206912 SOC: 0.5981 Cumulative_SOC_deviation: 4.8439 Fuel Consumption: 109.5185\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.772\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -161.97546972911863 SOC: 0.5954 Cumulative_SOC_deviation: 5.2973 Fuel Consumption: 109.0023\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.894\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -171.21600125584928 SOC: 0.5942 Cumulative_SOC_deviation: 6.1931 Fuel Consumption: 109.2854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.817\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -162.74776350852545 SOC: 0.5940 Cumulative_SOC_deviation: 5.3066 Fuel Consumption: 109.6823\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.640\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -158.43149461696927 SOC: 0.5967 Cumulative_SOC_deviation: 4.8452 Fuel Consumption: 109.9791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.749\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -186.73767475318098 SOC: 0.5960 Cumulative_SOC_deviation: 7.7505 Fuel Consumption: 109.2330\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.937\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -174.75800585768386 SOC: 0.5947 Cumulative_SOC_deviation: 6.5597 Fuel Consumption: 109.1606\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.691\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -187.7658598429515 SOC: 0.5947 Cumulative_SOC_deviation: 7.9039 Fuel Consumption: 108.7267\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.040\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -174.03065213292086 SOC: 0.5942 Cumulative_SOC_deviation: 6.4975 Fuel Consumption: 109.0553\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.866\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -191.58244045223964 SOC: 0.5915 Cumulative_SOC_deviation: 8.3338 Fuel Consumption: 108.2447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.690\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -205.8168268914457 SOC: 0.5963 Cumulative_SOC_deviation: 9.6382 Fuel Consumption: 109.4346\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.321\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -172.97783978811438 SOC: 0.5944 Cumulative_SOC_deviation: 6.4505 Fuel Consumption: 108.4726\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.565\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -200.90216667401918 SOC: 0.5932 Cumulative_SOC_deviation: 9.2340 Fuel Consumption: 108.5627\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.258\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -180.68552630878702 SOC: 0.5930 Cumulative_SOC_deviation: 7.1603 Fuel Consumption: 109.0828\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.811\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -173.07649863251333 SOC: 0.5952 Cumulative_SOC_deviation: 6.3705 Fuel Consumption: 109.3718\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.024\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -189.12999548524158 SOC: 0.5934 Cumulative_SOC_deviation: 8.0468 Fuel Consumption: 108.6615\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.014\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -206.81619379415847 SOC: 0.5917 Cumulative_SOC_deviation: 9.8654 Fuel Consumption: 108.1625\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.907\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -205.0074097037268 SOC: 0.5929 Cumulative_SOC_deviation: 9.6504 Fuel Consumption: 108.5034\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.240\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -185.9145387564074 SOC: 0.5966 Cumulative_SOC_deviation: 7.6846 Fuel Consumption: 109.0690\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.237\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -183.6940493905256 SOC: 0.5951 Cumulative_SOC_deviation: 7.5078 Fuel Consumption: 108.6156\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.678\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -191.29291009006607 SOC: 0.5950 Cumulative_SOC_deviation: 8.2196 Fuel Consumption: 109.0965\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.831\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -176.4746928886103 SOC: 0.5944 Cumulative_SOC_deviation: 6.7761 Fuel Consumption: 108.7137\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.513\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -177.8643491334791 SOC: 0.5948 Cumulative_SOC_deviation: 6.9364 Fuel Consumption: 108.5004\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.058\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -174.2720276419984 SOC: 0.5956 Cumulative_SOC_deviation: 6.5905 Fuel Consumption: 108.3671\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.848\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -185.9585718517126 SOC: 0.5939 Cumulative_SOC_deviation: 7.7543 Fuel Consumption: 108.4157\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.007\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -183.19156316411994 SOC: 0.5876 Cumulative_SOC_deviation: 7.5112 Fuel Consumption: 108.0798\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.877\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -187.40456496206937 SOC: 0.5935 Cumulative_SOC_deviation: 7.9113 Fuel Consumption: 108.2916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.761\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -183.97567971265727 SOC: 0.5947 Cumulative_SOC_deviation: 7.5985 Fuel Consumption: 107.9903\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.910\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -176.64921232622007 SOC: 0.5945 Cumulative_SOC_deviation: 6.8479 Fuel Consumption: 108.1701\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.791\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -209.8412677627473 SOC: 0.5934 Cumulative_SOC_deviation: 10.2158 Fuel Consumption: 107.6829\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.990\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -207.7986444958058 SOC: 0.5927 Cumulative_SOC_deviation: 9.9757 Fuel Consumption: 108.0413\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.782\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -205.5206892433794 SOC: 0.5917 Cumulative_SOC_deviation: 9.6917 Fuel Consumption: 108.6040\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.151\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -213.6804987478933 SOC: 0.5933 Cumulative_SOC_deviation: 10.5502 Fuel Consumption: 108.1787\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.484\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -215.8600069561587 SOC: 0.5915 Cumulative_SOC_deviation: 10.7679 Fuel Consumption: 108.1811\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.454\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -212.6969433668782 SOC: 0.5934 Cumulative_SOC_deviation: 10.4124 Fuel Consumption: 108.5726\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.486\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -244.02581305989685 SOC: 0.5935 Cumulative_SOC_deviation: 13.5909 Fuel Consumption: 108.1168\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.787\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -219.46401239555408 SOC: 0.5939 Cumulative_SOC_deviation: 11.0428 Fuel Consumption: 109.0355\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.751\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -249.84979269913163 SOC: 0.5909 Cumulative_SOC_deviation: 14.2049 Fuel Consumption: 107.8005\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.766\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -254.52388612408754 SOC: 0.5898 Cumulative_SOC_deviation: 14.6431 Fuel Consumption: 108.0925\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.902\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -255.470211889126 SOC: 0.5927 Cumulative_SOC_deviation: 14.7097 Fuel Consumption: 108.3734\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.736\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -226.48325358392987 SOC: 0.5903 Cumulative_SOC_deviation: 11.8584 Fuel Consumption: 107.8995\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.672\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -218.26467097242522 SOC: 0.5933 Cumulative_SOC_deviation: 11.0172 Fuel Consumption: 108.0926\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.901\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -225.5178876182148 SOC: 0.5941 Cumulative_SOC_deviation: 11.7413 Fuel Consumption: 108.1045\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.004\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -222.8740278311368 SOC: 0.5941 Cumulative_SOC_deviation: 11.4488 Fuel Consumption: 108.3856\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.923\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -240.46543578701136 SOC: 0.5945 Cumulative_SOC_deviation: 13.1786 Fuel Consumption: 108.6790\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.927\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -248.43624435612838 SOC: 0.5897 Cumulative_SOC_deviation: 14.0626 Fuel Consumption: 107.8104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.123\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -238.65612756574595 SOC: 0.5960 Cumulative_SOC_deviation: 13.0053 Fuel Consumption: 108.6028\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.891\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -208.14512113209489 SOC: 0.5935 Cumulative_SOC_deviation: 10.0242 Fuel Consumption: 107.9031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.990\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -198.90554284473913 SOC: 0.5932 Cumulative_SOC_deviation: 9.0449 Fuel Consumption: 108.4566\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.044\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -209.73356011174437 SOC: 0.5949 Cumulative_SOC_deviation: 10.0971 Fuel Consumption: 108.7621\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.017\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -246.98150488102445 SOC: 0.5973 Cumulative_SOC_deviation: 13.7762 Fuel Consumption: 109.2193\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.201\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -250.2564028621446 SOC: 0.5923 Cumulative_SOC_deviation: 14.1979 Fuel Consumption: 108.2778\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.305\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -239.76882964162573 SOC: 0.5927 Cumulative_SOC_deviation: 13.1412 Fuel Consumption: 108.3572\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.424\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -235.1702472266271 SOC: 0.5927 Cumulative_SOC_deviation: 12.7005 Fuel Consumption: 108.1650\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.787\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -219.86547466316074 SOC: 0.5921 Cumulative_SOC_deviation: 11.2133 Fuel Consumption: 107.7321\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.311\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -235.0374192143273 SOC: 0.5908 Cumulative_SOC_deviation: 12.7290 Fuel Consumption: 107.7469\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.662\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -256.0377233769655 SOC: 0.5913 Cumulative_SOC_deviation: 14.8161 Fuel Consumption: 107.8765\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.602\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -249.19025651023043 SOC: 0.5947 Cumulative_SOC_deviation: 14.0441 Fuel Consumption: 108.7489\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.858\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -218.36551530427658 SOC: 0.5916 Cumulative_SOC_deviation: 10.9862 Fuel Consumption: 108.5037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.800\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -211.59871056859242 SOC: 0.5966 Cumulative_SOC_deviation: 10.3119 Fuel Consumption: 108.4796\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.318\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -173.832786799755 SOC: 0.5972 Cumulative_SOC_deviation: 6.5034 Fuel Consumption: 108.7987\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.790\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -220.59642631602838 SOC: 0.5878 Cumulative_SOC_deviation: 11.2102 Fuel Consumption: 108.4949\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.478\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -227.3032504893512 SOC: 0.5912 Cumulative_SOC_deviation: 11.9276 Fuel Consumption: 108.0277\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.995\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -241.2533400079951 SOC: 0.5951 Cumulative_SOC_deviation: 13.2815 Fuel Consumption: 108.4383\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.773\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -218.55744658682147 SOC: 0.5960 Cumulative_SOC_deviation: 10.9736 Fuel Consumption: 108.8213\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.308\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -229.71329982427326 SOC: 0.5994 Cumulative_SOC_deviation: 11.9647 Fuel Consumption: 110.0659\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.510\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -209.08831869851488 SOC: 0.5975 Cumulative_SOC_deviation: 10.0190 Fuel Consumption: 108.8979\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.532\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -240.438326773427 SOC: 0.5859 Cumulative_SOC_deviation: 13.2352 Fuel Consumption: 108.0859\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.989\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -282.00758506381277 SOC: 0.5926 Cumulative_SOC_deviation: 17.3350 Fuel Consumption: 108.6573\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.587\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -262.5659765847785 SOC: 0.5889 Cumulative_SOC_deviation: 15.3902 Fuel Consumption: 108.6643\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.478\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -261.5264734329141 SOC: 0.5921 Cumulative_SOC_deviation: 15.2012 Fuel Consumption: 109.5143\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.764\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -264.37726224094587 SOC: 0.5912 Cumulative_SOC_deviation: 15.4988 Fuel Consumption: 109.3890\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.634\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -269.75618938370775 SOC: 0.5906 Cumulative_SOC_deviation: 16.1102 Fuel Consumption: 108.6545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.670\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -278.7588388481622 SOC: 0.5918 Cumulative_SOC_deviation: 17.0587 Fuel Consumption: 108.1723\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.977\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -222.7523162072363 SOC: 0.5965 Cumulative_SOC_deviation: 11.3729 Fuel Consumption: 109.0232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.890\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -224.18590785274378 SOC: 0.5914 Cumulative_SOC_deviation: 11.5254 Fuel Consumption: 108.9316\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.769\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -248.55175725738374 SOC: 0.5914 Cumulative_SOC_deviation: 13.9742 Fuel Consumption: 108.8099\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.871\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -251.2631208873575 SOC: 0.5883 Cumulative_SOC_deviation: 14.2010 Fuel Consumption: 109.2532\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.933\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -305.65357274909513 SOC: 0.5943 Cumulative_SOC_deviation: 19.5149 Fuel Consumption: 110.5047\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.719\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -244.7514511117478 SOC: 0.5924 Cumulative_SOC_deviation: 13.4740 Fuel Consumption: 110.0115\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.738\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -176.0457704317711 SOC: 0.5971 Cumulative_SOC_deviation: 6.7646 Fuel Consumption: 108.3996\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.968\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -260.93507044117473 SOC: 0.5883 Cumulative_SOC_deviation: 15.2749 Fuel Consumption: 108.1860\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.730\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -258.16017147912464 SOC: 0.5959 Cumulative_SOC_deviation: 14.9124 Fuel Consumption: 109.0358\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.948\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -252.5990766540856 SOC: 0.5935 Cumulative_SOC_deviation: 14.3697 Fuel Consumption: 108.9019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.882\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -225.36681285436777 SOC: 0.5973 Cumulative_SOC_deviation: 11.6544 Fuel Consumption: 108.8233\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.815\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -232.8451354295561 SOC: 0.5972 Cumulative_SOC_deviation: 12.3202 Fuel Consumption: 109.6432\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.920\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -183.45755819842367 SOC: 0.5964 Cumulative_SOC_deviation: 7.4759 Fuel Consumption: 108.6984\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.744\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -262.1540736072513 SOC: 0.5975 Cumulative_SOC_deviation: 15.2839 Fuel Consumption: 109.3152\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.834\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -158.5610066229372 SOC: 0.5920 Cumulative_SOC_deviation: 5.0514 Fuel Consumption: 108.0470\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.684\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -208.2320305508522 SOC: 0.5820 Cumulative_SOC_deviation: 10.0106 Fuel Consumption: 108.1259\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.757\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -223.57253112579215 SOC: 0.5902 Cumulative_SOC_deviation: 11.3717 Fuel Consumption: 109.8560\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.979\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -241.36265943010957 SOC: 0.5911 Cumulative_SOC_deviation: 13.1666 Fuel Consumption: 109.6962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.082\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -277.6849782453924 SOC: 0.5952 Cumulative_SOC_deviation: 16.7514 Fuel Consumption: 110.1705\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.196\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -255.73301513183975 SOC: 0.5912 Cumulative_SOC_deviation: 14.6276 Fuel Consumption: 109.4569\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.008\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -246.9429955034999 SOC: 0.5982 Cumulative_SOC_deviation: 13.7009 Fuel Consumption: 109.9342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.159\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -239.0574434933148 SOC: 0.5957 Cumulative_SOC_deviation: 12.8433 Fuel Consumption: 110.6241\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.876\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -208.13111019771017 SOC: 0.5918 Cumulative_SOC_deviation: 9.8947 Fuel Consumption: 109.1846\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.633\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -211.56831725925397 SOC: 0.5974 Cumulative_SOC_deviation: 10.1143 Fuel Consumption: 110.4256\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.902\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -188.84974235996356 SOC: 0.5990 Cumulative_SOC_deviation: 7.8529 Fuel Consumption: 110.3207\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.511\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -186.62474133720852 SOC: 0.5967 Cumulative_SOC_deviation: 7.7260 Fuel Consumption: 109.3651\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.468\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -192.9087230260311 SOC: 0.5964 Cumulative_SOC_deviation: 8.3470 Fuel Consumption: 109.4388\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.519\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -228.6675249256085 SOC: 0.5949 Cumulative_SOC_deviation: 11.8178 Fuel Consumption: 110.4898\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.717\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -252.65845310055442 SOC: 0.5926 Cumulative_SOC_deviation: 14.2731 Fuel Consumption: 109.9277\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.629\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -239.7807360446789 SOC: 0.5914 Cumulative_SOC_deviation: 13.0049 Fuel Consumption: 109.7321\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.370\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -238.89029727679653 SOC: 0.5964 Cumulative_SOC_deviation: 12.8859 Fuel Consumption: 110.0315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.783\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -222.47017060897633 SOC: 0.5955 Cumulative_SOC_deviation: 11.2173 Fuel Consumption: 110.2969\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.183\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -273.3802208556128 SOC: 0.5893 Cumulative_SOC_deviation: 16.2087 Fuel Consumption: 111.2934\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.686\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -247.63111808494205 SOC: 0.5917 Cumulative_SOC_deviation: 13.5379 Fuel Consumption: 112.2524\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.994\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -242.6799033904407 SOC: 0.5894 Cumulative_SOC_deviation: 13.2280 Fuel Consumption: 110.3998\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.168\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -303.46157662375833 SOC: 0.5965 Cumulative_SOC_deviation: 19.2851 Fuel Consumption: 110.6111\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.086\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -235.5483512474627 SOC: 0.5954 Cumulative_SOC_deviation: 12.5254 Fuel Consumption: 110.2941\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "# print(env.version)\n",
    "\n",
    "# num_trials = 1\n",
    "reward_factors = [7, 8, 9, 10]\n",
    "results_dict = {} \n",
    "driving_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "driving_cycle = sio.loadmat(driving_cycle_path)\n",
    "driving_cycle = driving_cycle[\"sch_cycle\"][:, 1]\n",
    "\n",
    "for reward_factor in reward_factors: \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(reward_factor))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "#         driving_cycle = driver.get_cycle() \n",
    "        env = initialization_env(driving_cycle, reward_factor)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "#             history = test_agent(actor_model, reward_factor)\n",
    "            history = env.history \n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "            \n",
    "#         if (ep + 1) % 200 == 0:             \n",
    "    root = \"DDPG_cycleOne_reward_factor{}\".format(reward_factor)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "            \n",
    "    \n",
    "    results_dict[reward_factor] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG_cycleOne_7to10.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
